{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'D:\\Project Phase II\\Dataset\\train.csv',encoding='cp1252')\n",
    "test = pd.read_csv(r'D:\\Project Phase II\\Dataset\\test.csv',encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop = ['Stime', 'Ltime', 'attack_cat']\n",
    "reducedTrain = train.drop(todrop, axis = 1)\n",
    "reducedTest = test.drop(todrop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = reducedTrain.drop(['Label'], axis = 1)\n",
    "y_train = reducedTrain['Label']\n",
    "x_test = reducedTest.drop(['Label'], axis = 1)\n",
    "y_test = reducedTest['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x, adj_matrix):\n",
    "        x = F.relu(self.fc1(torch.matmul(adj_matrix, x)))\n",
    "        x = self.fc2(torch.matmul(adj_matrix, x))\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a networkx directed graph from the dataframes\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "trainnodes = set()\n",
    "testnodes = set()\n",
    "\n",
    "for i in range(len(train)):\n",
    "    trainnodes.add(str(train.iloc[i]['srcip'])+\":\"+str(train.iloc[i]['sport']))\n",
    "    trainnodes.add(str(train.iloc[i]['dstip'])+\":\"+str(train.iloc[i]['dsport']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    testnodes.add(str(test.iloc[i]['srcip'])+\":\"+str(test.iloc[i]['sport']))\n",
    "    testnodes.add(str(test.iloc[i]['dstip'])+\":\"+str(test.iloc[i]['dsport']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainG = nx.DiGraph()\n",
    "for node in trainnodes:\n",
    "    trainG.add_node(node)\n",
    "\n",
    "testG = nx.DiGraph()\n",
    "for node in testnodes:\n",
    "    testG.add_node(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.iloc[0][4:46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dsport                       83\n",
       "proto                       120\n",
       "state                         2\n",
       "dur                    0.001046\n",
       "sbytes                      146\n",
       "dbytes                      178\n",
       "sttl                         31\n",
       "dttl                         29\n",
       "sloss                         0\n",
       "dloss                         0\n",
       "service                       2\n",
       "Sload                558317.375\n",
       "Dload               680688.3125\n",
       "Spkts                         2\n",
       "Dpkts                         2\n",
       "swin                          0\n",
       "dwin                          0\n",
       "stcpb                         0\n",
       "dtcpb                         0\n",
       "smeansz                      73\n",
       "dmeansz                      89\n",
       "trans_depth                   0\n",
       "res_bdy_len                   0\n",
       "Sjit                        0.0\n",
       "Djit                        0.0\n",
       "Stime                1424231464\n",
       "Ltime                1424231464\n",
       "Sintpkt                   0.003\n",
       "Dintpkt                   0.001\n",
       "tcprtt                      0.0\n",
       "synack                      0.0\n",
       "ackdat                      0.0\n",
       "ct_state_ttl                  0\n",
       "ct_flw_http_mthd            0.0\n",
       "is_ftp_login                  0\n",
       "ct_ftp_cmd                    0\n",
       "ct_srv_src                    1\n",
       "ct_srv_dst                    3\n",
       "ct_dst_ltm                    3\n",
       "ct_src_ ltm                   1\n",
       "ct_src_dport_ltm              1\n",
       "ct_dst_sport_ltm              1\n",
       "ct_dst_src_ltm                1\n",
       "attack_cat                   -1\n",
       "Label                         0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0][3:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add edges\n",
    "for i in range(len(train)):\n",
    "    trainG.add_edge(str(train.iloc[i]['srcip'])+\":\"+str(train.iloc[i]['sport']), str(train.iloc[i]['dstip'])+\":\"+str(train.iloc[i]['dsport']), weight = train.iloc[i][4:46], label=train.iloc[i][-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object dtype is not supported by sparse matrices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m adj_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjacency_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m adj_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(adj_matrix\u001b[38;5;241m.\u001b[39mtoarray())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\networkx\\utils\\backends.py:412\u001b[0m, in \u001b[0;36m_dispatch.__call__\u001b[1;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backends:\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;66;03m# Fast path if no backends are installed\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001b[39;00m\n\u001b[0;32m    415\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\networkx\\linalg\\graphmatrix.py:166\u001b[0m, in \u001b[0;36madjacency_matrix\u001b[1;34m(G, nodelist, dtype, weight)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;129m@nx\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(edge_attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madjacency_matrix\u001b[39m(G, nodelist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;124;03m\"\"\"Returns adjacency matrix of G.\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    adjacency_spectrum\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_scipy_sparse_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodelist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\networkx\\utils\\backends.py:412\u001b[0m, in \u001b[0;36m_dispatch.__call__\u001b[1;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backends:\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;66;03m# Fast path if no backends are installed\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001b[39;00m\n\u001b[0;32m    415\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\networkx\\convert_matrix.py:599\u001b[0m, in \u001b[0;36mto_scipy_sparse_array\u001b[1;34m(G, nodelist, dtype, weight, format)\u001b[0m\n\u001b[0;32m    596\u001b[0m     row, col, data \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m G\u001b[38;5;241m.\u001b[39mis_directed():\n\u001b[1;32m--> 599\u001b[0m     A \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoo_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnlen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnlen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;66;03m# symmetrize matrix\u001b[39;00m\n\u001b[0;32m    602\u001b[0m     d \u001b[38;5;241m=\u001b[39m data \u001b[38;5;241m+\u001b[39m data\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\sparse\\_coo.py:166\u001b[0m, in \u001b[0;36m_coo_base.__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(row, copy\u001b[38;5;241m=\u001b[39mcopy, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(col, copy\u001b[38;5;241m=\u001b[39mcopy, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[1;32m--> 166\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mgetdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_canonical_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\sparse\\_sputils.py:143\u001b[0m, in \u001b[0;36mgetdata\u001b[1;34m(obj, dtype, copy)\u001b[0m\n\u001b[0;32m    140\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(obj, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Defer to getdtype for checking that the dtype is OK.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# This is called for the validation only; we don't need the return value.\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m \u001b[43mgetdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\sparse\\_sputils.py:128\u001b[0m, in \u001b[0;36mgetdtype\u001b[1;34m(dtype, a, default)\u001b[0m\n\u001b[0;32m    126\u001b[0m     newdtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m newdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m--> 128\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    129\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject dtype is not supported by sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    130\u001b[0m         )\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m newdtype\n",
      "\u001b[1;31mValueError\u001b[0m: object dtype is not supported by sparse matrices"
     ]
    }
   ],
   "source": [
    "adj_matrix = nx.adjacency_matrix(trainG)\n",
    "adj_matrix = torch.FloatTensor(adj_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert data to PyTorch tensors\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m y_train_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(np\u001b[38;5;241m.\u001b[39marray(y_train))\n\u001b[0;32m      4\u001b[0m X_test_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(x_test)\n",
      "\u001b[1;31mValueError\u001b[0m: could not determine the shape of object type 'DataFrame'"
     ]
    }
   ],
   "source": [
    "#Pass networkx graph to GCN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(x_train)\n",
    "y_train_tensor = torch.LongTensor(np.array(y_train))\n",
    "X_test_tensor = torch.FloatTensor(x_test)\n",
    "y_test_tensor = torch.LongTensor(np.array(y_test))\n",
    "\n",
    "# Define the adjacency matrix (assuming no graph structure, so identity matrix)\n",
    "num_nodes = X_train.shape[0]\n",
    "adj_matrix = torch.eye(num_nodes)\n",
    "\n",
    "# Instantiate GCN model\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 4\n",
    "output_dim = 1\n",
    "model = GCN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, optimizer, criterion, adj_matrix, X_train, y_train, epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train, adj_matrix)\n",
    "        loss = criterion(output, torch.argmax(y_train, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')\n",
    "\n",
    "train_model(model, optimizer, criterion, adj_matrix, X_train_tensor, y_train_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "def evaluate_model(model, X_test, y_test, adj_matrix):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(X_test, adj_matrix)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        correct = (predicted == torch.argmax(y_test, dim=1)).sum().item()\n",
    "        accuracy = correct / y_test.size(0)\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "\n",
    "evaluate_model(model, X_test_tensor, y_test_tensor, adj_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
