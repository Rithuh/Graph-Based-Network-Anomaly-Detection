{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop = ['srcip', 'sport', 'dstip', 'dsport','sloss', 'dloss','stcpb', 'dtcpb', 'trans_depth', 'Stime', 'Ltime','ct_flw_http_mthd', \n",
    "        'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ ltm',\n",
    "        'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'attack_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['proto', 'state', 'dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'service', 'Sload', 'Dload',\n",
    "       'Spkts', 'Dpkts', 'swin', 'dwin', 'smeansz',\n",
    "       'dmeansz',  'res_bdy_len', 'Sjit', 'Djit', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack', 'ackdat',\n",
    "       'ct_state_ttl','Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_20992\\2025491202.py:1: DtypeWarning: Columns (46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv(r'D:\\Project Phase II\\Dataset\\finaltrain.csv',encoding='cp1252')\n",
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_20992\\2025491202.py:2: DtypeWarning: Columns (46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test = pd.read_csv(r'D:\\Project Phase II\\Dataset\\finaltest.csv',encoding='cp1252')\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(r'D:\\Project Phase II\\Dataset\\finaltrain.csv',encoding='cp1252')\n",
    "test = pd.read_csv(r'D:\\Project Phase II\\Dataset\\finaltest.csv',encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Attack:  40502  Non attack:  40502 Total:  81004\n",
      "Testing set:\n",
      "Attack:  17358  Non attack:  17358 Total:  34716\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "print('Attack: ', len(train[train['Label'] == 0]), ' Non attack: ', len(train[train['Label'] == 0]), 'Total: ', len(train))\n",
    "print(\"Testing set:\")\n",
    "print('Attack: ', len(test[test['Label'] == 0]), ' Non attack: ', len(test[test['Label'] == 0]), 'Total: ', len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract edge features alone from train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop = ['srcip', 'sport', 'dstip', 'dsport','sloss', 'dloss','stcpb', 'dtcpb', 'trans_depth', 'Stime', 'Ltime','ct_flw_http_mthd', \n",
    "        'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ ltm',\n",
    "        'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'attack_cat', 'Label']\n",
    "\n",
    "trainAttributes = train.drop(todrop, axis = 1)\n",
    "testAttributes = test.drop(todrop, axis = 1)\n",
    "\n",
    "trainLabel = train['Label']\n",
    "testLabel = test['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use LDA to reduce dimension to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components = 1)\n",
    "lda_x_train = lda.fit_transform(trainAttributes, trainLabel)\n",
    "lda_x_test = lda.transform(testAttributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute nodes and edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider only 7000 train records since memory becomes high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train.head(3500), train.tail(3500)])\n",
    "lda_x_train = np.concatenate((lda_x_train[:3500], lda_x_train[len(lda_x_train)-3500:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = set()\n",
    "edges = set()\n",
    "for i in range(7000):\n",
    "    src = str(train['srcip'].iloc[i])+':'+str(train['sport'].iloc[i])\n",
    "    dst = str(train['dstip'].iloc[i])+':'+str(train['dsport'].iloc[i])\n",
    "    nodes.add(src)\n",
    "    nodes.add(dst)\n",
    "    edges.add((src,dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8963"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 613. MiB for an array with shape (8963, 8963) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Prepare an adjacency matrix of the nodes\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m adjacency_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(nodes), \u001b[38;5;28mlen\u001b[39m(nodes)), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m      4\u001b[0m label_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(nodes), \u001b[38;5;28mlen\u001b[39m(nodes)))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Add the columns srcip:sport and dstip:dsport to the adjacency matrix\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 613. MiB for an array with shape (8963, 8963) and data type float64"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Prepare an adjacency matrix of the nodes\n",
    "adjacency_matrix = np.zeros((len(nodes), len(nodes)), dtype=float)\n",
    "label_matrix = np.zeros((len(nodes), len(nodes)))\n",
    "\n",
    "\n",
    "# Add the columns srcip:sport and dstip:dsport to the adjacency matrix\n",
    "for i in range(7000):\n",
    "    src = str(train['srcip'].iloc[i])+':'+str(train['sport'].iloc[i])\n",
    "    dst = str(train['dstip'].iloc[i])+':'+str(train['dsport'].iloc[i])\n",
    "    src_index = list(nodes).index(src)\n",
    "    dst_index = list(nodes).index(dst)\n",
    "    adjacency_matrix[src_index, dst_index] = lda_x_train[i]\n",
    "    label_matrix[src_index, dst_index] = train['Label'].iloc[i]\n",
    "# Flatten tuple values in the adjacency matrix\n",
    "adjacency_matrix_flat = adjacency_matrix.reshape(-1, 1)\n",
    "label_flat = label_matrix.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    3500\n",
       "1    3500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find label counts for first 7000 records in train\n",
    "train['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider only 5000 records for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([test.head(2500), test.tail(2500)])\n",
    "lda_x_test = np.concatenate((lda_x_test[:2500], lda_x_test[len(lda_x_test)-2500:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenodes = set()\n",
    "teedges = set()\n",
    "for i in range(len(test)):\n",
    "    src = str(test['srcip'].iloc[i])+':'+str(test['sport'].iloc[i])\n",
    "    dst = str(test['dstip'].iloc[i])+':'+str(test['dsport'].iloc[i])\n",
    "    tenodes.add(src)\n",
    "    tenodes.add(dst)\n",
    "    teedges.add((src,dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 628. MiB for an array with shape (9074, 9074) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Prepare an adjacency matrix of the nodes\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m adjacency_matrix_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(tenodes), \u001b[38;5;28mlen\u001b[39m(tenodes)), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m      4\u001b[0m label_matrix_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(tenodes), \u001b[38;5;28mlen\u001b[39m(tenodes)))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Add the columns srcip:sport and dstip:dsport to the adjacency matrix\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 628. MiB for an array with shape (9074, 9074) and data type float64"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Prepare an adjacency matrix of the nodes\n",
    "adjacency_matrix_test = np.zeros((len(tenodes), len(tenodes)), dtype=float)\n",
    "label_matrix_test = np.zeros((len(tenodes), len(tenodes)))\n",
    "\n",
    "\n",
    "# Add the columns srcip:sport and dstip:dsport to the adjacency matrix\n",
    "for i in range(len(test)):\n",
    "    src = str(test['srcip'].iloc[i])+':'+str(test['sport'].iloc[i])\n",
    "    dst = str(test['dstip'].iloc[i])+':'+str(test['dsport'].iloc[i])\n",
    "    src_index = list(nodes).index(src)\n",
    "    dst_index = list(nodes).index(dst)\n",
    "    adjacency_matrix_test[src_index, dst_index] = lda_x_test[i]\n",
    "    label_matrix_test[src_index, dst_index] = test['Label'].iloc[i]\n",
    "# Flatten tuple values in the adjacency matrix\n",
    "adjacency_matrix_test_flat = adjacency_matrix_test.reshape(-1, 1)\n",
    "label_test_flat = label_matrix_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "# Hyperparameters\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Modify the call method of the LSTMClassifier\n",
    "class LSTMClassifier(tf.keras.Model):\n",
    "    def __init__(self, input_shape, hidden_units, output_units):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = LSTM(hidden_units, return_sequences=False)  # Set return_sequences=False since we only need the output at the last timestep\n",
    "        self.dense = Dense(output_units, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.expand_dims(inputs, axis=-1)  # Add a new dimension to represent the input features\n",
    "        x = self.lstm(x)\n",
    "        output = self.dense(x)\n",
    "        return output\n",
    "    \n",
    "\n",
    "# Hyperparameters\n",
    "input_shape = adjacency_matrix_flat.shape[1:]  # Assuming each tuple has 2 attributes\n",
    "hidden_units = 16\n",
    "output_units = 1  # Binary classification\n",
    "\n",
    "# Convert adjacency_matrix_flat to a TensorFlow tensor\n",
    "adjacency_tensor = tf.convert_to_tensor(adjacency_matrix_flat, dtype=tf.float32)\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "lstmmodel = LSTMClassifier(input_shape, hidden_units, output_units)\n",
    "lstmmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lstmhistory = lstmmodel.fit(adjacency_tensor, label_flat, epochs=2, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmmodel.save_weights(\"lstmfinalldaweights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmpredictions = lstmmodel.predict(adjacency_matrix_test_flat)\n",
    "lstmpredictions = (lstmpredictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(label_test_flat, lstmpredictions)\n",
    "\n",
    "print(\"Classification Report for LSTM:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
