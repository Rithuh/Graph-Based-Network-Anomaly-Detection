{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_5200\\3370251438.py:1: DtypeWarning: Columns (1,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r'D:\\Project Phase II\\Dataset\\phase2labelencodeddataset.csv',encoding='cp1252')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\Project Phase II\\Dataset\\phase2labelencodeddataset.csv',encoding='cp1252')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43005"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find all string values in sport\n",
    "df['sport'] = df['sport'].astype(str)\n",
    "#Replace '-' with 0\n",
    "df['sport'] = df['sport'].replace('-', '80')\n",
    "#COnvert hexadecimal values to decimal in sport\n",
    "df['sport'] = df['sport'].apply(lambda x: int(x, 16))\n",
    "#Convert sport to int\n",
    "df['sport'] = df['sport'].astype(int)\n",
    "\n",
    "len(df['sport'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64380"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dsport'] = df['dsport'].astype(str)\n",
    "df['dsport'] = df['dsport'].replace('-', '80')\n",
    "df['dsport'] = df['dsport'].apply(lambda x: int(x, 16))\n",
    "df['dsport'] = df['dsport'].astype(int)\n",
    "len(df['dsport'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_5200\\4043762459.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfAttack.drop(['Label'], axis=1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "321283"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAttack = df[df['Label']==1]\n",
    "dfAttack.drop(['Label'], axis=1, inplace=True)\n",
    "len(dfAttack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.166.0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>30306</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>0.119596</td>\n",
       "      <td>4550</td>\n",
       "      <td>68342</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.166.0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.2</td>\n",
       "      <td>161545</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>0.650574</td>\n",
       "      <td>8928</td>\n",
       "      <td>320</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.166.0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>20880</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>2158</td>\n",
       "      <td>2464</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149.171.126.18</td>\n",
       "      <td>0</td>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>83</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149.171.126.18</td>\n",
       "      <td>0</td>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>83</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535847</th>\n",
       "      <td>59.166.0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>0.087306</td>\n",
       "      <td>320</td>\n",
       "      <td>1828</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535848</th>\n",
       "      <td>59.166.0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>0.365058</td>\n",
       "      <td>456</td>\n",
       "      <td>346</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535849</th>\n",
       "      <td>59.166.0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>6.335154</td>\n",
       "      <td>1802</td>\n",
       "      <td>2088</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535850</th>\n",
       "      <td>59.166.0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.0</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>2.200934</td>\n",
       "      <td>3498</td>\n",
       "      <td>166054</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535851</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.17</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>0.942984</td>\n",
       "      <td>574</td>\n",
       "      <td>676</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2535852 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  srcip  sport           dstip  dsport  proto  state  \\\n",
       "0            59.166.0.1      0   149.171.126.4   30306    114      5   \n",
       "1            59.166.0.3      0   149.171.126.2  161545    114      5   \n",
       "2            59.166.0.8      0   149.171.126.9   20880    114      5   \n",
       "3        149.171.126.18      0    175.45.176.3      83    120      6   \n",
       "4        149.171.126.18      0    175.45.176.3      83    120      6   \n",
       "...                 ...    ...             ...     ...    ...    ...   \n",
       "2535847      59.166.0.5      0   149.171.126.7       0    114      5   \n",
       "2535848      59.166.0.7      0   149.171.126.4       0    114      2   \n",
       "2535849      59.166.0.3      0   149.171.126.9       0    114      2   \n",
       "2535850      59.166.0.9      0   149.171.126.0       0    114      2   \n",
       "2535851    175.45.176.0      0  149.171.126.17       0    114      2   \n",
       "\n",
       "              dur  sbytes  dbytes  sttl  ...  ct_ftp_cmd  ct_srv_src  \\\n",
       "0        0.119596    4550   68342    31  ...           0           6   \n",
       "1        0.650574    8928     320    31  ...           0           3   \n",
       "2        0.007980    2158    2464    31  ...           0           3   \n",
       "3        0.000005     264       0    60  ...           0          19   \n",
       "4        0.000005     264       0    60  ...           0          19   \n",
       "...           ...     ...     ...   ...  ...         ...         ...   \n",
       "2535847  0.087306     320    1828    31  ...           0           1   \n",
       "2535848  0.365058     456     346    31  ...           2           2   \n",
       "2535849  6.335154    1802    2088    31  ...           2           2   \n",
       "2535850  2.200934    3498  166054    31  ...           0           1   \n",
       "2535851  0.942984     574     676    62  ...           0           1   \n",
       "\n",
       "         ct_srv_dst  ct_dst_ltm  ct_src_ ltm  ct_src_dport_ltm  \\\n",
       "0                 2           2            5                 1   \n",
       "1                 5           2            4                 1   \n",
       "2                 5           1            1                 1   \n",
       "3                19          19           19                19   \n",
       "4                19          19           19                19   \n",
       "...             ...         ...          ...               ...   \n",
       "2535847           2           3            3                 1   \n",
       "2535848           2           2            2                 2   \n",
       "2535849           2           4            2                 2   \n",
       "2535850           1           2            4                 2   \n",
       "2535851           1           2            4                 2   \n",
       "\n",
       "         ct_dst_sport_ltm  ct_dst_src_ltm  attack_cat  Label  \n",
       "0                       1               2           6      0  \n",
       "1                       1               4           6      0  \n",
       "2                       1               3           6      0  \n",
       "3                      19              19           6      0  \n",
       "4                      19              19           6      0  \n",
       "...                   ...             ...         ...    ...  \n",
       "2535847                 1               3           6      0  \n",
       "2535848                 2               2           6      0  \n",
       "2535849                 2               2           6      0  \n",
       "2535850                 2               2           6      0  \n",
       "2535851                 2               2           3      1  \n",
       "\n",
       "[2535852 rows x 48 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train and test based on attack_cat\n",
    "X = dfAttack.drop(['attack_cat'], axis=1)\n",
    "y = dfAttack['attack_cat']\n",
    "X = X.drop(['srcip','dstip'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       558\n",
      "           1       0.00      0.00      0.00       445\n",
      "           2       0.00      0.00      0.00      3355\n",
      "           3       0.47      0.54      0.51      8946\n",
      "           4       0.66      0.04      0.07      4897\n",
      "           5       0.79      0.99      0.88     42913\n",
      "           7       0.00      0.00      0.00      2807\n",
      "           8       0.00      0.00      0.00       298\n",
      "           9       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.74     64257\n",
      "   macro avg       0.21      0.17      0.16     64257\n",
      "weighted avg       0.64      0.74      0.66     64257\n",
      "\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test,y_pred))\n\u001b[1;32m----> 7\u001b[0m auc_scores \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43movr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Or multi_class='ovo' for one-vs-one\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC Scores for each class:\u001b[39m\u001b[38;5;124m\"\u001b[39m, auc_scores)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:561\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multi_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_class must be in (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_multiclass_roc_auc_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    565\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:627\u001b[0m, in \u001b[0;36m_multiclass_roc_auc_score\u001b[1;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;124;03m\"\"\"Multiclass roc auc score.\u001b[39;00m\n\u001b[0;32m    588\u001b[0m \n\u001b[0;32m    589\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m \n\u001b[0;32m    625\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;66;03m# validation of the input y_score\u001b[39;00m\n\u001b[1;32m--> 627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(\u001b[38;5;241m1\u001b[39m, \u001b[43my_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    629\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget scores need to be probabilities for multiclass \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    630\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_auc, i.e. they should sum up to 1.0 over classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    631\u001b[0m     )\n\u001b[0;32m    633\u001b[0m \u001b[38;5;66;03m# validation for multiclass parameter specifications\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "#Logistic regression to classify using all variables\n",
    "from sklearn.metrics import roc_auc_score\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "auc_scores = roc_auc_score(y_test, y_pred, multi_class='ovr')  # Or multi_class='ovo' for one-vs-one\n",
    "print(\"AUC Scores for each class:\", auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    172568\n",
       "3     35579\n",
       "4     19349\n",
       "2     12998\n",
       "7     11180\n",
       "0      2119\n",
       "1      1884\n",
       "8      1213\n",
       "9       136\n",
       "Name: attack_cat, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the number of each attack category in XTrain\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    42913\n",
       "3     8946\n",
       "4     4897\n",
       "2     3355\n",
       "7     2807\n",
       "0      558\n",
       "1      445\n",
       "8      298\n",
       "9       38\n",
       "Name: attack_cat, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score of Logistic Regression:  0.7402947561725273\n",
      "Accuracy of Logistic Regression:  0.7371025724823754\n"
     ]
    }
   ],
   "source": [
    "#Training score of Logistic Regression\n",
    "print(\"Training score of Logistic Regression: \", lr.score(X_train, y_train))\n",
    "#For each class\n",
    "print(\"Accuracy of Logistic Regression: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.18      0.28       558\n",
      "           1       0.49      0.10      0.17       445\n",
      "           2       0.33      0.36      0.34      3355\n",
      "           3       0.64      0.76      0.69      8946\n",
      "           4       0.95      0.87      0.91      4897\n",
      "           5       1.00      0.99      0.99     42913\n",
      "           7       0.89      0.77      0.83      2807\n",
      "           8       0.85      0.83      0.84       298\n",
      "           9       0.55      0.55      0.55        38\n",
      "\n",
      "    accuracy                           0.89     64257\n",
      "   macro avg       0.70      0.60      0.62     64257\n",
      "weighted avg       0.90      0.89      0.89     64257\n",
      "\n",
      "Training score of Decision Tree:  0.9304973037747154\n",
      "Accuracy of Decision Tree:  0.8899730768632211\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree and also visualise the tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Training score of Decision Tree: \", dt.score(X_train, y_train))\n",
    "print(\"Accuracy of Decision Tree: \", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 5 sbytes (0.622920)\n",
      "2. feature 1 dsport (0.164337)\n",
      "3. feature 11 service (0.037611)\n",
      "4. feature 6 dbytes (0.021495)\n",
      "5. feature 7 sttl (0.021233)\n",
      "6. feature 21 dmeansz (0.017264)\n",
      "7. feature 20 smeansz (0.016261)\n",
      "8. feature 38 ct_srv_dst (0.012310)\n",
      "9. feature 18 stcpb (0.011167)\n",
      "10. feature 26 Stime (0.008336)\n",
      "11. feature 9 sloss (0.005382)\n",
      "12. feature 13 Dload (0.004789)\n",
      "13. feature 37 ct_srv_src (0.004033)\n",
      "14. feature 19 dtcpb (0.003968)\n",
      "15. feature 31 synack (0.003931)\n",
      "16. feature 32 ackdat (0.003838)\n",
      "17. feature 12 Sload (0.003636)\n",
      "18. feature 30 tcprtt (0.003404)\n",
      "19. feature 4 dur (0.003202)\n",
      "20. feature 25 Djit (0.003178)\n",
      "21. feature 23 res_bdy_len (0.003127)\n",
      "22. feature 28 Sintpkt (0.002834)\n",
      "23. feature 24 Sjit (0.002834)\n",
      "24. feature 27 Ltime (0.002691)\n",
      "25. feature 29 Dintpkt (0.002579)\n",
      "26. feature 10 dloss (0.002545)\n",
      "27. feature 34 ct_flw_http_mthd (0.002181)\n",
      "28. feature 40 ct_src_ ltm (0.001456)\n",
      "29. feature 14 Spkts (0.001384)\n",
      "30. feature 0 sport (0.001240)\n",
      "31. feature 43 ct_dst_src_ltm (0.001144)\n",
      "32. feature 39 ct_dst_ltm (0.001111)\n",
      "33. feature 15 Dpkts (0.000905)\n",
      "34. feature 2 proto (0.000685)\n",
      "35. feature 42 ct_dst_sport_ltm (0.000385)\n",
      "36. feature 41 ct_src_dport_ltm (0.000289)\n",
      "37. feature 22 trans_depth (0.000212)\n",
      "38. feature 33 ct_state_ttl (0.000051)\n",
      "39. feature 8 dttl (0.000022)\n",
      "40. feature 16 swin (0.000016)\n",
      "41. feature 17 dwin (0.000012)\n",
      "42. feature 3 state (0.000003)\n",
      "43. feature 35 is_ftp_login (0.000000)\n",
      "44. feature 36 ct_ftp_cmd (0.000000)\n"
     ]
    }
   ],
   "source": [
    "#Sort the Gini Index and find the most important and least important features\n",
    "#With the feature names\n",
    "\n",
    "importances = dt.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], X.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Sampling with Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSample0 = df[df['Label'] == 0].sample(n=250000, random_state=42)\n",
    "dfSample1 = df[df['Label'] == 1].sample(n=250000, random_state=42)\n",
    "\n",
    "dfSample = pd.concat([dfSample0, dfSample1])\n",
    "dfSample = dfSample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#Split the dataset into features and labels\n",
    "XSample = dfSample.drop('Label', axis=1)\n",
    "ySample = dfSample['Label']\n",
    "\n",
    "#Split the dataset into training and testing sets\n",
    "XSample_train, XSample_test, ySample_train, ySample_test = train_test_split(XSample, ySample, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_5200\\3429069213.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfDroppedforLR = dfDroppedforLR.append(df[df['Label'] == 1].sample(n=250000, random_state=40))\n"
     ]
    }
   ],
   "source": [
    "#Take equal number of samples for each label\n",
    "dfDroppedforLR = df[df['Label'] == 0].sample(n=250000, random_state=40)\n",
    "dfDroppedforLR = dfDroppedforLR.append(df[df['Label'] == 1].sample(n=250000, random_state=40))\n",
    "\n",
    "#Drop srcip and dstip and use a new df\n",
    "dfDroppedforLR = dfDroppedforLR.drop(['srcip', 'dstip','attack_cat','Stime','Ltime'], axis=1)\n",
    "\n",
    "#Shuffle the dataset\n",
    "dfDroppedforLR = dfDroppedforLR.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#Split the dataset into features and labels\n",
    "X = dfDroppedforLR.iloc[:,0:42]\n",
    "y = dfDroppedforLR['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models with Sampled Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     49981\n",
      "           1       0.99      0.99      0.99     50019\n",
      "\n",
      "    accuracy                           0.99    100000\n",
      "   macro avg       0.99      0.99      0.99    100000\n",
      "weighted avg       0.99      0.99      0.99    100000\n",
      "\n",
      "Training score of Decision Tree:  0.9998325\n",
      "Accuracy of Decision Tree:  0.99047\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Training score of Decision Tree: \", dt.score(X_train, y_train))\n",
    "print(\"Accuracy of Decision Tree: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 31 ct_state_ttl (0.963163)\n",
      "2. feature 1 dsport (0.005711)\n",
      "3. feature 7 sttl (0.004860)\n",
      "4. feature 20 smeansz (0.003025)\n",
      "5. feature 5 sbytes (0.001611)\n",
      "6. feature 19 dtcpb (0.001538)\n",
      "7. feature 12 Sload (0.001507)\n",
      "8. feature 35 ct_srv_src (0.001440)\n",
      "9. feature 18 stcpb (0.001399)\n",
      "10. feature 36 ct_srv_dst (0.001372)\n",
      "11. feature 30 ackdat (0.001175)\n",
      "12. feature 29 synack (0.001172)\n",
      "13. feature 4 dur (0.001125)\n",
      "14. feature 28 tcprtt (0.001073)\n",
      "15. feature 25 Djit (0.001035)\n",
      "16. feature 41 ct_dst_src_ltm (0.000907)\n",
      "17. feature 26 Sintpkt (0.000867)\n",
      "18. feature 24 Sjit (0.000838)\n",
      "19. feature 27 Dintpkt (0.000773)\n",
      "20. feature 38 ct_src_ ltm (0.000751)\n",
      "21. feature 16 swin (0.000649)\n",
      "22. feature 37 ct_dst_ltm (0.000606)\n",
      "23. feature 13 Dload (0.000524)\n",
      "24. feature 23 res_bdy_len (0.000513)\n",
      "25. feature 39 ct_src_dport_ltm (0.000491)\n",
      "26. feature 6 dbytes (0.000373)\n",
      "27. feature 21 dmeansz (0.000368)\n",
      "28. feature 0 sport (0.000333)\n",
      "29. feature 40 ct_dst_sport_ltm (0.000237)\n",
      "30. feature 32 ct_flw_http_mthd (0.000126)\n",
      "31. feature 15 Dpkts (0.000121)\n",
      "32. feature 2 proto (0.000113)\n",
      "33. feature 14 Spkts (0.000067)\n",
      "34. feature 9 sloss (0.000066)\n",
      "35. feature 10 dloss (0.000040)\n",
      "36. feature 33 is_ftp_login (0.000023)\n",
      "37. feature 11 service (0.000010)\n",
      "38. feature 8 dttl (0.000000)\n",
      "39. feature 34 ct_ftp_cmd (0.000000)\n",
      "40. feature 17 dwin (0.000000)\n",
      "41. feature 3 state (0.000000)\n",
      "42. feature 22 trans_depth (0.000000)\n"
     ]
    }
   ],
   "source": [
    "#Sort the Gini Index and find the most important and least important features\n",
    "#With the feature names\n",
    "\n",
    "importances = dt.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], X.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA for sttl and ct_state_ttl with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96     49981\n",
      "           1       0.98      0.93      0.96     50019\n",
      "\n",
      "    accuracy                           0.96    100000\n",
      "   macro avg       0.96      0.96      0.96    100000\n",
      "weighted avg       0.96      0.96      0.96    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1)\n",
    "X = X[['sttl', 'ct_state_ttl']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pca_x_train = pca.fit_transform(X_train)\n",
    "pca_x_test = pca.fit_transform(X_test)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(pca_x_train, y_train)\n",
    "y_pred = classifier.predict(pca_x_test)\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Co efficients using Linear Equation of Logistic Regression:  [[-0.03420537]]\n",
      "PCA Co efficients for sttl and ct_state_ttl:\n",
      "[[-0.99996548 -0.00830924]]\n"
     ]
    }
   ],
   "source": [
    "#Linear equation formed by PCA\n",
    "print(\"PCA Co efficients using Linear Equation of Logistic Regression: \", classifier.coef_)\n",
    "print(\"PCA Co efficients for sttl and ct_state_ttl:\")\n",
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA for sttl and ct_state_ttl with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     49981\n",
      "           1       0.98      1.00      0.99     50019\n",
      "\n",
      "    accuracy                           0.99    100000\n",
      "   macro avg       0.99      0.99      0.99    100000\n",
      "weighted avg       0.99      0.99      0.99    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1)\n",
    "X = X[['ct_state_ttl','sttl']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pca_x_train = pca.fit_transform(X_train)\n",
    "pca_x_test = pca.fit_transform(X_test)\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(pca_x_train, y_train)\n",
    "y_pred = classifier.predict(pca_x_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Co efficients for sttl and ct_state_ttl:\n",
      "[[-0.00830924 -0.99996548]]\n"
     ]
    }
   ],
   "source": [
    "#Linear equation formed by PCA\n",
    "print(\"PCA Co efficients for sttl and ct_state_ttl:\")\n",
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proper class-wise dataset sampling and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsample0 = dfSample0.sample(n=12500, random_state=42)\n",
    "dfsample1 = dfSample1.sample(n=12500, random_state=42)\n",
    "\n",
    "dfsample0train, dfsample0test = train_test_split(dfsample0, test_size=0.2, random_state=42)\n",
    "dfsample1train, dfsample1test = train_test_split(dfsample1, test_size=0.2, random_state=42)\n",
    "\n",
    "dfsampletrain = pd.concat([dfsample0train, dfsample1train])\n",
    "dfsampletest = pd.concat([dfsample0test, dfsample1test])\n",
    "\n",
    "XSample_train = dfsampletrain[['srcip','sport','dstip','dsport','sttl', 'ct_state_ttl']]\n",
    "ySample_train = dfsampletrain['Label']\n",
    "XSample_test = dfsampletest[['srcip','sport','dstip','dsport','sttl', 'ct_state_ttl']]\n",
    "ySample_test = dfsampletest['Label']\n",
    "\n",
    "\n",
    "\n",
    "dfsample = dfsampletrain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2995"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = set()\n",
    "edges = set()\n",
    "for i in range(len(dfsample)):\n",
    "    src = str(dfsample['srcip'].iloc[i])+':'+str(dfsample['sport'].iloc[i])\n",
    "    dst = str(dfsample['dstip'].iloc[i])+':'+str(dfsample['dsport'].iloc[i])\n",
    "    nodes.add(src)\n",
    "    nodes.add(dst)\n",
    "    edges.add((src,dst))\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3988"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8970025"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2995*2995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Prepare an adjacency matrix of the nodes\n",
    "adjacency_matrix = np.zeros((len(nodes), len(nodes)), dtype=float)\n",
    "label_matrix = np.zeros((len(nodes), len(nodes)))\n",
    "\n",
    "# Add the columns srcip:sport and dstip:dsport to the adjacency matrix\n",
    "for i in range(len(dfsample)):\n",
    "    src = str(dfsample['srcip'].iloc[i])+':'+str(dfsample['sport'].iloc[i])\n",
    "    dst = str(dfsample['dstip'].iloc[i])+':'+str(dfsample['dsport'].iloc[i])\n",
    "    src_index = list(nodes).index(src)\n",
    "    dst_index = list(nodes).index(dst)\n",
    "    adjacency_matrix[src_index, dst_index] = 0.99996548*dfsample['sttl'].iloc[i] + 0.00830924*dfsample['ct_state_ttl'].iloc[i]\n",
    "    label_matrix[src_index, dst_index] = dfsample['Label'].iloc[i]\n",
    "# Flatten tuple values in the adjacency matrix\n",
    "adjacency_matrix_flat = adjacency_matrix.reshape(-1, 1)\n",
    "label_flat = label_matrix.reshape(-1, 1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM MODEL TRAINING FOR edge_weight = 0.99996548 * sttl + 0.00830924 * ct_state_ttl (DONOT RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "224251/224251 [==============================] - 2646s 12ms/step - loss: 8.5013e-04 - accuracy: 1.0000 - val_loss: 1.1908e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "224251/224251 [==============================] - 2072s 9ms/step - loss: 5.4401e-05 - accuracy: 1.0000 - val_loss: 1.0904e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Modify the call method of the LSTMClassifier\n",
    "class LSTMClassifier(tf.keras.Model):\n",
    "    def __init__(self, input_shape, hidden_units, output_units):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = LSTM(hidden_units, return_sequences=False)  # Set return_sequences=False since we only need the output at the last timestep\n",
    "        self.dense = Dense(output_units, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.expand_dims(inputs, axis=-1)  # Add a new dimension to represent the input features\n",
    "        x = self.lstm(x)\n",
    "        output = self.dense(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "input_shape = adjacency_matrix_flat.shape[1:]  # Assuming each tuple has 2 attributes\n",
    "hidden_units = 16\n",
    "output_units = 1  # Binary classification\n",
    "\n",
    "# Convert adjacency_matrix_flat to a TensorFlow tensor\n",
    "adjacency_tensor = tf.convert_to_tensor(adjacency_matrix_flat, dtype=tf.float32)\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "model = LSTMClassifier(input_shape, hidden_units, output_units)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Training\n",
    "history = model.fit(adjacency_tensor, label_flat, epochs=2, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluation\n",
    "#loss, accuracy = model.evaluate(adjacency_tensor, label_flat) \n",
    "#print(f'Loss: {loss}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the LSTM Model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to HDF5 file\n",
    "model.save_weights(\"lstm_weights_sttl_ct_state_ttl_pca.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the weights to create the LSTM for edge_weight = 0.99996548 * sttl + 0.00830924 * ct_state_ttlfrom stored data\n",
    "\n",
    "LSTM needs some dummy data to get initialised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 31s 31s/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6921 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.6921 - accuracy: 1.0000 - val_loss: 0.6910 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "# Hyperparameters\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Modify the call method of the LSTMClassifier\n",
    "class LSTMClassifier(tf.keras.Model):\n",
    "    def __init__(self, input_shape, hidden_units, output_units):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = LSTM(hidden_units, return_sequences=False)  # Set return_sequences=False since we only need the output at the last timestep\n",
    "        self.dense = Dense(output_units, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.expand_dims(inputs, axis=-1)  # Add a new dimension to represent the input features\n",
    "        x = self.lstm(x)\n",
    "        output = self.dense(x)\n",
    "        return output\n",
    "    \n",
    "input_shape = adjacency_matrix_flat.shape[1:]  # Assuming each tuple has 2 attributes\n",
    "hidden_units = 16\n",
    "output_units = 1  # Binary classification\n",
    "# Initialize model, optimizer, and loss function\n",
    "model_test_load = LSTMClassifier(input_shape, hidden_units, output_units)\n",
    "\n",
    "dummy_input = np.zeros((4, 4), dtype=float)\n",
    "dummy_label = np.zeros((4, 4))\n",
    "#Use dummy data to initialize the model\n",
    "dummy_flat = dummy_input.reshape(-1, 1)\n",
    "dummy_label_flat = dummy_label.reshape(-1, 1) \n",
    "\n",
    "model_test_load.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model_test_load.fit(dummy_flat, dummy_label_flat, epochs=2, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved weights\n",
    "model_test_load.load_weights(\"lstm_weights_sttl_ct_state_ttl_pca.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodes = set()\n",
    "edges = set()\n",
    "for i in range(len(dfsampletest)):\n",
    "    src = str(dfsampletest['srcip'].iloc[i])+':'+str(dfsampletest['sport'].iloc[i])\n",
    "    dst = str(dfsampletest['dstip'].iloc[i])+':'+str(dfsampletest['dsport'].iloc[i])\n",
    "    nodes.add(src)\n",
    "    nodes.add(dst)\n",
    "    edges.add((src,dst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "915"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1422"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Prepare an adjacency matrix of the nodes\n",
    "adjacency_matrix_test = np.zeros((len(nodes), len(nodes)), dtype=float)\n",
    "label_matrix_test = np.zeros((len(nodes), len(nodes)))\n",
    "\n",
    "# Add the columns srcip:sport and dstip:dsport to the adjacency matrix\n",
    "for i in range(len(dfsampletest)):\n",
    "    src = str(dfsampletest['srcip'].iloc[i])+':'+str(dfsampletest['sport'].iloc[i])\n",
    "    dst = str(dfsampletest['dstip'].iloc[i])+':'+str(dfsampletest['dsport'].iloc[i])\n",
    "    src_index = list(nodes).index(src)\n",
    "    dst_index = list(nodes).index(dst)\n",
    "    adjacency_matrix_test[src_index, dst_index] = 0.99996548*dfsampletest['sttl'].iloc[i] + 0.00830924*dfsampletest['ct_state_ttl'].iloc[i]\n",
    "    label_matrix_test[src_index, dst_index] = dfsampletest['Label'].iloc[i]\n",
    "# Flatten tuple values in the adjacency matrix\n",
    "adjacency_matrix_test_flat = adjacency_matrix_test.reshape(-1, 1)\n",
    "label_test_flat = label_matrix_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26164/26164 [==============================] - 146s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(adjacency_matrix_test_flat)\n",
    "predictionsclass = (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25116/26164 [===========================>..] - ETA: 6s"
     ]
    }
   ],
   "source": [
    "predictions_test = model_test_load.predict(adjacency_matrix_test_flat)\n",
    "predictionsclass_test = (predictions_test > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(label_test_flat, predictionsclass_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    836839\n",
      "         1.0       0.92      1.00      0.96       386\n",
      "\n",
      "    accuracy                           1.00    837225\n",
      "   macro avg       0.96      1.00      0.98    837225\n",
      "weighted avg       1.00      1.00      1.00    837225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(label_test_flat, predictionsclass)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999985708308815"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AuC for each class\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(label_test_flat, predictions_test, multi_class='ovr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Positive Class (Label 1): 0.999985708308815\n"
     ]
    }
   ],
   "source": [
    "auc_score = roc_auc_score(label_test_flat, predictions_test)\n",
    "\n",
    "print(\"AUC Score for Positive Class (Label 1):\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Label 0: 0.999985708308815\n"
     ]
    }
   ],
   "source": [
    "predictions_label_0 = 1 - predictions_test\n",
    "labels_label_0 = 1 - label_test_flat\n",
    "\n",
    "# Calculate AUC score for label = 0\n",
    "auc_score_label_0 = roc_auc_score(labels_label_0, predictions_label_0)\n",
    "\n",
    "print(\"AUC Score for Label 0:\", auc_score_label_0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
