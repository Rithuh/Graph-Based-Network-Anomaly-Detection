{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop = ['srcip', 'sport', 'dstip', 'dsport','sloss', 'dloss','stcpb', 'dtcpb', 'trans_depth', 'Stime', 'Ltime','ct_flw_http_mthd', \n",
    "        'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ ltm',\n",
    "        'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'attack_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['proto', 'state', 'dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'service', 'Sload', 'Dload',\n",
    "       'Spkts', 'Dpkts', 'swin', 'dwin', 'smeansz',\n",
    "       'dmeansz',  'res_bdy_len', 'Sjit', 'Djit', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack', 'ackdat',\n",
    "       'ct_state_ttl','Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'D:\\Project Phase II\\Dataset\\finaltrain.csv',encoding='cp1252')\n",
    "test = pd.read_csv(r'D:\\Project Phase II\\Dataset\\finaltest.csv',encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Attack:  40502  Non attack:  40502 Total:  81004\n",
      "Testing set:\n",
      "Attack:  17358  Non attack:  17358 Total:  34716\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "print('Attack: ', len(train[train['Label'] == 0]), ' Non attack: ', len(train[train['Label'] == 0]), 'Total: ', len(train))\n",
    "print(\"Testing set:\")\n",
    "print('Attack: ', len(test[test['Label'] == 0]), ' Non attack: ', len(test[test['Label'] == 0]), 'Total: ', len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract edge features alone from train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop = ['srcip', 'sport', 'dstip', 'dsport','sloss', 'dloss','stcpb', 'dtcpb', 'trans_depth', 'Stime', 'Ltime','ct_flw_http_mthd', \n",
    "        'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ ltm',\n",
    "        'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'attack_cat', 'Label']\n",
    "\n",
    "trainAttributes = train.drop(todrop, axis = 1)\n",
    "testAttributes = test.drop(todrop, axis = 1)\n",
    "\n",
    "trainLabel = train['Label']\n",
    "testLabel = test['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use LDA to reduce dimension to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components = 1)\n",
    "lda_x_train = lda.fit_transform(trainAttributes, trainLabel)\n",
    "lda_x_test = lda.transform(testAttributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute nodes and edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider only 7000 train records since memory becomes high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train.head(3500), train.tail(3500)])\n",
    "lda_x_train = np.concatenate((lda_x_train[:3500], lda_x_train[len(lda_x_train)-3500:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = set()\n",
    "edges = set()\n",
    "for i in range(7000):\n",
    "    src = str(train['srcip'].iloc[i])+':'+str(train['sport'].iloc[i])\n",
    "    dst = str(train['dstip'].iloc[i])+':'+str(train['dsport'].iloc[i])\n",
    "    nodes.add(src)\n",
    "    nodes.add(dst)\n",
    "    edges.add((src,dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8963"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_14840\\3664507687.py:13: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  adjacency_matrix[src_index, dst_index] = lda_x_train[i]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Prepare an adjacency matrix of the nodes\n",
    "adjacency_matrix = np.zeros((len(nodes), len(nodes)), dtype=float)\n",
    "label_matrix = np.zeros((len(nodes), len(nodes)))\n",
    "\n",
    "\n",
    "# Add the columns srcip:sport and dstip:dsport to the adjacency matrix\n",
    "for i in range(7000):\n",
    "    src = str(train['srcip'].iloc[i])+':'+str(train['sport'].iloc[i])\n",
    "    dst = str(train['dstip'].iloc[i])+':'+str(train['dsport'].iloc[i])\n",
    "    src_index = list(nodes).index(src)\n",
    "    dst_index = list(nodes).index(dst)\n",
    "    adjacency_matrix[src_index, dst_index] = lda_x_train[i]\n",
    "    label_matrix[src_index, dst_index] = train['Label'].iloc[i]\n",
    "# Flatten tuple values in the adjacency matrix\n",
    "adjacency_matrix_flat = adjacency_matrix.reshape(-1, 1)\n",
    "label_flat = label_matrix.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider only 5000 records for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([test.head(2500), test.tail(2500)])\n",
    "lda_x_test = np.concatenate((lda_x_test[:2500], lda_x_test[len(lda_x_test)-2500:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenodes = set()\n",
    "teedges = set()\n",
    "for i in range(len(test)):\n",
    "    src = str(test['srcip'].iloc[i])+':'+str(test['sport'].iloc[i])\n",
    "    dst = str(test['dstip'].iloc[i])+':'+str(test['dsport'].iloc[i])\n",
    "    tenodes.add(src)\n",
    "    tenodes.add(dst)\n",
    "    teedges.add((src,dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_14840\\4001184087.py:13: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  adjacency_matrix_test[src_index, dst_index] = lda_x_test[i]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Prepare an adjacency matrix of the nodes\n",
    "adjacency_matrix_test = np.zeros((len(tenodes), len(tenodes)), dtype=float)\n",
    "label_matrix_test = np.zeros((len(tenodes), len(tenodes)))\n",
    "\n",
    "\n",
    "# Add the columns srcip:sport and dstip:dsport to the adjacency matrix\n",
    "for i in range(len(test)):\n",
    "    src = str(test['srcip'].iloc[i])+':'+str(test['sport'].iloc[i])\n",
    "    dst = str(test['dstip'].iloc[i])+':'+str(test['dsport'].iloc[i])\n",
    "    src_index = list(tenodes).index(src)\n",
    "    dst_index = list(tenodes).index(dst)\n",
    "    adjacency_matrix_test[src_index, dst_index] = lda_x_test[i]\n",
    "    label_matrix_test[src_index, dst_index] = test['Label'].iloc[i]\n",
    "# Flatten tuple values in the adjacency matrix\n",
    "adjacency_matrix_test_flat = adjacency_matrix_test.reshape(-1, 1)\n",
    "label_test_flat = label_matrix_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sathi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sathi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sathi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From C:\\Users\\sathi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sathi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2008385/2008385 [==============================] - 6828s 3ms/step - loss: 1.0093e-04 - accuracy: 1.0000 - val_loss: 1.5123e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "2008385/2008385 [==============================] - 6704s 3ms/step - loss: 1.3081e-05 - accuracy: 1.0000 - val_loss: 1.3967e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "# Hyperparameters\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Modify the call method of the LSTMClassifier\n",
    "class LSTMClassifier(tf.keras.Model):\n",
    "    def __init__(self, input_shape, hidden_units, output_units):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = LSTM(hidden_units, return_sequences=False)  # Set return_sequences=False since we only need the output at the last timestep\n",
    "        self.dense = Dense(output_units, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.expand_dims(inputs, axis=-1)  # Add a new dimension to represent the input features\n",
    "        x = self.lstm(x)\n",
    "        output = self.dense(x)\n",
    "        return output\n",
    "    \n",
    "\n",
    "# Hyperparameters\n",
    "input_shape = adjacency_matrix_flat.shape[1:]  # Assuming each tuple has 2 attributes\n",
    "hidden_units = 16\n",
    "output_units = 1  # Binary classification\n",
    "\n",
    "# Convert adjacency_matrix_flat to a TensorFlow tensor\n",
    "adjacency_tensor = tf.convert_to_tensor(adjacency_matrix_flat, dtype=tf.float32)\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "lstmmodel = LSTMClassifier(input_shape, hidden_units, output_units)\n",
    "lstmmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lstmhistory = lstmmodel.fit(adjacency_tensor, label_flat, epochs=2, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmmodel.save_weights(\"lstmfinalldaweights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sathi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sathi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From C:\\Users\\sathi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sathi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6931 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6920 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "# Hyperparameters\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Modify the call method of the LSTMClassifier\n",
    "class LSTMClassifier(tf.keras.Model):\n",
    "    def __init__(self, input_shape, hidden_units, output_units):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = LSTM(hidden_units, return_sequences=False)  # Set return_sequences=False since we only need the output at the last timestep\n",
    "        self.dense = Dense(output_units, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.expand_dims(inputs, axis=-1)  # Add a new dimension to represent the input features\n",
    "        x = self.lstm(x)\n",
    "        output = self.dense(x)\n",
    "        return output\n",
    "    \n",
    "input_shape = adjacency_matrix_flat.shape[1:]  # Assuming each tuple has 2 attributes\n",
    "hidden_units = 16\n",
    "output_units = 1  # Binary classification\n",
    "# Initialize model, optimizer, and loss function\n",
    "lstmmodel = LSTMClassifier(input_shape, hidden_units, output_units)\n",
    "\n",
    "dummy_input = np.zeros((4, 4), dtype=float)\n",
    "dummy_label = np.zeros((4, 4))\n",
    "#Use dummy data to initialize the model\n",
    "dummy_flat = dummy_input.reshape(-1, 1)\n",
    "dummy_label_flat = dummy_label.reshape(-1, 1) \n",
    "\n",
    "lstmmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "lstmhistory = lstmmodel.fit(dummy_flat, dummy_label_flat, epochs=2, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved weights\n",
    "lstmmodel.load_weights(\"lstmfinalldaweights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350547/1350547 [==============================] - 2952s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "lstmpredictions = lstmmodel.predict(adjacency_matrix_test_flat)\n",
    "lstmpredictions = (lstmpredictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for LSTM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00  43214979\n",
      "         1.0       0.98      0.99      0.99      2497\n",
      "\n",
      "    accuracy                           1.00  43217476\n",
      "   macro avg       0.99      1.00      0.99  43217476\n",
      "weighted avg       1.00      1.00      1.00  43217476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(label_test_flat, lstmpredictions)\n",
    "\n",
    "print(\"Classification Report for LSTM:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test lstm with author's test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "autest = pd.read_csv(r'D:\\Project Phase II\\Dataset\\UNSW_NB15_testing-set.csv',encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "autestdrop = ['ï»¿id', 'rate', 'sloss', 'dloss','stcpb', 'dtcpb','trans_depth','ct_srv_src','ct_dst_ltm',\n",
    "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
    "       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n",
    "       'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat']\n",
    "\n",
    "\n",
    "autest = autest.drop(autestdrop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change column names of autest\n",
    "autest.rename(columns={'dinpkt':'Dintpkt','djit':'Djit','dload':'Dload','dpkts':'Dpkts','label':'Label','sinpkt':'Sintpkt','sjit':'Sjit', 'sload':'Sload', 'spkts':'Spkts','dmean':'dmeansz','response_body_len':'res_bdy_len', 'smean':'smeansz'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "autest = autest[(autest['proto']=='tcp') | (autest['proto']=='udp') | (autest['proto']=='ospf')]\n",
    "autest = autest[(autest['service']=='ssh') | (autest['service']=='ftp-data ')  | (autest['service']=='ftp') | (autest['service']=='-') | (autest['service']=='dns') | (autest['service']=='smtp') | (autest['service']=='http') | (autest['service']=='radius') | (autest['service']=='pop3') ]\n",
    "autest = autest[(autest['state'] == 'CON') | (autest['state'] == 'RST') | (autest['state'] == 'FIN') | (autest['state'] == 'ACC') | (autest['state'] == 'REQ') | (autest['state'] == 'INT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "autest['proto'].replace(\"tcp\", 0, inplace = True)\n",
    "autest['proto'].replace(\"udp\", 1, inplace = True)\n",
    "autest['proto'].replace(\"ospf\", 2, inplace = True)\n",
    "\n",
    "autest['service'].replace(\"ssh\", 0, inplace = True)\n",
    "autest['service'].replace(\"ftp-data\", 1, inplace = True)\n",
    "autest['service'].replace(\"ftp\", 2, inplace = True)\n",
    "autest['service'].replace(\"-\", 3, inplace = True)\n",
    "autest['service'].replace(\"dns\", 4, inplace = True)\n",
    "autest['service'].replace(\"smtp\", 5, inplace = True)\n",
    "autest['service'].replace(\"http\", 6, inplace = True)\n",
    "autest['service'].replace(\"radius\", 7, inplace = True)\n",
    "autest['service'].replace(\"pop3\", 8, inplace = True)\n",
    "\n",
    "autest['state'].replace(\"CON\", 0, inplace = True)\n",
    "autest['state'].replace(\"RST\", 1, inplace = True)\n",
    "autest['state'].replace(\"FIN\", 2, inplace = True)\n",
    "autest['state'].replace(\"ACC\", 3, inplace = True)\n",
    "autest['state'].replace(\"REQ\", 4, inplace = True)\n",
    "autest['state'].replace(\"INT\", 5, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in autest.columns:\n",
    "    if column != 'Label':\n",
    "        col_mean = sum(autest[column]) / len(autest[column])\n",
    "        col_std = (sum((x - col_mean) ** 2 for x in autest[column]) / len(autest[column])) ** 0.5\n",
    "        autest[column] = [(x - col_mean) / col_std for x in autest[column]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "autest = autest.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m autestAttributes \u001b[38;5;241m=\u001b[39m autestAttributes[trainAttributes\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[0;32m      3\u001b[0m autestLabel \u001b[38;5;241m=\u001b[39m autest[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m lda_x_autest \u001b[38;5;241m=\u001b[39m lda\u001b[38;5;241m.\u001b[39mtransform(autestAttributes)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lda' is not defined"
     ]
    }
   ],
   "source": [
    "autestAttributes = autest.drop(['Label'], axis = 1)\n",
    "autestAttributes = autestAttributes[trainAttributes.columns]\n",
    "autestLabel = autest['Label']\n",
    "lda_x_autest = lda.transform(autestAttributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_14840\\2740835615.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  adjacency_matrix_autest[i, j] = lda_x_autest[counter]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Prepare an adjacency matrix of the nodes\n",
    "autestlen = int(len(autest) ** 0.5)\n",
    "adjacency_matrix_autest = np.zeros((autestlen, autestlen), dtype=float)\n",
    "label_matrix_autest = np.zeros((autestlen, autestlen))\n",
    "counter = 0\n",
    "\n",
    "\n",
    "# Add the columns srcip:sport and dstip:dsport to the adjacency matrix\n",
    "for i in range(autestlen):\n",
    "    for j in range(autestlen):\n",
    "        adjacency_matrix_autest[i, j] = lda_x_autest[counter]\n",
    "        label_matrix_autest[i, j] = autest['Label'].iloc[counter]\n",
    "        counter += 1\n",
    "# Flatten tuple values in the adjacency matrix\n",
    "adjacency_matrix_autest_flat = adjacency_matrix_autest.reshape(-1, 1)\n",
    "label_autest_flat = label_matrix_autest.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392/1392 [==============================] - 11s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "lstmpredictions = lstmmodel.predict(adjacency_matrix_autest_flat)\n",
    "lstmpredictions = (lstmpredictions >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    29673\n",
       "1    14973\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autest.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: 0, Count: 44178\n",
      "Value: 1, Count: 343\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(lstmpredictions, return_counts=True)\n",
    "\n",
    "# Display the unique values and their counts\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Value: {value}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for LSTM using Author's test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.99      0.79     29548\n",
      "         1.0       0.05      0.00      0.00     14973\n",
      "\n",
      "    accuracy                           0.66     44521\n",
      "   macro avg       0.36      0.50      0.40     44521\n",
      "weighted avg       0.46      0.66      0.53     44521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(label_autest_flat, lstmpredictions)\n",
    "\n",
    "print(\"Classification Report for LSTM using Author's test set:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is down bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "\n",
    "# Modify the call method of the GRUClassifier\n",
    "class GRUClassifier(tf.keras.Model):\n",
    "    def __init__(self, input_shape, hidden_units, output_units):\n",
    "        super(GRUClassifier, self).__init__()\n",
    "        self.gru = GRU(hidden_units, return_sequences=False)  # Set return_sequences=False since we only need the output at the last timestep\n",
    "        self.dense = Dense(output_units, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.expand_dims(inputs, axis=-1)  # Add a new dimension to represent the input features\n",
    "        x = self.gru(x)\n",
    "        output = self.dense(x)\n",
    "        return output\n",
    "\n",
    "# Hyperparameters\n",
    "input_shape = adjacency_matrix_flat.shape[1:]  # Assuming each tuple has 2 attributes\n",
    "hidden_units = 16\n",
    "output_units = 1  # Binary classification\n",
    "\n",
    "grumodel = GRUClassifier(input_shape, hidden_units, output_units)\n",
    "\n",
    "\n",
    "grumodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "gruhistory = grumodel.fit(adjacency_tensor, label_flat, epochs=2, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Convert adjacency_matrix_flat to a TensorFlow tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grumodel.save_weights(\"grufinalldaweights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupredictions = grumodel.predict(adjacency_matrix_test_flat)\n",
    "grupredictions = (grupredictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(label_test_flat, grupredictions)\n",
    "\n",
    "print(\"Classification Report for GRU:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out baseline models with the same datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of classifiers to include\n",
    "import sklearn\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import sklearn.discriminant_analysis\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "#Skip SVM\n",
    "classifiers = [\n",
    "    ('AdaBoostClassifier', sklearn.ensemble.AdaBoostClassifier),\n",
    "    ('BaggingClassifier', sklearn.ensemble.BaggingClassifier),\n",
    "    ('BernoulliNB', sklearn.naive_bayes.BernoulliNB),\n",
    "    ('DecisionTreeClassifier', sklearn.tree.DecisionTreeClassifier),\n",
    "    ('DummyClassifier', sklearn.dummy.DummyClassifier),\n",
    "    ('GaussianNB', sklearn.naive_bayes.GaussianNB),\n",
    "    ('KNeighborsClassifier',  sklearn.neighbors.KNeighborsClassifier),\n",
    "    ('LinearDiscriminantAnalysis',  sklearn.discriminant_analysis.LinearDiscriminantAnalysis),\n",
    "    ('LogisticRegression', sklearn.linear_model.LogisticRegression),\n",
    "    ('Perceptron', sklearn.linear_model.Perceptron),\n",
    "    ('QuadraticDiscriminantAnalysis',  sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis),\n",
    "    ('RandomForestClassifier', sklearn.ensemble.RandomForestClassifier),\n",
    "    ('StackingClassifier', sklearn.ensemble.StackingClassifier),\n",
    "    ('XGBClassifier', xgboost.XGBClassifier),\n",
    "    ('LGBMClassifier', lightgbm.LGBMClassifier)\n",
    "]\n",
    "\n",
    "clf = LazyClassifier(verbose=1,ignore_warnings=True, custom_metric=None,classifiers=classifiers,predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34716, 34716)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testAttributes), len(testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tuple' object has no attribute '__name__'\n",
      "Invalid Classifier(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:10<02:20, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostClassifier', 'Accuracy': 0.9923090217767024, 'Balanced Accuracy': 0.9923090217767023, 'ROC AUC': 0.9923090217767024, 'F1 Score': 0.9923086002624436, 'Time taken': 10.04209017753601}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:20<01:06,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BaggingClassifier', 'Accuracy': 0.9927699043668625, 'Balanced Accuracy': 0.9927699043668625, 'ROC AUC': 0.9927699043668625, 'F1 Score': 0.9927697527009295, 'Time taken': 10.1019868850708}\n",
      "{'Model': 'BernoulliNB', 'Accuracy': 0.9578292430003457, 'Balanced Accuracy': 0.9578292430003457, 'ROC AUC': 0.9578292430003457, 'F1 Score': 0.9577980384976114, 'Time taken': 0.1698317527770996}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [00:21<00:25,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DecisionTreeClassifier', 'Accuracy': 0.988391519760341, 'Balanced Accuracy': 0.988391519760341, 'ROC AUC': 0.988391519760341, 'F1 Score': 0.9883915162831916, 'Time taken': 1.3259849548339844}\n",
      "{'Model': 'DummyClassifier', 'Accuracy': 0.5, 'Balanced Accuracy': 0.5, 'ROC AUC': 0.5, 'F1 Score': 0.3333333333333333, 'Time taken': 0.14907026290893555}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [00:22<00:15,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GaussianNB', 'Accuracy': 0.9806717363751585, 'Balanced Accuracy': 0.9806717363751585, 'ROC AUC': 0.9806717363751584, 'F1 Score': 0.9806682680699299, 'Time taken': 0.20907211303710938}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [00:30<00:32,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'KNeighborsClassifier', 'Accuracy': 0.9925106579098975, 'Balanced Accuracy': 0.9925106579098975, 'ROC AUC': 0.9925106579098975, 'F1 Score': 0.9925103992913666, 'Time taken': 8.876134872436523}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [00:31<00:20,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LinearDiscriminantAnalysis', 'Accuracy': 0.9890828436455813, 'Balanced Accuracy': 0.9890828436455813, 'ROC AUC': 0.9890828436455813, 'F1 Score': 0.9890825062198392, 'Time taken': 0.3450310230255127}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [00:31<00:13,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LogisticRegression', 'Accuracy': 0.9915888927295772, 'Balanced Accuracy': 0.9915888927295772, 'ROC AUC': 0.9915888927295771, 'F1 Score': 0.9915884424476723, 'Time taken': 0.6943261623382568}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [00:32<00:08,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Perceptron', 'Accuracy': 0.9891980642931213, 'Balanced Accuracy': 0.9891980642931213, 'ROC AUC': 0.9891980642931214, 'F1 Score': 0.9891977373124287, 'Time taken': 0.2919578552246094}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [00:32<00:04,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'QuadraticDiscriminantAnalysis', 'Accuracy': 0.9901198294734417, 'Balanced Accuracy': 0.9901198294734417, 'ROC AUC': 0.9901198294734417, 'F1 Score': 0.9901191447252966, 'Time taken': 0.24010252952575684}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [00:52<00:20,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RandomForestClassifier', 'Accuracy': 0.9934324230902177, 'Balanced Accuracy': 0.9934324230902178, 'ROC AUC': 0.9934324230902178, 'F1 Score': 0.9934322304822528, 'Time taken': 19.548397541046143}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [00:52<00:03,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'XGBClassifier', 'Accuracy': 0.9934612282521028, 'Balanced Accuracy': 0.9934612282521028, 'ROC AUC': 0.9934612282521027, 'F1 Score': 0.9934610219423573, 'Time taken': 0.872687578201294}\n",
      "[LightGBM] [Info] Number of positive: 40502, number of negative: 40502\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4392\n",
      "[LightGBM] [Info] Number of data points in the train set: 81004, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:54<00:00,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LGBMClassifier', 'Accuracy': 0.9934612282521028, 'Balanced Accuracy': 0.9934612282521027, 'ROC AUC': 0.9934612282521028, 'F1 Score': 0.993461017688523, 'Time taken': 2.0775115489959717}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "# Execute the code block\n",
    "models, predictions = clf.fit(trainAttributes,  testAttributes, trainLabel, testLabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     17358\n",
      "           1       0.99      1.00      0.99     17358\n",
      "\n",
      "    accuracy                           0.99     34716\n",
      "   macro avg       0.99      0.99      0.99     34716\n",
      "weighted avg       0.99      0.99      0.99     34716\n",
      "\n",
      "AUC Scores for each class: 0.9923090217767024\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "BaggingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     17358\n",
      "           1       0.99      1.00      0.99     17358\n",
      "\n",
      "    accuracy                           0.99     34716\n",
      "   macro avg       0.99      0.99      0.99     34716\n",
      "weighted avg       0.99      0.99      0.99     34716\n",
      "\n",
      "AUC Scores for each class: 0.9927699043668625\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "BernoulliNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     17358\n",
      "           1       0.98      0.93      0.96     17358\n",
      "\n",
      "    accuracy                           0.96     34716\n",
      "   macro avg       0.96      0.96      0.96     34716\n",
      "weighted avg       0.96      0.96      0.96     34716\n",
      "\n",
      "AUC Scores for each class: 0.9578292430003457\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     17358\n",
      "           1       0.99      0.99      0.99     17358\n",
      "\n",
      "    accuracy                           0.99     34716\n",
      "   macro avg       0.99      0.99      0.99     34716\n",
      "weighted avg       0.99      0.99      0.99     34716\n",
      "\n",
      "AUC Scores for each class: 0.988391519760341\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "DummyClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     17358\n",
      "           1       0.00      0.00      0.00     17358\n",
      "\n",
      "    accuracy                           0.50     34716\n",
      "   macro avg       0.25      0.50      0.33     34716\n",
      "weighted avg       0.25      0.50      0.33     34716\n",
      "\n",
      "AUC Scores for each class: 0.5\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     17358\n",
      "           1       0.97      0.99      0.98     17358\n",
      "\n",
      "    accuracy                           0.98     34716\n",
      "   macro avg       0.98      0.98      0.98     34716\n",
      "weighted avg       0.98      0.98      0.98     34716\n",
      "\n",
      "AUC Scores for each class: 0.9806717363751584\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     17358\n",
      "           1       0.99      1.00      0.99     17358\n",
      "\n",
      "    accuracy                           0.99     34716\n",
      "   macro avg       0.99      0.99      0.99     34716\n",
      "weighted avg       0.99      0.99      0.99     34716\n",
      "\n",
      "AUC Scores for each class: 0.9925106579098975\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "LinearDiscriminantAnalysis\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     17358\n",
      "           1       0.98      0.99      0.99     17358\n",
      "\n",
      "    accuracy                           0.99     34716\n",
      "   macro avg       0.99      0.99      0.99     34716\n",
      "weighted avg       0.99      0.99      0.99     34716\n",
      "\n",
      "AUC Scores for each class: 0.9890828436455813\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     17358\n",
      "           1       0.98      1.00      0.99     17358\n",
      "\n",
      "    accuracy                           0.99     34716\n",
      "   macro avg       0.99      0.99      0.99     34716\n",
      "weighted avg       0.99      0.99      0.99     34716\n",
      "\n",
      "AUC Scores for each class: 0.9915888927295771\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "Perceptron\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     17358\n",
      "           1       0.98      0.99      0.99     17358\n",
      "\n",
      "    accuracy                           0.99     34716\n",
      "   macro avg       0.99      0.99      0.99     34716\n",
      "weighted avg       0.99      0.99      0.99     34716\n",
      "\n",
      "AUC Scores for each class: 0.9891980642931214\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "QuadraticDiscriminantAnalysis\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     17358\n",
      "           1       0.98      1.00      0.99     17358\n",
      "\n",
      "    accuracy                           0.99     34716\n",
      "   macro avg       0.99      0.99      0.99     34716\n",
      "weighted avg       0.99      0.99      0.99     34716\n",
      "\n",
      "AUC Scores for each class: 0.9901198294734417\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     17358\n",
      "           1       0.99      1.00      0.99     17358\n",
      "\n",
      "    accuracy                           0.99     34716\n",
      "   macro avg       0.99      0.99      0.99     34716\n",
      "weighted avg       0.99      0.99      0.99     34716\n",
      "\n",
      "AUC Scores for each class: 0.9934324230902178\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "XGBClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     17358\n",
      "           1       0.99      1.00      0.99     17358\n",
      "\n",
      "    accuracy                           0.99     34716\n",
      "   macro avg       0.99      0.99      0.99     34716\n",
      "weighted avg       0.99      0.99      0.99     34716\n",
      "\n",
      "AUC Scores for each class: 0.9934612282521027\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "LGBMClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     17358\n",
      "           1       0.99      1.00      0.99     17358\n",
      "\n",
      "    accuracy                           0.99     34716\n",
      "   macro avg       0.99      0.99      0.99     34716\n",
      "weighted avg       0.99      0.99      0.99     34716\n",
      "\n",
      "AUC Scores for each class: 0.9934612282521028\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "for model in predictions.columns:\n",
    "    print(model)\n",
    "    print(classification_report(testLabel, predictions[model]))\n",
    "    auc_scores = roc_auc_score(testLabel, predictions[model], multi_class='ovr')  # Or multi_class='ovo' for one-vs-one\n",
    "    print(\"AUC Scores for each class:\", auc_scores)\n",
    "    print('-----------------------------------------------------------------------------------')\n",
    "    print('-----------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of classifiers to include\n",
    "import sklearn\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import sklearn.discriminant_analysis\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "#Skip SVM\n",
    "classifiers = [\n",
    " ('AdaBoostClassifier', sklearn.ensemble._weight_boosting.AdaBoostClassifier),\n",
    " ('BaggingClassifier', sklearn.ensemble._bagging.BaggingClassifier),\n",
    " ('BernoulliNB', sklearn.naive_bayes.BernoulliNB),\n",
    " ('DecisionTreeClassifier', sklearn.tree._classes.DecisionTreeClassifier),\n",
    " ('DummyClassifier', sklearn.dummy.DummyClassifier),\n",
    " ('GaussianNB', sklearn.naive_bayes.GaussianNB),\n",
    " ('KNeighborsClassifier',  sklearn.neighbors._classification.KNeighborsClassifier),\n",
    " ('LinearDiscriminantAnalysis',  sklearn.discriminant_analysis.LinearDiscriminantAnalysis),\n",
    " ('LogisticRegression', sklearn.linear_model._logistic.LogisticRegression),\n",
    " ('Perceptron', sklearn.linear_model._perceptron.Perceptron),\n",
    " ('QuadraticDiscriminantAnalysis',  sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis),\n",
    " ('RandomForestClassifier', sklearn.ensemble._forest.RandomForestClassifier),\n",
    " ('StackingClassifier', sklearn.ensemble._stacking.StackingClassifier),\n",
    " ('XGBClassifier', xgboost.sklearn.XGBClassifier),\n",
    " ('LGBMClassifier', lightgbm.sklearn.LGBMClassifier)]\n",
    "clf = LazyClassifier(verbose=1,ignore_warnings=True, custom_metric=None,classifiers=classifiers,predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tuple' object has no attribute '__name__'\n",
      "Invalid Classifier(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:10<02:32, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostClassifier', 'Accuracy': 0.6479863817587241, 'Balanced Accuracy': 0.6508268315380992, 'ROC AUC': 0.6508268315380992, 'F1 Score': 0.6573292986953801, 'Time taken': 10.917290210723877}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:24<02:43, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BaggingClassifier', 'Accuracy': 0.6479863817587241, 'Balanced Accuracy': 0.6508268315380992, 'ROC AUC': 0.6508268315380992, 'F1 Score': 0.6573292986953801, 'Time taken': 13.720137596130371}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:25<01:23,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BernoulliNB', 'Accuracy': 0.6435514939748241, 'Balanced Accuracy': 0.48480555871056225, 'ROC AUC': 0.48480555871056225, 'F1 Score': 0.5220059637540395, 'Time taken': 0.3721601963043213}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [00:26<00:54,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DecisionTreeClassifier', 'Accuracy': 0.6479863817587241, 'Balanced Accuracy': 0.6508268315380992, 'ROC AUC': 0.6508268315380992, 'F1 Score': 0.6573292986953801, 'Time taken': 1.7805242538452148}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [00:27<00:32,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DummyClassifier', 'Accuracy': 0.6646284101599247, 'Balanced Accuracy': 0.5, 'ROC AUC': 0.5, 'F1 Score': 0.5307261619417766, 'Time taken': 0.2160952091217041}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [00:27<00:20,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GaussianNB', 'Accuracy': 0.6612910451104242, 'Balanced Accuracy': 0.505711223821657, 'ROC AUC': 0.505711223821657, 'F1 Score': 0.5479663117789038, 'Time taken': 0.3502204418182373}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [00:44<00:56,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'KNeighborsClassifier', 'Accuracy': 0.6628589347309949, 'Balanced Accuracy': 0.5122837999174641, 'ROC AUC': 0.5122837999174641, 'F1 Score': 0.5598802062969052, 'Time taken': 17.066572666168213}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [00:44<00:34,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LinearDiscriminantAnalysis', 'Accuracy': 0.6646956054293778, 'Balanced Accuracy': 0.5001498096432034, 'ROC AUC': 0.5001498096432034, 'F1 Score': 0.5310053960773934, 'Time taken': 0.4419279098510742}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [00:45<00:22,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LogisticRegression', 'Accuracy': 0.667383416207499, 'Balanced Accuracy': 0.5041570226265736, 'ROC AUC': 0.5041570226265735, 'F1 Score': 0.5371914151920912, 'Time taken': 1.0497419834136963}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [00:46<00:13,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Perceptron', 'Accuracy': 0.6665546745509117, 'Balanced Accuracy': 0.502904922183828, 'ROC AUC': 0.502904922183828, 'F1 Score': 0.5352524020153651, 'Time taken': 0.5434849262237549}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [00:46<00:08,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'QuadraticDiscriminantAnalysis', 'Accuracy': 0.6646284101599247, 'Balanced Accuracy': 0.5, 'ROC AUC': 0.5, 'F1 Score': 0.5307261619417766, 'Time taken': 0.38330578804016113}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [01:12<00:27,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RandomForestClassifier', 'Accuracy': 0.6782018545894369, 'Balanced Accuracy': 0.5605188891786296, 'ROC AUC': 0.5605188891786296, 'F1 Score': 0.6256727936623417, 'Time taken': 25.623571395874023}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [01:14<00:05,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'XGBClassifier', 'Accuracy': 0.6462169063297943, 'Balanced Accuracy': 0.6391065843500608, 'ROC AUC': 0.6391065843500608, 'F1 Score': 0.6546524492172303, 'Time taken': 1.8930308818817139}\n",
      "[LightGBM] [Info] Number of positive: 40502, number of negative: 40502\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4392\n",
      "[LightGBM] [Info] Number of data points in the train set: 81004, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:16<00:00,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LGBMClassifier', 'Accuracy': 0.6479863817587241, 'Balanced Accuracy': 0.6508268315380992, 'ROC AUC': 0.6508268315380992, 'F1 Score': 0.6573292986953801, 'Time taken': 1.9653925895690918}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models, predictions = clf.fit(trainAttributes,  autestAttributes, trainLabel, autestLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71     29673\n",
      "           1       0.48      0.66      0.56     14973\n",
      "\n",
      "    accuracy                           0.65     44646\n",
      "   macro avg       0.64      0.65      0.63     44646\n",
      "weighted avg       0.69      0.65      0.66     44646\n",
      "\n",
      "AUC Scores for each class: 0.6508268315380992\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "BaggingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71     29673\n",
      "           1       0.48      0.66      0.56     14973\n",
      "\n",
      "    accuracy                           0.65     44646\n",
      "   macro avg       0.64      0.65      0.63     44646\n",
      "weighted avg       0.69      0.65      0.66     44646\n",
      "\n",
      "AUC Scores for each class: 0.6508268315380992\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "BernoulliNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.97      0.78     29673\n",
      "           1       0.04      0.00      0.01     14973\n",
      "\n",
      "    accuracy                           0.64     44646\n",
      "   macro avg       0.35      0.48      0.39     44646\n",
      "weighted avg       0.45      0.64      0.52     44646\n",
      "\n",
      "AUC Scores for each class: 0.48480555871056225\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71     29673\n",
      "           1       0.48      0.66      0.56     14973\n",
      "\n",
      "    accuracy                           0.65     44646\n",
      "   macro avg       0.64      0.65      0.63     44646\n",
      "weighted avg       0.69      0.65      0.66     44646\n",
      "\n",
      "AUC Scores for each class: 0.6508268315380992\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "DummyClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80     29673\n",
      "           1       0.00      0.00      0.00     14973\n",
      "\n",
      "    accuracy                           0.66     44646\n",
      "   macro avg       0.33      0.50      0.40     44646\n",
      "weighted avg       0.44      0.66      0.53     44646\n",
      "\n",
      "AUC Scores for each class: 0.5\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.79     29673\n",
      "           1       0.43      0.03      0.06     14973\n",
      "\n",
      "    accuracy                           0.66     44646\n",
      "   macro avg       0.55      0.51      0.43     44646\n",
      "weighted avg       0.59      0.66      0.55     44646\n",
      "\n",
      "AUC Scores for each class: 0.505711223821657\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.97      0.79     29673\n",
      "           1       0.48      0.05      0.10     14973\n",
      "\n",
      "    accuracy                           0.66     44646\n",
      "   macro avg       0.57      0.51      0.45     44646\n",
      "weighted avg       0.61      0.66      0.56     44646\n",
      "\n",
      "AUC Scores for each class: 0.5122837999174641\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "LinearDiscriminantAnalysis\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80     29673\n",
      "           1       0.67      0.00      0.00     14973\n",
      "\n",
      "    accuracy                           0.66     44646\n",
      "   macro avg       0.67      0.50      0.40     44646\n",
      "weighted avg       0.67      0.66      0.53     44646\n",
      "\n",
      "AUC Scores for each class: 0.5001498096432034\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80     29673\n",
      "           1       0.98      0.01      0.02     14973\n",
      "\n",
      "    accuracy                           0.67     44646\n",
      "   macro avg       0.82      0.50      0.41     44646\n",
      "weighted avg       0.77      0.67      0.54     44646\n",
      "\n",
      "AUC Scores for each class: 0.5041570226265735\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "Perceptron\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80     29673\n",
      "           1       0.98      0.01      0.01     14973\n",
      "\n",
      "    accuracy                           0.67     44646\n",
      "   macro avg       0.82      0.50      0.41     44646\n",
      "weighted avg       0.77      0.67      0.54     44646\n",
      "\n",
      "AUC Scores for each class: 0.502904922183828\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "QuadraticDiscriminantAnalysis\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80     29673\n",
      "           1       0.00      0.00      0.00     14973\n",
      "\n",
      "    accuracy                           0.66     44646\n",
      "   macro avg       0.33      0.50      0.40     44646\n",
      "weighted avg       0.44      0.66      0.53     44646\n",
      "\n",
      "AUC Scores for each class: 0.5\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.92      0.79     29673\n",
      "           1       0.56      0.20      0.30     14973\n",
      "\n",
      "    accuracy                           0.68     44646\n",
      "   macro avg       0.63      0.56      0.54     44646\n",
      "weighted avg       0.65      0.68      0.63     44646\n",
      "\n",
      "AUC Scores for each class: 0.5605188891786296\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "XGBClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.66      0.71     29673\n",
      "           1       0.48      0.62      0.54     14973\n",
      "\n",
      "    accuracy                           0.65     44646\n",
      "   macro avg       0.63      0.64      0.63     44646\n",
      "weighted avg       0.67      0.65      0.65     44646\n",
      "\n",
      "AUC Scores for each class: 0.6391065843500608\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "LGBMClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71     29673\n",
      "           1       0.48      0.66      0.56     14973\n",
      "\n",
      "    accuracy                           0.65     44646\n",
      "   macro avg       0.64      0.65      0.63     44646\n",
      "weighted avg       0.69      0.65      0.66     44646\n",
      "\n",
      "AUC Scores for each class: 0.6508268315380992\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "for model in predictions.columns:\n",
    "    print(model)\n",
    "    print(classification_report(autestLabel, predictions[model]))\n",
    "    auc_scores = roc_auc_score(autestLabel, predictions[model], multi_class='ovr')  # Or multi_class='ovo' for one-vs-one\n",
    "    print(\"AUC Scores for each class:\", auc_scores)\n",
    "    print('-----------------------------------------------------------------------------------')\n",
    "    print('-----------------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
