{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD STUFF IGNORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_20632\\870708999.py:1: DtypeWarning: Columns (1,3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r'D:\\Project Phase II\\Dataset\\completedataset.csv',encoding='cp1252')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.166.0.1</td>\n",
       "      <td>18247</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>7662</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.119596</td>\n",
       "      <td>4550</td>\n",
       "      <td>68342</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.166.0.3</td>\n",
       "      <td>54771</td>\n",
       "      <td>149.171.126.2</td>\n",
       "      <td>27709</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.650574</td>\n",
       "      <td>8928</td>\n",
       "      <td>320</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.166.0.8</td>\n",
       "      <td>13289</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>5190</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>2158</td>\n",
       "      <td>2464</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149.171.126.18</td>\n",
       "      <td>1043</td>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>INT</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149.171.126.18</td>\n",
       "      <td>1043</td>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>INT</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540042</th>\n",
       "      <td>59.166.0.5</td>\n",
       "      <td>33094</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>43433</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.087306</td>\n",
       "      <td>320</td>\n",
       "      <td>1828</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540043</th>\n",
       "      <td>59.166.0.7</td>\n",
       "      <td>20848</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>21</td>\n",
       "      <td>tcp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.365058</td>\n",
       "      <td>456</td>\n",
       "      <td>346</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540044</th>\n",
       "      <td>59.166.0.3</td>\n",
       "      <td>21511</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>21</td>\n",
       "      <td>tcp</td>\n",
       "      <td>CON</td>\n",
       "      <td>6.335154</td>\n",
       "      <td>1802</td>\n",
       "      <td>2088</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540045</th>\n",
       "      <td>59.166.0.9</td>\n",
       "      <td>35433</td>\n",
       "      <td>149.171.126.0</td>\n",
       "      <td>80</td>\n",
       "      <td>tcp</td>\n",
       "      <td>CON</td>\n",
       "      <td>2.200934</td>\n",
       "      <td>3498</td>\n",
       "      <td>166054</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540046</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>17293</td>\n",
       "      <td>149.171.126.17</td>\n",
       "      <td>110</td>\n",
       "      <td>tcp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.942984</td>\n",
       "      <td>574</td>\n",
       "      <td>676</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Exploits</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2540047 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  srcip  sport           dstip dsport proto state       dur  \\\n",
       "0            59.166.0.1  18247   149.171.126.4   7662   tcp   FIN  0.119596   \n",
       "1            59.166.0.3  54771   149.171.126.2  27709   tcp   FIN  0.650574   \n",
       "2            59.166.0.8  13289   149.171.126.9   5190   tcp   FIN  0.007980   \n",
       "3        149.171.126.18   1043    175.45.176.3     53   udp   INT  0.000005   \n",
       "4        149.171.126.18   1043    175.45.176.3     53   udp   INT  0.000005   \n",
       "...                 ...    ...             ...    ...   ...   ...       ...   \n",
       "2540042      59.166.0.5  33094   149.171.126.7  43433   tcp   FIN  0.087306   \n",
       "2540043      59.166.0.7  20848   149.171.126.4     21   tcp   CON  0.365058   \n",
       "2540044      59.166.0.3  21511   149.171.126.9     21   tcp   CON  6.335154   \n",
       "2540045      59.166.0.9  35433   149.171.126.0     80   tcp   CON  2.200934   \n",
       "2540046    175.45.176.0  17293  149.171.126.17    110   tcp   CON  0.942984   \n",
       "\n",
       "         sbytes  dbytes  sttl  ...  ct_ftp_cmd  ct_srv_src  ct_srv_dst  \\\n",
       "0          4550   68342    31  ...                       6           2   \n",
       "1          8928     320    31  ...                       3           5   \n",
       "2          2158    2464    31  ...                       3           5   \n",
       "3           264       0    60  ...                      19          19   \n",
       "4           264       0    60  ...                      19          19   \n",
       "...         ...     ...   ...  ...         ...         ...         ...   \n",
       "2540042     320    1828    31  ...                       1           2   \n",
       "2540043     456     346    31  ...           2           2           2   \n",
       "2540044    1802    2088    31  ...           2           2           2   \n",
       "2540045    3498  166054    31  ...                       1           1   \n",
       "2540046     574     676    62  ...                       1           1   \n",
       "\n",
       "        ct_dst_ltm  ct_src_ ltm  ct_src_dport_ltm  ct_dst_sport_ltm  \\\n",
       "0                2            5                 1                 1   \n",
       "1                2            4                 1                 1   \n",
       "2                1            1                 1                 1   \n",
       "3               19           19                19                19   \n",
       "4               19           19                19                19   \n",
       "...            ...          ...               ...               ...   \n",
       "2540042          3            3                 1                 1   \n",
       "2540043          2            2                 2                 2   \n",
       "2540044          4            2                 2                 2   \n",
       "2540045          2            4                 2                 2   \n",
       "2540046          2            4                 2                 2   \n",
       "\n",
       "         ct_dst_src_ltm  attack_cat  Label  \n",
       "0                     2         NaN      0  \n",
       "1                     4         NaN      0  \n",
       "2                     3         NaN      0  \n",
       "3                    19         NaN      0  \n",
       "4                    19         NaN      0  \n",
       "...                 ...         ...    ...  \n",
       "2540042               3         NaN      0  \n",
       "2540043               2         NaN      0  \n",
       "2540044               2         NaN      0  \n",
       "2540045               2         NaN      0  \n",
       "2540046               2    Exploits      1  \n",
       "\n",
       "[2540047 rows x 49 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\Project Phase II\\Dataset\\completedataset.csv',encoding='cp1252')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "proto      Label\n",
       "3pc        1        137\n",
       "a/n        1        137\n",
       "aes-sp3-d  1        137\n",
       "any        1        411\n",
       "argus      1        137\n",
       "                   ... \n",
       "wsn        1        137\n",
       "xnet       1        137\n",
       "xns-idp    1        137\n",
       "xtp        1        137\n",
       "zero       1        137\n",
       "Name: count, Length: 138, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "df.groupby('proto')['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proto      Label\n",
      "3pc        1        137\n",
      "a/n        1        137\n",
      "aes-sp3-d  1        137\n",
      "any        1        411\n",
      "argus      1        137\n",
      "                   ... \n",
      "wsn        1        137\n",
      "xnet       1        137\n",
      "xns-idp    1        137\n",
      "xtp        1        137\n",
      "zero       1        137\n",
      "Name: count, Length: 138, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by service, and counts with label\n",
    "df1 = df.groupby('proto')['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Cleaning dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop is_sm_ips_ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_16936\\1444029592.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(['is_sm_ips_ports'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Cleaning df by removing rows with is_sm_ips_ports = 1\n",
    "df = df[df['is_sm_ips_ports']==0]\n",
    "#Dropping is_sm_ips_ports column\n",
    "df.drop(['is_sm_ips_ports'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Exploits', ' Fuzzers ', 'DoS', 'Generic', ' Shellcode ',\n",
       "       'Backdoor', ' Reconnaissance ', 'Worms', 'Analysis',\n",
       "       'Reconnaissance', 'Shellcode', ' Fuzzers', 'Backdoors'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find out unique values in df['attack_cat']\n",
    "df['attack_cat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove trailing white spaces from the dataset\n",
    "df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Exploits', 'Fuzzers', 'DoS', 'Generic', 'Shellcode',\n",
       "       'Backdoor', 'Reconnaissance', 'Worms', 'Analysis', 'Backdoors'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['attack_cat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace 'Backdoor' with 'Backdoors'\n",
    "df['attack_cat'] = df['attack_cat'].replace('Backdoor', 'Backdoors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill NaN values with 0 for int and float columns and None for object columns\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'int64' or df[col].dtype == 'float64':\n",
    "        df[col] = df[col].fillna(0)\n",
    "    elif df[col].dtype == 'object':\n",
    "        df[col] = df[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['None', 'Exploits', 'Fuzzers', 'DoS', 'Generic', 'Shellcode',\n",
       "       'Backdoors', 'Reconnaissance', 'Worms', 'Analysis'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['attack_cat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace None in sport and dport with 0\n",
    "df['sport'] = df['sport'].replace('None', '0')\n",
    "df['dsport'] = df['dsport'].replace('None', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 4., 2.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.is_ftp_login.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert is_ftp_login to int\n",
    "df['is_ftp_login'] = df['is_ftp_login'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert all is_ftp_login values > 0 to 1\n",
    "df['is_ftp_login'] = df['is_ftp_login'].apply(lambda x: 1 if x > 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  4,  3, 19,  1,  5,  7,  6, 25, 24, 10,  9, 18, 22, 17, 32, 54,\n",
       "       15, 33, 48, 40, 37, 16, 42, 34, 39, 31, 36, 11, 30, 21, 27, 29, 35,\n",
       "       43, 59, 23, 47, 20, 14, 38, 56, 45,  8, 51, 26, 41, 28, 49, 12, 46,\n",
       "       13, 44, 53, 50, 52, 57, 58, 55, 60, 66, 61, 65, 67, 63],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ct_dst_src_ltm .unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to csv and store in a new file\n",
    "df.to_csv(r'D:\\Project Phase II\\Dataset\\phase2cleaneddataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['attack_cat'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'attack_cat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'attack_cat'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mservice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m labelencoder\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mservice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     11\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m labelencoder\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 12\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattack_cat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m labelencoder\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattack_cat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'attack_cat'"
     ]
    }
   ],
   "source": [
    "#label encoding for non numerical features\n",
    "labelencoder = LabelEncoder()\n",
    "from sklearn import preprocessing \n",
    "\n",
    "# label_encoder object knows  \n",
    "# how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "\n",
    "df['proto'] = labelencoder.fit_transform(df['proto'])\n",
    "df['service'] = labelencoder.fit_transform(df['service'])\n",
    "df['state'] = labelencoder.fit_transform(df['state'])\n",
    "df['attack_cat'] = labelencoder.fit_transform(df['attack_cat'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_20212\\128579614.py:1: DtypeWarning: Columns (1,3,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(r'D:\\Project Phase II\\Dataset\\phase2cleaneddataset.csv',encoding='cp1252')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.166.0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>7662</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.119596</td>\n",
       "      <td>4550</td>\n",
       "      <td>68342</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.166.0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.2</td>\n",
       "      <td>27709</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.650574</td>\n",
       "      <td>8928</td>\n",
       "      <td>320</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.166.0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>5190</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>2158</td>\n",
       "      <td>2464</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149.171.126.18</td>\n",
       "      <td>0</td>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>INT</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149.171.126.18</td>\n",
       "      <td>0</td>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>INT</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535847</th>\n",
       "      <td>59.166.0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.087306</td>\n",
       "      <td>320</td>\n",
       "      <td>1828</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535848</th>\n",
       "      <td>59.166.0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.365058</td>\n",
       "      <td>456</td>\n",
       "      <td>346</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535849</th>\n",
       "      <td>59.166.0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>CON</td>\n",
       "      <td>6.335154</td>\n",
       "      <td>1802</td>\n",
       "      <td>2088</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535850</th>\n",
       "      <td>59.166.0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.0</td>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>CON</td>\n",
       "      <td>2.200934</td>\n",
       "      <td>3498</td>\n",
       "      <td>166054</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535851</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.17</td>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.942984</td>\n",
       "      <td>574</td>\n",
       "      <td>676</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Exploits</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2535852 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  srcip sport           dstip dsport proto state       dur  \\\n",
       "0            59.166.0.1     0   149.171.126.4   7662   tcp   FIN  0.119596   \n",
       "1            59.166.0.3     0   149.171.126.2  27709   tcp   FIN  0.650574   \n",
       "2            59.166.0.8     0   149.171.126.9   5190   tcp   FIN  0.007980   \n",
       "3        149.171.126.18     0    175.45.176.3     53   udp   INT  0.000005   \n",
       "4        149.171.126.18     0    175.45.176.3     53   udp   INT  0.000005   \n",
       "...                 ...   ...             ...    ...   ...   ...       ...   \n",
       "2535847      59.166.0.5     0   149.171.126.7      0   tcp   FIN  0.087306   \n",
       "2535848      59.166.0.7     0   149.171.126.4      0   tcp   CON  0.365058   \n",
       "2535849      59.166.0.3     0   149.171.126.9      0   tcp   CON  6.335154   \n",
       "2535850      59.166.0.9     0   149.171.126.0      0   tcp   CON  2.200934   \n",
       "2535851    175.45.176.0     0  149.171.126.17      0   tcp   CON  0.942984   \n",
       "\n",
       "         sbytes  dbytes  sttl  ...  ct_ftp_cmd  ct_srv_src  ct_srv_dst  \\\n",
       "0          4550   68342    31  ...         NaN           6           2   \n",
       "1          8928     320    31  ...         NaN           3           5   \n",
       "2          2158    2464    31  ...         NaN           3           5   \n",
       "3           264       0    60  ...         NaN          19          19   \n",
       "4           264       0    60  ...         NaN          19          19   \n",
       "...         ...     ...   ...  ...         ...         ...         ...   \n",
       "2535847     320    1828    31  ...         NaN           1           2   \n",
       "2535848     456     346    31  ...         2.0           2           2   \n",
       "2535849    1802    2088    31  ...         2.0           2           2   \n",
       "2535850    3498  166054    31  ...         NaN           1           1   \n",
       "2535851     574     676    62  ...         NaN           1           1   \n",
       "\n",
       "        ct_dst_ltm  ct_src_ ltm  ct_src_dport_ltm  ct_dst_sport_ltm  \\\n",
       "0                2            5                 1                 1   \n",
       "1                2            4                 1                 1   \n",
       "2                1            1                 1                 1   \n",
       "3               19           19                19                19   \n",
       "4               19           19                19                19   \n",
       "...            ...          ...               ...               ...   \n",
       "2535847          3            3                 1                 1   \n",
       "2535848          2            2                 2                 2   \n",
       "2535849          4            2                 2                 2   \n",
       "2535850          2            4                 2                 2   \n",
       "2535851          2            4                 2                 2   \n",
       "\n",
       "         ct_dst_src_ltm  attack_cat  Label  \n",
       "0                     2        None      0  \n",
       "1                     4        None      0  \n",
       "2                     3        None      0  \n",
       "3                    19        None      0  \n",
       "4                    19        None      0  \n",
       "...                 ...         ...    ...  \n",
       "2535847               3        None      0  \n",
       "2535848               2        None      0  \n",
       "2535849               2        None      0  \n",
       "2535850               2        None      0  \n",
       "2535851               2    Exploits      1  \n",
       "\n",
       "[2535852 rows x 48 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(r'D:\\Project Phase II\\Dataset\\phase2cleaneddataset.csv',encoding='cp1252')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Replace '' and 'None' with 0 in ct_ftp_cmd\n",
    "df2['ct_ftp_cmd'] = df2['ct_ftp_cmd'].replace('None', '0')\n",
    "df2['ct_ftp_cmd'] = df2['ct_ftp_cmd'].replace('', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.ct_ftp_cmd.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['ct_ftp_cmd'] = df2['ct_ftp_cmd'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 4, 2, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['ct_ftp_cmd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to csv and store in a new file\n",
    "df2.to_csv(r'D:\\Project Phase II\\Dataset\\phase2cleaneddataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert ct_ftp_cmd to int\n",
    "df['ct_ftp_cmd'] = df['ct_ftp_cmd'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2535852 entries, 0 to 2540046\n",
      "Data columns (total 48 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   srcip             object \n",
      " 1   sport             object \n",
      " 2   dstip             object \n",
      " 3   dsport            object \n",
      " 4   proto             int32  \n",
      " 5   state             int32  \n",
      " 6   dur               float64\n",
      " 7   sbytes            int64  \n",
      " 8   dbytes            int64  \n",
      " 9   sttl              int64  \n",
      " 10  dttl              int64  \n",
      " 11  sloss             int64  \n",
      " 12  dloss             int64  \n",
      " 13  service           int32  \n",
      " 14  Sload             float64\n",
      " 15  Dload             float64\n",
      " 16  Spkts             int64  \n",
      " 17  Dpkts             int64  \n",
      " 18  swin              int64  \n",
      " 19  dwin              int64  \n",
      " 20  stcpb             int64  \n",
      " 21  dtcpb             int64  \n",
      " 22  smeansz           int64  \n",
      " 23  dmeansz           int64  \n",
      " 24  trans_depth       int64  \n",
      " 25  res_bdy_len       int64  \n",
      " 26  Sjit              float64\n",
      " 27  Djit              float64\n",
      " 28  Stime             int64  \n",
      " 29  Ltime             int64  \n",
      " 30  Sintpkt           float64\n",
      " 31  Dintpkt           float64\n",
      " 32  tcprtt            float64\n",
      " 33  synack            float64\n",
      " 34  ackdat            float64\n",
      " 35  ct_state_ttl      int64  \n",
      " 36  ct_flw_http_mthd  float64\n",
      " 37  is_ftp_login      int64  \n",
      " 38  ct_ftp_cmd        int32  \n",
      " 39  ct_srv_src        int64  \n",
      " 40  ct_srv_dst        int64  \n",
      " 41  ct_dst_ltm        int64  \n",
      " 42  ct_src_ ltm       int64  \n",
      " 43  ct_src_dport_ltm  int64  \n",
      " 44  ct_dst_sport_ltm  int64  \n",
      " 45  ct_dst_src_ltm    int64  \n",
      " 46  attack_cat        int32  \n",
      " 47  Label             int64  \n",
      "dtypes: float64(11), int32(5), int64(28), object(4)\n",
      "memory usage: 899.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to csv and store in a new file\n",
    "df.to_csv(r'D:\\Project Phase II\\Dataset\\phase2labelencodeddataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling in null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_2968\\201358963.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.fillna(0, inplace=True)\n",
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_2968\\201358963.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.replace('', 0, inplace=True)\n",
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_2968\\201358963.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.replace(' ', 0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Fill nullvalues\n",
    "#Filling Nan values with 0\n",
    "df.fillna(0, inplace=True)\n",
    "#Filling '' with 0\n",
    "df.replace('', 0, inplace=True)\n",
    "df.replace(' ', 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.166.0.1</td>\n",
       "      <td>18247</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>7662</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>0.119596</td>\n",
       "      <td>4550</td>\n",
       "      <td>68342</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.166.0.3</td>\n",
       "      <td>54771</td>\n",
       "      <td>149.171.126.2</td>\n",
       "      <td>27709</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>0.650574</td>\n",
       "      <td>8928</td>\n",
       "      <td>320</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.166.0.8</td>\n",
       "      <td>13289</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>5190</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>2158</td>\n",
       "      <td>2464</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149.171.126.18</td>\n",
       "      <td>1043</td>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>53</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149.171.126.18</td>\n",
       "      <td>1043</td>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>53</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540042</th>\n",
       "      <td>59.166.0.5</td>\n",
       "      <td>33094</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>43433</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>0.087306</td>\n",
       "      <td>320</td>\n",
       "      <td>1828</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540043</th>\n",
       "      <td>59.166.0.7</td>\n",
       "      <td>20848</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>21</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>0.365058</td>\n",
       "      <td>456</td>\n",
       "      <td>346</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540044</th>\n",
       "      <td>59.166.0.3</td>\n",
       "      <td>21511</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>21</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>6.335154</td>\n",
       "      <td>1802</td>\n",
       "      <td>2088</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540045</th>\n",
       "      <td>59.166.0.9</td>\n",
       "      <td>35433</td>\n",
       "      <td>149.171.126.0</td>\n",
       "      <td>80</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>2.200934</td>\n",
       "      <td>3498</td>\n",
       "      <td>166054</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540046</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>17293</td>\n",
       "      <td>149.171.126.17</td>\n",
       "      <td>110</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>0.942984</td>\n",
       "      <td>574</td>\n",
       "      <td>676</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2535852 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  srcip  sport           dstip dsport  proto  state       dur  \\\n",
       "0            59.166.0.1  18247   149.171.126.4   7662    114      5  0.119596   \n",
       "1            59.166.0.3  54771   149.171.126.2  27709    114      5  0.650574   \n",
       "2            59.166.0.8  13289   149.171.126.9   5190    114      5  0.007980   \n",
       "3        149.171.126.18   1043    175.45.176.3     53    120      6  0.000005   \n",
       "4        149.171.126.18   1043    175.45.176.3     53    120      6  0.000005   \n",
       "...                 ...    ...             ...    ...    ...    ...       ...   \n",
       "2540042      59.166.0.5  33094   149.171.126.7  43433    114      5  0.087306   \n",
       "2540043      59.166.0.7  20848   149.171.126.4     21    114      2  0.365058   \n",
       "2540044      59.166.0.3  21511   149.171.126.9     21    114      2  6.335154   \n",
       "2540045      59.166.0.9  35433   149.171.126.0     80    114      2  2.200934   \n",
       "2540046    175.45.176.0  17293  149.171.126.17    110    114      2  0.942984   \n",
       "\n",
       "         sbytes  dbytes  sttl  ...  is_ftp_login  ct_ftp_cmd  ct_srv_src  \\\n",
       "0          4550   68342    31  ...           0.0           0           6   \n",
       "1          8928     320    31  ...           0.0           0           3   \n",
       "2          2158    2464    31  ...           0.0           0           3   \n",
       "3           264       0    60  ...           0.0           0          19   \n",
       "4           264       0    60  ...           0.0           0          19   \n",
       "...         ...     ...   ...  ...           ...         ...         ...   \n",
       "2540042     320    1828    31  ...           0.0           0           1   \n",
       "2540043     456     346    31  ...           2.0           2           2   \n",
       "2540044    1802    2088    31  ...           2.0           2           2   \n",
       "2540045    3498  166054    31  ...           0.0           0           1   \n",
       "2540046     574     676    62  ...           0.0           0           1   \n",
       "\n",
       "         ct_srv_dst  ct_dst_ltm  ct_src_ ltm  ct_src_dport_ltm  \\\n",
       "0                 2           2            5                 1   \n",
       "1                 5           2            4                 1   \n",
       "2                 5           1            1                 1   \n",
       "3                19          19           19                19   \n",
       "4                19          19           19                19   \n",
       "...             ...         ...          ...               ...   \n",
       "2540042           2           3            3                 1   \n",
       "2540043           2           2            2                 2   \n",
       "2540044           2           4            2                 2   \n",
       "2540045           1           2            4                 2   \n",
       "2540046           1           2            4                 2   \n",
       "\n",
       "         ct_dst_sport_ltm  ct_dst_src_ltm  Label  \n",
       "0                       1               2      0  \n",
       "1                       1               4      0  \n",
       "2                       1               3      0  \n",
       "3                      19              19      0  \n",
       "4                      19              19      0  \n",
       "...                   ...             ...    ...  \n",
       "2540042                 1               3      0  \n",
       "2540043                 2               2      0  \n",
       "2540044                 2               2      0  \n",
       "2540045                 2               2      0  \n",
       "2540046                 2               2      1  \n",
       "\n",
       "[2535852 rows x 47 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "proto               0.011832\n",
       "state               0.338312\n",
       "dur                 0.002055\n",
       "sbytes              0.010134\n",
       "dbytes              0.075698\n",
       "sttl                0.904512\n",
       "dttl                0.134569\n",
       "sloss               0.043423\n",
       "dloss               0.096054\n",
       "service             0.009492\n",
       "Sload               0.192121\n",
       "Dload               0.220163\n",
       "Spkts               0.121179\n",
       "Dpkts               0.116195\n",
       "swin                0.316271\n",
       "dwin                0.315079\n",
       "stcpb               0.234160\n",
       "dtcpb               0.234252\n",
       "smeansz             0.065710\n",
       "dmeansz             0.273102\n",
       "trans_depth         0.029195\n",
       "res_bdy_len         0.027398\n",
       "Sjit                0.020903\n",
       "Djit                0.054562\n",
       "Stime               0.275647\n",
       "Ltime               0.275647\n",
       "Sintpkt             0.012086\n",
       "Dintpkt             0.010668\n",
       "tcprtt              0.143044\n",
       "synack              0.122190\n",
       "ackdat              0.143386\n",
       "ct_state_ttl        0.880216\n",
       "ct_flw_http_mthd    0.026690\n",
       "is_ftp_login        0.031908\n",
       "ct_srv_src          0.382770\n",
       "ct_srv_dst          0.386279\n",
       "ct_dst_ltm          0.339234\n",
       "ct_src_ ltm         0.343003\n",
       "ct_src_dport_ltm    0.396617\n",
       "ct_dst_sport_ltm    0.418946\n",
       "ct_dst_src_ltm      0.439758\n",
       "Label               1.000000\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation with output variable\n",
    "cor = df.corr()\n",
    "cor_target = abs(cor[\"Label\"])\n",
    "cor_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.9045123713273255,\n",
       " 0.8802159911646181,\n",
       " 0.4397582040181459,\n",
       " 0.41894609595431975,\n",
       " 0.3966171141155974,\n",
       " 0.3862785180682943,\n",
       " 0.38276987066060003,\n",
       " 0.34300251941699716,\n",
       " 0.33923406199653117,\n",
       " 0.3383115509958634,\n",
       " 0.31627126136549794,\n",
       " 0.31507938791330836,\n",
       " 0.2756467745810105,\n",
       " 0.2756467361934781,\n",
       " 0.2731022353548177,\n",
       " 0.23425165967570538,\n",
       " 0.23415972437915167,\n",
       " 0.22016301877421282,\n",
       " 0.19212078068924934,\n",
       " 0.14338606748651497,\n",
       " 0.14304379120018665,\n",
       " 0.1345687229012209,\n",
       " 0.12218956387082323,\n",
       " 0.12117868665702373,\n",
       " 0.11619454701110364,\n",
       " 0.09605449315010073,\n",
       " 0.07569769679289255,\n",
       " 0.06571002635878419,\n",
       " 0.054562098246944746,\n",
       " 0.043423355305197676,\n",
       " 0.03190817000838083,\n",
       " 0.02919529475181047,\n",
       " 0.02739821746445534,\n",
       " 0.02668985508780704,\n",
       " 0.020902958909795925,\n",
       " 0.01208573079157584,\n",
       " 0.011832106432080278,\n",
       " 0.010667773256950744,\n",
       " 0.010133696212686666,\n",
       " 0.009492262382872188,\n",
       " 0.002055001885478537]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(cor_target,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information Gain of features\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "X = df.iloc[:,0:42]  #independent columns\n",
    "y = df.iloc[:,-1]    #target column i.e Label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tensor(): argument 'dtype' must be torch.dtype, not pybind11_type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m dfsample \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Extract features and labels\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfsample\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msrcip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdstip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStringType\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(dfsample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m      9\u001b[0m features \u001b[38;5;241m=\u001b[39m dfsample\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrcip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdstip\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msport\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdsport\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: tensor(): argument 'dtype' must be torch.dtype, not pybind11_type"
     ]
    }
   ],
   "source": [
    "#SAmple the dataset\n",
    "# Randomly sample 1000 rows\n",
    "dfsample = df.sample(n=1000, random_state=42)\n",
    "\n",
    "# Extract features and labels\n",
    "src_encoder = LabelEncoder()\n",
    "x = src_encoder.fit_transform(x)\n",
    "dst_encoder = LabelEncoder()\n",
    "y = dst_encoder.fit_transform(data['Dst IP Addr'])\n",
    "\n",
    "x = torch.tensor(dfsample[['srcip', 'dstip']].values, dtype=torch.long)\n",
    "y = torch.tensor(dfsample['Label'].values, dtype=torch.long)\n",
    "\n",
    "features = dfsample.drop(columns=['srcip', 'dstip','sport','dsport', 'Label'])\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "#Sampling\n",
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construct edge indices\n",
    "edge_index = torch.tensor([dfsample['srcip'].values, dfsample['dstip'].values], dtype=torch.long)\n",
    "edge_attr = torch.tensor(features, dtype=torch.ListType) \n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = GCN(input_dim=2, hidden_dim=64, output_dim=2)  # input_dim=2 since we have 2 features (source and destination IPs), output_dim=2 for binary edge classification\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training\n",
    "def train_model(model, optimizer, criterion, x_train, edge_index, edge_attr, y_train, epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x_train, edge_index, edge_attr)\n",
    "        loss = criterion(out, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch: {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Convert edge labels to one-hot encoding\n",
    "y_train_onehot = F.one_hot(y_train)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, optimizer, criterion, x_train, edge_index, edge_attr, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "def test_model(model, x_test, edge_index, edge_attr, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(x_test, edge_index, edge_attr)\n",
    "        pred = out.argmax(dim=1)\n",
    "        f1 = f1_score(y_test, pred, average='macro')\n",
    "        print(f'F1 Score: {f1}')\n",
    "\n",
    "# Test the model\n",
    "test_model(model, x_test, edge_index, edge_attr, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_18892\\868858865.py:1: DtypeWarning: Columns (1,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r'D:\\Project Phase II\\Dataset\\phase2labelencodeddataset.csv',encoding='cp1252')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\Project Phase II\\Dataset\\phase2labelencodeddataset.csv',encoding='cp1252')\n",
    "#Set attack_cat as -1 if Label ==0 else attack_cat\n",
    "df['attack_cat'] = df.apply(lambda x: -1 if x['Label'] == 0 else x['attack_cat'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split df into 5 minutes timeframe based on Stime\n",
    "\n",
    "start_Stime = 1421927443    \n",
    "df_timeframe_1_5mins = df[(df['Stime'] >= start_Stime) & (df['Stime'] <= (start_Stime + 300))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    2214569\n",
       " 5     215481\n",
       " 3      44525\n",
       " 4      24246\n",
       " 2      16353\n",
       " 7      13987\n",
       " 0       2677\n",
       " 1       2329\n",
       " 8       1511\n",
       " 9        174\n",
       "Name: attack_cat, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the number of times each attack_cat repeats\n",
    "df['attack_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-1 Non attack ||\n",
    "5 Generic ||\n",
    "3 Exploits ||\n",
    "4 Fuzzers ||\n",
    "2 DoS ||\n",
    "7 Reconnaissance ||\n",
    "0 Analysis ||\n",
    "1 Backdoors ||\n",
    "8 Shellcode ||\n",
    "9 Worms\n",
    "\n",
    "Alphabetical ordering is followed during label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.166.0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>7662</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>0.119596</td>\n",
       "      <td>4550</td>\n",
       "      <td>68342</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.166.0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.2</td>\n",
       "      <td>27709</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>0.650574</td>\n",
       "      <td>8928</td>\n",
       "      <td>320</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.166.0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>5190</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>2158</td>\n",
       "      <td>2464</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149.171.126.18</td>\n",
       "      <td>0</td>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>53</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149.171.126.18</td>\n",
       "      <td>0</td>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>53</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535847</th>\n",
       "      <td>59.166.0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>0.087306</td>\n",
       "      <td>320</td>\n",
       "      <td>1828</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535848</th>\n",
       "      <td>59.166.0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>0.365058</td>\n",
       "      <td>456</td>\n",
       "      <td>346</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535849</th>\n",
       "      <td>59.166.0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>6.335154</td>\n",
       "      <td>1802</td>\n",
       "      <td>2088</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535850</th>\n",
       "      <td>59.166.0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.0</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>2.200934</td>\n",
       "      <td>3498</td>\n",
       "      <td>166054</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535851</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.17</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>0.942984</td>\n",
       "      <td>574</td>\n",
       "      <td>676</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2535852 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  srcip sport           dstip dsport  proto  state       dur  \\\n",
       "0            59.166.0.1     0   149.171.126.4   7662    114      5  0.119596   \n",
       "1            59.166.0.3     0   149.171.126.2  27709    114      5  0.650574   \n",
       "2            59.166.0.8     0   149.171.126.9   5190    114      5  0.007980   \n",
       "3        149.171.126.18     0    175.45.176.3     53    120      6  0.000005   \n",
       "4        149.171.126.18     0    175.45.176.3     53    120      6  0.000005   \n",
       "...                 ...   ...             ...    ...    ...    ...       ...   \n",
       "2535847      59.166.0.5     0   149.171.126.7      0    114      5  0.087306   \n",
       "2535848      59.166.0.7     0   149.171.126.4      0    114      2  0.365058   \n",
       "2535849      59.166.0.3     0   149.171.126.9      0    114      2  6.335154   \n",
       "2535850      59.166.0.9     0   149.171.126.0      0    114      2  2.200934   \n",
       "2535851    175.45.176.0     0  149.171.126.17      0    114      2  0.942984   \n",
       "\n",
       "         sbytes  dbytes  sttl  ...  ct_ftp_cmd  ct_srv_src  ct_srv_dst  \\\n",
       "0          4550   68342    31  ...           0           6           2   \n",
       "1          8928     320    31  ...           0           3           5   \n",
       "2          2158    2464    31  ...           0           3           5   \n",
       "3           264       0    60  ...           0          19          19   \n",
       "4           264       0    60  ...           0          19          19   \n",
       "...         ...     ...   ...  ...         ...         ...         ...   \n",
       "2535847     320    1828    31  ...           0           1           2   \n",
       "2535848     456     346    31  ...           2           2           2   \n",
       "2535849    1802    2088    31  ...           2           2           2   \n",
       "2535850    3498  166054    31  ...           0           1           1   \n",
       "2535851     574     676    62  ...           0           1           1   \n",
       "\n",
       "         ct_dst_ltm  ct_src_ ltm  ct_src_dport_ltm  ct_dst_sport_ltm  \\\n",
       "0                 2            5                 1                 1   \n",
       "1                 2            4                 1                 1   \n",
       "2                 1            1                 1                 1   \n",
       "3                19           19                19                19   \n",
       "4                19           19                19                19   \n",
       "...             ...          ...               ...               ...   \n",
       "2535847           3            3                 1                 1   \n",
       "2535848           2            2                 2                 2   \n",
       "2535849           4            2                 2                 2   \n",
       "2535850           2            4                 2                 2   \n",
       "2535851           2            4                 2                 2   \n",
       "\n",
       "         ct_dst_src_ltm  attack_cat  Label  \n",
       "0                     2           6      0  \n",
       "1                     4           6      0  \n",
       "2                     3           6      0  \n",
       "3                    19           6      0  \n",
       "4                    19           6      0  \n",
       "...                 ...         ...    ...  \n",
       "2535847               3           6      0  \n",
       "2535848               2           6      0  \n",
       "2535849               2           6      0  \n",
       "2535850               2           6      0  \n",
       "2535851               2           3      1  \n",
       "\n",
       "[2535852 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'D:\\Project Phase II\\Dataset\\phase2cleaneddataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare df and df1, and replace values of sport and dsport in df with values in df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of Label = 0 and Label = 1 for each unique combination of sttl and ct_state_ttl:\n",
      "Label                    0       1\n",
      "sttl ct_state_ttl                 \n",
      "0    0                5862       0\n",
      "     2                  23     375\n",
      "1    0                4520       0\n",
      "29   0                2736       0\n",
      "30   0                 225       0\n",
      "31   0             1940700       0\n",
      "32   0                1602       0\n",
      "60   0              214255       0\n",
      "62   0                  19       1\n",
      "     1                3847   22231\n",
      "     2                   0     180\n",
      "     3                3394     291\n",
      "63   0                 524       0\n",
      "     1                   1       1\n",
      "64   0                3625       0\n",
      "252  0                  84       0\n",
      "254  0                2888    1078\n",
      "     1               19623   35684\n",
      "     2                7200  260037\n",
      "     3                 454     112\n",
      "     4                  12      28\n",
      "     5                   1       1\n",
      "     6                2935    1228\n",
      "255  0                  37      29\n",
      "     1                   2       7\n"
     ]
    }
   ],
   "source": [
    "#Count the number of records with Label = 1 and Label = 0 for each unique value of sttl and ct_state_ttl\n",
    "counts = df.groupby(['sttl', 'ct_state_ttl', 'Label']).size().unstack(fill_value=0)\n",
    "\n",
    "# Displaying the counts\n",
    "print(\"Counts of Label = 0 and Label = 1 for each unique combination of sttl and ct_state_ttl:\")\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of Label = 0 and Label = 1 for each unique sttl:\n",
      "Label        0       1\n",
      "sttl                  \n",
      "0         5885     375\n",
      "1         4520       0\n",
      "29        2736       0\n",
      "30         225       0\n",
      "31     1940700       0\n",
      "32        1602       0\n",
      "60      214255       0\n",
      "62        7260   22703\n",
      "63         525       1\n",
      "64        3625       0\n",
      "252         84       0\n",
      "254      33113  298168\n",
      "255         39      36\n"
     ]
    }
   ],
   "source": [
    "countssttl = df.groupby(['sttl', 'Label']).size().unstack(fill_value=0)\n",
    "\n",
    "# Displaying the counts\n",
    "print(\"Counts of Label = 0 and Label = 1 for each unique sttl:\")\n",
    "print(countssttl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 3, 4, 2, 5, 8, 1, 7, 9, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['attack_cat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of attack_cat for each unique sttl:\n",
      "attack_cat       -1     0     1      2      3      4       5      7     8    9\n",
      "sttl                                                                          \n",
      "0              5885     3    21    108    183     15      21     24     0    0\n",
      "1              4520     0     0      0      0      0       0      0     0    0\n",
      "29             2736     0     0      0      0      0       0      0     0    0\n",
      "30              225     0     0      0      0      0       0      0     0    0\n",
      "31          1940700     0     0      0      0      0       0      0     0    0\n",
      "32             1602     0     0      0      0      0       0      0     0    0\n",
      "60           214255     0     0      0      0      0       0      0     0    0\n",
      "62             7260   609    47   1828  18725     55    1395     40     0    4\n",
      "63              525     0     0      0      1      0       0      0     0    0\n",
      "64             3625     0     0      0      0      0       0      0     0    0\n",
      "252              84     0     0      0      0      0       0      0     0    0\n",
      "254           33113  2065  2261  14401  25612  24161  214065  13922  1511  170\n",
      "255              39     0     0     16      4     15       0      1     0    0\n"
     ]
    }
   ],
   "source": [
    "countsattcatsttl = df.groupby(['sttl', 'attack_cat']).size().unstack(fill_value=0)\n",
    "\n",
    "# Displaying the counts\n",
    "print(\"Counts of attack_cat for each unique sttl:\")\n",
    "print(countsattcatsttl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_8472\\3150562644.py:1: DtypeWarning: Columns (1,3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(r'D:\\Project Phase II\\Dataset\\completedataset.csv',encoding='cp1252')\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(r'D:\\Project Phase II\\Dataset\\completedataset.csv',encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace 'Backdoor' with 'Backdoors'\n",
    "#Remove trailing white spaces from the dataset\n",
    "df1 = df1.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "df1['attack_cat'] = df1['attack_cat'].replace('Backdoor', 'Backdoors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of attack_cat for each unique sttl:\n",
      "attack_cat  Analysis  Backdoors    DoS  Exploits  Fuzzers  Generic  \\\n",
      "sttl                                                                 \n",
      "0                  3         21    108       183       15       21   \n",
      "62               609         47   1828     18725       55     1395   \n",
      "63                 0          0      0         1        0        0   \n",
      "254             2065       2261  14401     25612    24161   214065   \n",
      "255                0          0     16         4       15        0   \n",
      "\n",
      "attack_cat  Reconnaissance  Shellcode  Worms  \n",
      "sttl                                          \n",
      "0                       24          0      0  \n",
      "62                      40          0      4  \n",
      "63                       0          0      0  \n",
      "254                  13922       1511    170  \n",
      "255                      1          0      0  \n"
     ]
    }
   ],
   "source": [
    "countsattcatsttl1 = df1.groupby(['sttl', 'attack_cat']).size().unstack(fill_value=0)\n",
    "\n",
    "# Displaying the counts\n",
    "print(\"Counts of attack_cat for each unique sttl:\")\n",
    "print(countsattcatsttl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of Label = 0 and Label = 1 for each unique 'ct_state_ttl':\n",
      "Label               0       1\n",
      "ct_state_ttl                 \n",
      "0             2177077    1108\n",
      "1               23473   57923\n",
      "2                7223  260592\n",
      "3                3848     403\n",
      "4                  12      28\n",
      "5                   1       1\n",
      "6                2935    1228\n"
     ]
    }
   ],
   "source": [
    "countsctstatettl = df.groupby(['ct_state_ttl', 'Label']).size().unstack(fill_value=0)\n",
    "\n",
    "# Displaying the counts\n",
    "print(\"Counts of Label = 0 and Label = 1 for each unique 'ct_state_ttl':\")\n",
    "print(countsctstatettl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stime :  1421927377  to  1424262068  difference =  2334691\n",
      "Ltime :  1421927414  to  1424262069  difference =  2334655\n"
     ]
    }
   ],
   "source": [
    "#FInd minimum and maximum value of Stime and Ltime\n",
    "minstime = df['Stime'].min()\n",
    "minltime = df['Ltime'].min()\n",
    "maxstime = df['Stime'].max()\n",
    "maxltime = df['Ltime'].max()\n",
    "\n",
    "print(\"Stime : \", minstime, \" to \", maxstime, \" difference = \", maxstime - minstime )\n",
    "print(\"Ltime : \", minltime, \" to \", maxltime , \" difference = \", maxltime-minltime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22/01/2015'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Unix time to DD/MM/YYYY format\n",
    "from datetime import datetime\n",
    "minstimets = datetime.fromtimestamp(minstime).strftime('%d/%m/%Y')\n",
    "minstimets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18/02/2015'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxstimets = datetime.fromtimestamp(maxstime).strftime('%d/%m/%Y')\n",
    "maxstimets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1421927443    426\n",
      "1424219889    383\n",
      "1421945101    226\n",
      "1424251722    225\n",
      "1424237259    213\n",
      "1421945117    210\n",
      "1421927444    209\n",
      "1424230476    202\n",
      "1424251558    201\n",
      "1421945200    200\n",
      "Name: Stime, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "top_ten_stime = df['Stime'].value_counts().head(10)\n",
    "print(top_ten_stime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set attack_cat = -1 when label = 0\n",
    "df['attack_cat'] = df.apply(lambda x: -1 if x['Label'] == 0 else x['attack_cat'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    2214569\n",
       " 5     215481\n",
       " 3      44525\n",
       " 4      24246\n",
       " 2      16353\n",
       " 7      13987\n",
       " 0       2677\n",
       " 1       2329\n",
       " 8       1511\n",
       " 9        174\n",
       "Name: attack_cat, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.attack_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2445148\n",
       "0          12944\n",
       "47439       2398\n",
       "1043        2054\n",
       "47439        339\n",
       "          ...   \n",
       "65254          1\n",
       "57073          1\n",
       "4077           1\n",
       "33654          1\n",
       "15104          1\n",
       "Name: sport, Length: 47691, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sport.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        916027\n",
       "53       617298\n",
       "80       126521\n",
       "5190      64255\n",
       "6881      61833\n",
       "          ...  \n",
       "26781         1\n",
       "22261         1\n",
       "25630         1\n",
       "24029         1\n",
       "30870         1\n",
       "Name: dsport, Length: 69442, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dsport.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\AppData\\Local\\Temp\\ipykernel_11172\\3150562644.py:1: DtypeWarning: Columns (1,3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(r'D:\\Project Phase II\\Dataset\\completedataset.csv',encoding='cp1252')\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(r'D:\\Project Phase II\\Dataset\\completedataset.csv',encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generic             215481\n",
       "Exploits             44525\n",
       " Fuzzers             19195\n",
       "DoS                  16353\n",
       " Reconnaissance      12228\n",
       " Fuzzers              5051\n",
       "Analysis              2677\n",
       "Backdoor              1795\n",
       "Reconnaissance        1759\n",
       " Shellcode            1288\n",
       "Backdoors              534\n",
       "Shellcode              223\n",
       "Worms                  174\n",
       "Name: attack_cat, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.attack_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1043     217979\n",
       "47439    200532\n",
       "0         49884\n",
       "0          4160\n",
       "138        3480\n",
       "          ...  \n",
       "13623         1\n",
       "34404         1\n",
       "51737         1\n",
       "46837         1\n",
       "706           1\n",
       "Name: sport, Length: 107594, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sport.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53       622508\n",
       "53       176460\n",
       "80       128153\n",
       "80        98545\n",
       "5190      65271\n",
       "          ...  \n",
       "8996          1\n",
       "53066         1\n",
       "10514         1\n",
       "30579         1\n",
       "11764         1\n",
       "Name: dsport, Length: 128286, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dsport.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1[df1['sport'] == 'None'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1[df1['sport'] == 'NaN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add all unique 'srcip' + 'sport' combinations to a set\n",
    "srcip_sport_set = set()\n",
    "for index, row in df1.iterrows():\n",
    "    srcip_sport_set.add((row['srcip'], row['sport']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split df1 into df1_label_true and df1_label_false\n",
    "df1_label_true = df1[df1['Label'] == 1]\n",
    "df1_label_false = df1[df1['Label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    321283\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_label_true.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2218764\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_label_false.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_label_false_grouped = df1_label_false.groupby(['srcip', 'sport', 'dstip', 'dsport']).size().reset_index(name='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.40.170.2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.40.170.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.40.170.2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.40.170.2</td>\n",
       "      <td>0</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.40.170.2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.40.170.2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.40.170.2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.40.170.2</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.40.182.1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.40.182.3</td>\n",
       "      <td>0</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899350</th>\n",
       "      <td>59.166.0.9</td>\n",
       "      <td>9952</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899351</th>\n",
       "      <td>59.166.0.9</td>\n",
       "      <td>9979</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899352</th>\n",
       "      <td>59.166.0.9</td>\n",
       "      <td>9989</td>\n",
       "      <td>149.171.126.6</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899353</th>\n",
       "      <td>59.166.0.9</td>\n",
       "      <td>9993</td>\n",
       "      <td>149.171.126.5</td>\n",
       "      <td>38742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899354</th>\n",
       "      <td>59.166.0.9</td>\n",
       "      <td>9994</td>\n",
       "      <td>149.171.126.8</td>\n",
       "      <td>8742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1899355 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               srcip sport          dstip dsport  count\n",
       "0        10.40.170.2     0    10.40.170.2      0   1194\n",
       "1        10.40.170.2     0    10.40.170.2      0    802\n",
       "2        10.40.170.2     0    10.40.170.2      0     20\n",
       "3        10.40.170.2     0    10.40.170.2      0     78\n",
       "4        10.40.182.1     0    10.40.182.3      0    998\n",
       "...              ...   ...            ...    ...    ...\n",
       "1899350   59.166.0.9  9952  149.171.126.7     53      1\n",
       "1899351   59.166.0.9  9979  149.171.126.9    143      1\n",
       "1899352   59.166.0.9  9989  149.171.126.6     80      1\n",
       "1899353   59.166.0.9  9993  149.171.126.5  38742      1\n",
       "1899354   59.166.0.9  9994  149.171.126.8   8742      1\n",
       "\n",
       "[1899355 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_label_false_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_label_true_grouped = df1_label_true.groupby(['srcip', 'sport', 'dstip', 'dsport']).size().reset_index(name='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.10</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.11</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.11</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.12</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.13</td>\n",
       "      <td>0</td>\n",
       "      <td>5188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65730</th>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>9750</td>\n",
       "      <td>149.171.126.11</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65731</th>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>9761</td>\n",
       "      <td>149.171.126.17</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65732</th>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>9812</td>\n",
       "      <td>149.171.126.15</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65733</th>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>9909</td>\n",
       "      <td>149.171.126.13</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65734</th>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>9953</td>\n",
       "      <td>149.171.126.15</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65735 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              srcip sport           dstip dsport  count\n",
       "0      175.45.176.0     0  149.171.126.10      0    299\n",
       "1      175.45.176.0     0  149.171.126.11      0     24\n",
       "2      175.45.176.0     0  149.171.126.11      0    240\n",
       "3      175.45.176.0     0  149.171.126.12      0    320\n",
       "4      175.45.176.0     0  149.171.126.13      0   5188\n",
       "...             ...   ...             ...    ...    ...\n",
       "65730  175.45.176.3  9750  149.171.126.11     80      1\n",
       "65731  175.45.176.3  9761  149.171.126.17     21      1\n",
       "65732  175.45.176.3  9812  149.171.126.15     80      1\n",
       "65733  175.45.176.3  9909  149.171.126.13     80      1\n",
       "65734  175.45.176.3  9953  149.171.126.15     80      1\n",
       "\n",
       "[65735 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_label_true_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# Create an empty graph\n",
    "attackG = nx.DiGraph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "for i in range(len(df1_label_true_grouped)):\n",
    "    src_node = str(df1_label_true_grouped['srcip'][i]) + ':' + str(df1_label_true_grouped['sport'][i])\n",
    "    dst_node = str(df1_label_true_grouped['dstip'][i]) + ':' + str(df1_label_true_grouped['dsport'][i])\n",
    "    attackG.add_node(src_node)\n",
    "    attackG.add_node(dst_node)\n",
    "\n",
    "# Add edges to the graph with edge weight as count\n",
    "for i in range(len(df1_label_true_grouped)):\n",
    "    src_node = str(df1_label_true_grouped['srcip'][i]) + ':' + str(df1_label_true_grouped['sport'][i])\n",
    "    dst_node = str(df1_label_true_grouped['dstip'][i]) + ':' + str(df1_label_true_grouped['dsport'][i])\n",
    "    edge_weight = df1_label_true_grouped['count'][i]\n",
    "    attackG.add_edge(src_node, dst_node, weight=edge_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# Create an empty graph\n",
    "nonAttackG = nx.DiGraph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "for i in range(len(df1_label_false_grouped)):\n",
    "    src_node = str(df1_label_false_grouped['srcip'][i]) + ':' + str(df1_label_false_grouped['sport'][i])\n",
    "    dst_node = str(df1_label_false_grouped['dstip'][i]) + ':' + str(df1_label_false_grouped['dsport'][i])\n",
    "    nonAttackG.add_node(src_node)\n",
    "    nonAttackG.add_node(dst_node)\n",
    "\n",
    "# Add edges to the graph with edge weight as count\n",
    "for i in range(len(df1_label_false_grouped)):\n",
    "    src_node = str(df1_label_false_grouped['srcip'][i]) + ':' + str(df1_label_false_grouped['sport'][i])\n",
    "    dst_node = str(df1_label_false_grouped['dstip'][i]) + ':' + str(df1_label_false_grouped['dsport'][i])\n",
    "    edge_weight = df1_label_false_grouped['count'][i]\n",
    "    nonAttackG.add_edge(src_node, dst_node, weight=edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_grouped = df1.groupby(['srcip', 'sport', 'dstip', 'dsport']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# Create an empty graph\n",
    "overallG = nx.DiGraph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "for i in range(len(df1_grouped)):\n",
    "    src_node = str(df1_grouped['srcip'][i]) + ':' + str(df1_grouped['sport'][i])\n",
    "    dst_node = str(df1_grouped['dstip'][i]) + ':' + str(df1_grouped['dsport'][i])\n",
    "    overallG.add_node(src_node)\n",
    "    overallG.add_node(dst_node)\n",
    "\n",
    "# Add edges to the graph with edge weight as count\n",
    "for i in range(len(df1_grouped)):\n",
    "    src_node = str(df1_grouped['srcip'][i]) + ':' + str(df1_grouped['sport'][i])\n",
    "    dst_node = str(df1_grouped['dstip'][i]) + ':' + str(df1_grouped['dsport'][i])\n",
    "    edge_weight = df1_grouped['count'][i]\n",
    "    overallG.add_edge(src_node, dst_node, weight=edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m degree_centrality \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mdegree_centrality(attackG)\n\u001b[0;32m      4\u001b[0m closeness_centrality \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mcloseness_centrality(attackG)\n\u001b[1;32m----> 5\u001b[0m betweenness_centrality \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbetweenness_centrality\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattackG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m eigenvector_centrality \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39meigenvector_centrality(attackG)\n\u001b[0;32m      7\u001b[0m number_of_communities \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mnumber_connected_components(attackG)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\networkx\\utils\\decorators.py:770\u001b[0m, in \u001b[0;36margmap.__call__.<locals>.func\u001b[1;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(\u001b[38;5;241m*\u001b[39margs, __wrapper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 770\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m argmap\u001b[38;5;241m.\u001b[39m_lazy_compile(__wrapper)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m<class 'networkx.utils.decorators.argmap'> compilation 4:4\u001b[0m, in \u001b[0;36margmap_betweenness_centrality_1\u001b[1;34m(G, k, normalized, weight, endpoints, seed, backend, **backend_kwargs)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\networkx\\utils\\backends.py:412\u001b[0m, in \u001b[0;36m_dispatch.__call__\u001b[1;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backends:\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;66;03m# Fast path if no backends are installed\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001b[39;00m\n\u001b[0;32m    415\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\networkx\\algorithms\\centrality\\betweenness.py:136\u001b[0m, in \u001b[0;36mbetweenness_centrality\u001b[1;34m(G, k, normalized, weight, endpoints, seed)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m nodes:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# single source shortest paths\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use BFS\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m         S, P, sigma, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_single_source_shortest_path_basic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# use Dijkstra's algorithm\u001b[39;00m\n\u001b[0;32m    138\u001b[0m         S, P, sigma, _ \u001b[38;5;241m=\u001b[39m _single_source_dijkstra_path_basic(G, s, weight)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\networkx\\algorithms\\centrality\\betweenness.py:259\u001b[0m, in \u001b[0;36m_single_source_shortest_path_basic\u001b[1;34m(G, s)\u001b[0m\n\u001b[0;32m    257\u001b[0m P \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m G:\n\u001b[1;32m--> 259\u001b[0m     P[v] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    260\u001b[0m sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(G, \u001b[38;5;241m0.0\u001b[39m)  \u001b[38;5;66;03m# sigma[v]=0 for v in G\u001b[39;00m\n\u001b[0;32m    261\u001b[0m D \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "# Calculate centrality measures\n",
    "degree_centrality = nx.degree_centrality(attackG)\n",
    "closeness_centrality = nx.closeness_centrality(attackG)\n",
    "betweenness_centrality = nx.betweenness_centrality(attackG)\n",
    "eigenvector_centrality = nx.eigenvector_centrality(attackG)\n",
    "number_of_communities = nx.number_connected_components(attackG)\n",
    "\n",
    "# Calculate average centrality scores\n",
    "average_degree = sum(degree_centrality.values()) / len(degree_centrality)\n",
    "average_closeness = sum(closeness_centrality.values()) / len(closeness_centrality)\n",
    "average_betweenness = sum(betweenness_centrality.values()) / len(betweenness_centrality)\n",
    "average_eigenvector = sum(eigenvector_centrality.values()) / len(eigenvector_centrality)\n",
    "\n",
    "# Print the results\n",
    "print(\"Degree Centrality:\", degree_centrality)\n",
    "print(\"Average Closeness Centrality:\", average_closeness)\n",
    "print(\"Average Betweenness Centrality:\", average_betweenness)\n",
    "print(\"Average Eigenvector Centrality:\", average_eigenvector)\n",
    "print(\"Number of Communities:\", number_of_communities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coefficient = nx.clustering(attackG)\n",
    "# Average Shortest Path Length\n",
    "average_shortest_path_length = nx.average_shortest_path_length(attackG)\n",
    "# Global Efficiency\n",
    "global_efficiency = nx.global_efficiency(attackG)\n",
    "# Local Efficiency\n",
    "local_efficiency = nx.local_efficiency(attackG)\n",
    "# Transitivity\n",
    "transitivity = nx.transitivity(attackG)\n",
    "# Diameter\n",
    "diameter = nx.diameter(attackG)\n",
    "# Average Clustering\n",
    "average_clustering = nx.average_clustering(attackG)\n",
    "# Density\n",
    "density = nx.density(attackG)\n",
    "\n",
    "print(\"Density:\", density)\n",
    "print(\"Clustering Coefficient:\", clustering_coefficient)\n",
    "print(\"Average Shortest Path Length:\", average_shortest_path_length)\n",
    "print(\"Global Efficiency:\", global_efficiency)\n",
    "print(\"Local Efficiency:\", local_efficiency)\n",
    "print(\"Transitivity:\", transitivity)\n",
    "print(\"Average Clustering:\", average_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "density = nx.density(attackG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.686936433800373e-05"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the graph to Gephi file format\n",
    "nx.write_gexf(overallG, \"D:\\Project Phase II\\Graphs\\completegraph.gexf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(attackG, \"D:\\Project Phase II\\Graphs\\\\attackgraph.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(nonAttackG, \"D:\\Project Phase II\\Graphs\\\\nonattackgraph.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = set()\n",
    "for i in range(len(df)):\n",
    "    nodes.add(str(df['srcip'][i])+':'+str(df['sport'][i]))\n",
    "    nodes.add(str(df['srcip'][i])+':'+str(df['sport'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68192"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use logistic regression to predict the label\n",
    "#Split the dataset into features and labels\n",
    "X = df['sttl']\n",
    "y = df['Label']\n",
    "\n",
    "#Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Logistic regression to classify only using one variable\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train.values.reshape(-1,1), y_train)\n",
    "\n",
    "y_pred = LR.predict(X_test.values.reshape(-1,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[436361,   6577],\n",
       "       [  4599,  59634]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    442938\n",
      "           1       0.90      0.93      0.91     64233\n",
      "\n",
      "    accuracy                           0.98    507171\n",
      "   macro avg       0.95      0.96      0.95    507171\n",
      "weighted avg       0.98      0.98      0.98    507171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98735601, 0.91432339])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#F1 score for each label\n",
    "f1_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    442938\n",
      "           1       0.90      0.93      0.91     64233\n",
      "\n",
      "    accuracy                           0.98    507171\n",
      "   macro avg       0.95      0.96      0.95    507171\n",
      "weighted avg       0.98      0.98      0.98    507171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PCA for dimensionality reduction using only two variables sttl and ct_state_ttl\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1)\n",
    "X = df[['sttl', 'ct_state_ttl']]\n",
    "y = df['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pca_x_train = pca.fit_transform(X_train)\n",
    "pca_x_test = pca.fit_transform(X_test)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(pca_x_train, y_train)\n",
    "y_pred = classifier.predict(pca_x_test)\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99996518 0.00834444]]\n"
     ]
    }
   ],
   "source": [
    "#Linear equation formed by PCA\n",
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Prediction Values of Baseline ML Models Alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43005"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find all string values in sport\n",
    "df['sport'] = df['sport'].astype(str)\n",
    "#Replace '-' with 0\n",
    "df['sport'] = df['sport'].replace('-', '80')\n",
    "#COnvert hexadecimal values to decimal in sport\n",
    "df['sport'] = df['sport'].apply(lambda x: int(x, 16))\n",
    "#Convert sport to int\n",
    "df['sport'] = df['sport'].astype(int)\n",
    "\n",
    "len(df['sport'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64380"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dsport'] = df['dsport'].astype(str)\n",
    "df['dsport'] = df['dsport'].replace('-', '80')\n",
    "df['dsport'] = df['dsport'].apply(lambda x: int(x, 16))\n",
    "df['dsport'] = df['dsport'].astype(int)\n",
    "len(df['dsport'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSample0 = df[df['Label'] == 0].sample(n=250000, random_state=42)\n",
    "dfSample1 = df[df['Label'] == 1].sample(n=250000, random_state=42)\n",
    "\n",
    "dfSample = pd.concat([dfSample0, dfSample1])\n",
    "dfSample = dfSample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#Split the dataset into features and labels\n",
    "XSample = dfSample.drop('Label', axis=1)\n",
    "ySample = dfSample['Label']\n",
    "\n",
    "#Split the dataset into training and testing sets\n",
    "XSample_train, XSample_test, ySample_train, ySample_test = train_test_split(XSample, ySample, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSample0 = df[df['Label'] == 0].sample(n=500000, random_state=42)\n",
    "dfSample1 = df[df['Label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique records in the DataFrame for Label = 0: 454722\n",
      "Number of unique records in the DataFrame for Label = 1: 79055\n"
     ]
    }
   ],
   "source": [
    "dfSample0 = dfSample0.drop(['srcip', 'dstip', 'attack_cat','Stime','Ltime'], axis=1)\n",
    "dfSample0 = dfSample0.drop_duplicates()\n",
    "dfSample1 = dfSample1.drop(['srcip', 'dstip', 'attack_cat','Stime','Ltime'], axis=1)\n",
    "dfSample1 = dfSample1.drop_duplicates()\n",
    "\n",
    "print(\"Number of unique records in the DataFrame for Label = 0:\", len(dfSample0))\n",
    "print(\"Number of unique records in the DataFrame for Label = 1:\", len(dfSample1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSample0 = dfSample0.sample(n=79055,random_state=40)\n",
    "\n",
    "Train0,Test0 = train_test_split(dfSample0, test_size=0.2, random_state=40)\n",
    "Train1,Test1 = train_test_split(dfSample1, test_size=0.2, random_state=40)\n",
    "\n",
    "Train = pd.concat([Train0,Train1])\n",
    "Test = pd.concat([Test0,Test1])\n",
    "\n",
    "Train = Train.sample(frac=1, random_state=40).reset_index(drop=True)\n",
    "Test = Test.sample(frac=1, random_state=40).reset_index(drop=True)\n",
    "\n",
    "X_train = Train.drop('Label', axis=1)\n",
    "y_train = Train['Label']\n",
    "X_test = Test.drop('Label', axis=1)\n",
    "y_test = Test['Label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.74      0.82     15811\n",
      "           1       0.78      0.94      0.86     15811\n",
      "\n",
      "    accuracy                           0.84     31622\n",
      "   macro avg       0.86      0.84      0.84     31622\n",
      "weighted avg       0.86      0.84      0.84     31622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression to classify using all variables\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     15811\n",
      "           1       0.99      0.98      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision tree classifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lazy Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use lazypredict \n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "#Remove time consuming lazypredict classifier models from training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of classifiers to include\n",
    "import sklearn\n",
    "import xgboost\n",
    "import lightgbm\n",
    "\n",
    "#Skip SVM\n",
    "classifiers = [\n",
    " ('AdaBoostClassifier', sklearn.ensemble._weight_boosting.AdaBoostClassifier),\n",
    " ('BaggingClassifier', sklearn.ensemble._bagging.BaggingClassifier),\n",
    " ('BernoulliNB', sklearn.naive_bayes.BernoulliNB),\n",
    " ('DecisionTreeClassifier', sklearn.tree._classes.DecisionTreeClassifier),\n",
    " ('DummyClassifier', sklearn.dummy.DummyClassifier),\n",
    " ('GaussianNB', sklearn.naive_bayes.GaussianNB),\n",
    " ('KNeighborsClassifier',  sklearn.neighbors._classification.KNeighborsClassifier),\n",
    " ('LinearDiscriminantAnalysis',  sklearn.discriminant_analysis.LinearDiscriminantAnalysis),\n",
    " ('LogisticRegression', sklearn.linear_model._logistic.LogisticRegression),\n",
    " ('Perceptron', sklearn.linear_model._perceptron.Perceptron),\n",
    " ('QuadraticDiscriminantAnalysis',  sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis),\n",
    " ('RandomForestClassifier', sklearn.ensemble._forest.RandomForestClassifier),\n",
    " ('StackingClassifier', sklearn.ensemble._stacking.StackingClassifier),\n",
    " ('XGBClassifier', xgboost.sklearn.XGBClassifier),\n",
    " ('LGBMClassifier', lightgbm.sklearn.LGBMClassifier)]\n",
    "clf = LazyClassifier(verbose=1,ignore_warnings=True, custom_metric=None,classifiers=classifiers,predictions=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AdaBoostClassifier', sklearn.ensemble._weight_boosting.AdaBoostClassifier),\n",
       " ('BaggingClassifier', sklearn.ensemble._bagging.BaggingClassifier),\n",
       " ('BernoulliNB', sklearn.naive_bayes.BernoulliNB),\n",
       " ('CalibratedClassifierCV', sklearn.calibration.CalibratedClassifierCV),\n",
       " ('CategoricalNB', sklearn.naive_bayes.CategoricalNB),\n",
       " ('DecisionTreeClassifier', sklearn.tree._classes.DecisionTreeClassifier),\n",
       " ('DummyClassifier', sklearn.dummy.DummyClassifier),\n",
       " ('ExtraTreeClassifier', sklearn.tree._classes.ExtraTreeClassifier),\n",
       " ('ExtraTreesClassifier', sklearn.ensemble._forest.ExtraTreesClassifier),\n",
       " ('GaussianNB', sklearn.naive_bayes.GaussianNB),\n",
       " ('KNeighborsClassifier',\n",
       "  sklearn.neighbors._classification.KNeighborsClassifier),\n",
       " ('LabelPropagation',\n",
       "  sklearn.semi_supervised._label_propagation.LabelPropagation),\n",
       " ('LabelSpreading', sklearn.semi_supervised._label_propagation.LabelSpreading),\n",
       " ('LinearDiscriminantAnalysis',\n",
       "  sklearn.discriminant_analysis.LinearDiscriminantAnalysis),\n",
       " ('LinearSVC', sklearn.svm._classes.LinearSVC),\n",
       " ('LogisticRegression', sklearn.linear_model._logistic.LogisticRegression),\n",
       " ('NearestCentroid', sklearn.neighbors._nearest_centroid.NearestCentroid),\n",
       " ('NuSVC', sklearn.svm._classes.NuSVC),\n",
       " ('PassiveAggressiveClassifier',\n",
       "  sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier),\n",
       " ('Perceptron', sklearn.linear_model._perceptron.Perceptron),\n",
       " ('QuadraticDiscriminantAnalysis',\n",
       "  sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis),\n",
       " ('RandomForestClassifier', sklearn.ensemble._forest.RandomForestClassifier),\n",
       " ('RidgeClassifier', sklearn.linear_model._ridge.RidgeClassifier),\n",
       " ('RidgeClassifierCV', sklearn.linear_model._ridge.RidgeClassifierCV),\n",
       " ('SGDClassifier', sklearn.linear_model._stochastic_gradient.SGDClassifier),\n",
       " ('SVC', sklearn.svm._classes.SVC),\n",
       " ('StackingClassifier', sklearn.ensemble._stacking.StackingClassifier),\n",
       " ('XGBClassifier', xgboost.sklearn.XGBClassifier),\n",
       " ('LGBMClassifier', lightgbm.sklearn.LGBMClassifier)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lazypredict import Supervised\n",
    "Supervised.CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tuple' object has no attribute '__name__'\n",
      "Invalid Classifier(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [01:31<21:18, 91.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostClassifier', 'Accuracy': 0.992663335652394, 'Balanced Accuracy': 0.992663335652394, 'ROC AUC': 0.992663335652394, 'F1 Score': 0.992662999630621, 'Time taken': 91.28628396987915}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [02:52<18:28, 85.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BaggingClassifier', 'Accuracy': 0.991524887736386, 'Balanced Accuracy': 0.991524887736386, 'ROC AUC': 0.991524887736386, 'F1 Score': 0.9915246597724386, 'Time taken': 81.00605750083923}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [02:54<09:29, 47.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BernoulliNB', 'Accuracy': 0.9882676617544748, 'Balanced Accuracy': 0.9882676617544748, 'ROC AUC': 0.9882676617544748, 'F1 Score': 0.9882672246988611, 'Time taken': 2.5598137378692627}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [03:08<06:16, 34.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DecisionTreeClassifier', 'Accuracy': 0.9859275188160141, 'Balanced Accuracy': 0.9859275188160141, 'ROC AUC': 0.9859275188160143, 'F1 Score': 0.9859274974106864, 'Time taken': 13.927546739578247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [03:11<03:47, 22.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DummyClassifier', 'Accuracy': 0.5, 'Balanced Accuracy': 0.5, 'ROC AUC': 0.5, 'F1 Score': 0.3333333333333333, 'Time taken': 2.304922103881836}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [03:13<02:22, 15.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GaussianNB', 'Accuracy': 0.9713490607804693, 'Balanced Accuracy': 0.9713490607804693, 'ROC AUC': 0.9713490607804693, 'F1 Score': 0.9713379713555109, 'Time taken': 2.388155460357666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [10:01<19:12, 144.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'KNeighborsClassifier', 'Accuracy': 0.9922206059072798, 'Balanced Accuracy': 0.9922206059072798, 'ROC AUC': 0.9922206059072797, 'F1 Score': 0.9922202496083309, 'Time taken': 407.98821234703064}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [10:05<11:37, 99.58s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LinearDiscriminantAnalysis', 'Accuracy': 0.9898488394155968, 'Balanced Accuracy': 0.9898488394155966, 'ROC AUC': 0.9898488394155966, 'F1 Score': 0.9898484844098117, 'Time taken': 4.40012526512146}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [10:14<07:06, 71.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LogisticRegression', 'Accuracy': 0.99209411169439, 'Balanced Accuracy': 0.99209411169439, 'ROC AUC': 0.99209411169439, 'F1 Score': 0.992093763012213, 'Time taken': 8.472248554229736}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [10:17<04:10, 50.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Perceptron', 'Accuracy': 0.988141167541585, 'Balanced Accuracy': 0.988141167541585, 'ROC AUC': 0.9881411675415849, 'F1 Score': 0.9881409250234493, 'Time taken': 3.1924448013305664}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [10:20<02:22, 35.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'QuadraticDiscriminantAnalysis', 'Accuracy': 0.9855796597305674, 'Balanced Accuracy': 0.9855796597305673, 'ROC AUC': 0.9855796597305674, 'F1 Score': 0.9855777065099594, 'Time taken': 2.592419147491455}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [12:14<02:58, 59.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RandomForestClassifier', 'Accuracy': 0.9928530769717285, 'Balanced Accuracy': 0.9928530769717285, 'ROC AUC': 0.9928530769717285, 'F1 Score': 0.9928527372885315, 'Time taken': 114.64744138717651}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [12:28<00:35, 35.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'XGBClassifier', 'Accuracy': 0.9929163240781734, 'Balanced Accuracy': 0.9929163240781734, 'ROC AUC': 0.9929163240781733, 'F1 Score': 0.9929159935505343, 'Time taken': 13.57119870185852}\n",
      "[LightGBM] [Info] Number of positive: 63244, number of negative: 63244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.211749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6513\n",
      "[LightGBM] [Info] Number of data points in the train set: 126488, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [12:44<00:00, 50.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LGBMClassifier', 'Accuracy': 0.9929163240781734, 'Balanced Accuracy': 0.9929163240781734, 'ROC AUC': 0.9929163240781735, 'F1 Score': 0.9929159811948223, 'Time taken': 16.169971466064453}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>13.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>16.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>114.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>91.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>407.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>81.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>13.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "XGBClassifier                      0.99               0.99     0.99      0.99   \n",
       "LGBMClassifier                     0.99               0.99     0.99      0.99   \n",
       "RandomForestClassifier             0.99               0.99     0.99      0.99   \n",
       "AdaBoostClassifier                 0.99               0.99     0.99      0.99   \n",
       "KNeighborsClassifier               0.99               0.99     0.99      0.99   \n",
       "LogisticRegression                 0.99               0.99     0.99      0.99   \n",
       "BaggingClassifier                  0.99               0.99     0.99      0.99   \n",
       "LinearDiscriminantAnalysis         0.99               0.99     0.99      0.99   \n",
       "BernoulliNB                        0.99               0.99     0.99      0.99   \n",
       "Perceptron                         0.99               0.99     0.99      0.99   \n",
       "DecisionTreeClassifier             0.99               0.99     0.99      0.99   \n",
       "QuadraticDiscriminantAnalysis      0.99               0.99     0.99      0.99   \n",
       "GaussianNB                         0.97               0.97     0.97      0.97   \n",
       "DummyClassifier                    0.50               0.50     0.50      0.33   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "XGBClassifier                       13.57  \n",
       "LGBMClassifier                      16.17  \n",
       "RandomForestClassifier             114.65  \n",
       "AdaBoostClassifier                  91.29  \n",
       "KNeighborsClassifier               407.99  \n",
       "LogisticRegression                   8.47  \n",
       "BaggingClassifier                   81.01  \n",
       "LinearDiscriminantAnalysis           4.40  \n",
       "BernoulliNB                          2.56  \n",
       "Perceptron                           3.19  \n",
       "DecisionTreeClassifier              13.93  \n",
       "QuadraticDiscriminantAnalysis        2.59  \n",
       "GaussianNB                           2.39  \n",
       "DummyClassifier                      2.30  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>32.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>195.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>35.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>347.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>158.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>8.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>26.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4007.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>20.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>8.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "XGBClassifier                      0.99               0.99     0.99      0.99   \n",
       "RandomForestClassifier             0.99               0.99     0.99      0.99   \n",
       "LGBMClassifier                     0.99               0.99     0.99      0.99   \n",
       "AdaBoostClassifier                 0.99               0.99     0.99      0.99   \n",
       "BaggingClassifier                  0.99               0.99     0.99      0.99   \n",
       "SGDClassifier                      0.99               0.99     0.99      0.99   \n",
       "LogisticRegression                 0.99               0.99     0.99      0.99   \n",
       "KNeighborsClassifier               0.99               0.99     0.99      0.99   \n",
       "Perceptron                         0.99               0.99     0.99      0.99   \n",
       "QuadraticDiscriminantAnalysis      0.99               0.99     0.99      0.99   \n",
       "DecisionTreeClassifier             0.99               0.99     0.99      0.99   \n",
       "LinearDiscriminantAnalysis         0.99               0.99     0.99      0.99   \n",
       "RidgeClassifierCV                  0.99               0.99     0.99      0.99   \n",
       "GaussianNB                         0.94               0.94     0.94      0.94   \n",
       "BernoulliNB                        0.91               0.91     0.91      0.91   \n",
       "DummyClassifier                    0.50               0.50     0.50      0.33   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "XGBClassifier                       32.44  \n",
       "RandomForestClassifier             195.56  \n",
       "LGBMClassifier                      35.15  \n",
       "AdaBoostClassifier                 347.93  \n",
       "BaggingClassifier                  158.00  \n",
       "SGDClassifier                        8.79  \n",
       "LogisticRegression                  26.86  \n",
       "KNeighborsClassifier              4007.74  \n",
       "Perceptron                          10.41  \n",
       "QuadraticDiscriminantAnalysis        6.30  \n",
       "DecisionTreeClassifier              20.20  \n",
       "LinearDiscriminantAnalysis           8.25  \n",
       "RidgeClassifierCV                   10.21  \n",
       "GaussianNB                           4.26  \n",
       "BernoulliNB                          4.27  \n",
       "DummyClassifier                      3.04  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>BernoulliNB</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>DummyClassifier</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>Perceptron</th>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>LGBMClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AdaBoostClassifier  BaggingClassifier  BernoulliNB  \\\n",
       "0                       1                  1            1   \n",
       "1                       0                  0            0   \n",
       "2                       1                  1            1   \n",
       "3                       0                  0            0   \n",
       "4                       1                  1            1   \n",
       "...                   ...                ...          ...   \n",
       "99995                   0                  0            0   \n",
       "99996                   1                  1            1   \n",
       "99997                   0                  0            0   \n",
       "99998                   0                  0            0   \n",
       "99999                   0                  0            0   \n",
       "\n",
       "       DecisionTreeClassifier  DummyClassifier  GaussianNB  \\\n",
       "0                           1                0           1   \n",
       "1                           0                0           0   \n",
       "2                           1                0           1   \n",
       "3                           0                0           0   \n",
       "4                           1                0           1   \n",
       "...                       ...              ...         ...   \n",
       "99995                       0                0           0   \n",
       "99996                       1                0           1   \n",
       "99997                       0                0           0   \n",
       "99998                       0                0           0   \n",
       "99999                       0                0           0   \n",
       "\n",
       "       KNeighborsClassifier  LinearDiscriminantAnalysis  LogisticRegression  \\\n",
       "0                         1                           1                   1   \n",
       "1                         0                           0                   0   \n",
       "2                         1                           1                   1   \n",
       "3                         0                           0                   0   \n",
       "4                         1                           1                   1   \n",
       "...                     ...                         ...                 ...   \n",
       "99995                     0                           0                   0   \n",
       "99996                     1                           1                   1   \n",
       "99997                     0                           0                   0   \n",
       "99998                     0                           0                   0   \n",
       "99999                     0                           0                   0   \n",
       "\n",
       "       Perceptron  QuadraticDiscriminantAnalysis  RandomForestClassifier  \\\n",
       "0               1                              1                       1   \n",
       "1               0                              0                       0   \n",
       "2               1                              1                       1   \n",
       "3               0                              0                       0   \n",
       "4               1                              1                       1   \n",
       "...           ...                            ...                     ...   \n",
       "99995           0                              0                       0   \n",
       "99996           1                              1                       1   \n",
       "99997           0                              0                       0   \n",
       "99998           0                              0                       0   \n",
       "99999           0                              0                       0   \n",
       "\n",
       "       XGBClassifier  LGBMClassifier  \n",
       "0                  1               1  \n",
       "1                  0               0  \n",
       "2                  1               1  \n",
       "3                  0               0  \n",
       "4                  1               1  \n",
       "...              ...             ...  \n",
       "99995              0               0  \n",
       "99996              1               1  \n",
       "99997              0               0  \n",
       "99998              0               0  \n",
       "99999              0               0  \n",
       "\n",
       "[100000 rows x 14 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lazyclassifier_model_predictions.pkl']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Save trained models\n",
    "joblib.dump(predictions, 'lazyclassifier_model_predictions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     15811\n",
      "           1       0.99      1.00      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.992663335652394\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "BaggingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     15811\n",
      "           1       0.99      1.00      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.991524887736386\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "BernoulliNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     15811\n",
      "           1       0.98      0.99      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.9882676617544748\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     15811\n",
      "           1       0.99      0.98      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.9859275188160143\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "DummyClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     15811\n",
      "           1       0.00      0.00      0.00     15811\n",
      "\n",
      "    accuracy                           0.50     31622\n",
      "   macro avg       0.25      0.50      0.33     31622\n",
      "weighted avg       0.25      0.50      0.33     31622\n",
      "\n",
      "AUC Scores for each class: 0.5\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     15811\n",
      "           1       0.95      0.99      0.97     15811\n",
      "\n",
      "    accuracy                           0.97     31622\n",
      "   macro avg       0.97      0.97      0.97     31622\n",
      "weighted avg       0.97      0.97      0.97     31622\n",
      "\n",
      "AUC Scores for each class: 0.9713490607804693\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     15811\n",
      "           1       0.99      1.00      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.9922206059072797\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "LinearDiscriminantAnalysis\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     15811\n",
      "           1       0.98      1.00      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.9898488394155966\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     15811\n",
      "           1       0.99      1.00      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.99209411169439\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "Perceptron\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     15811\n",
      "           1       0.98      0.99      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.9881411675415849\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "QuadraticDiscriminantAnalysis\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     15811\n",
      "           1       0.97      1.00      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.9855796597305674\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     15811\n",
      "           1       0.99      1.00      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.9928530769717285\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "XGBClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     15811\n",
      "           1       0.99      1.00      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.9929163240781733\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "LGBMClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     15811\n",
      "           1       0.99      1.00      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.9929163240781735\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "for model in predictions.columns:\n",
    "    print(model)\n",
    "    print(classification_report(y_test, predictions[model]))\n",
    "    auc_scores = roc_auc_score(y_test, predictions[model], multi_class='ovr')  # Or multi_class='ovo' for one-vs-one\n",
    "    print(\"AUC Scores for each class:\", auc_scores)\n",
    "    print('-----------------------------------------------------------------------------------')\n",
    "    print('-----------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try without sttl and ct_state_ttl\n",
    "X_train = X_train.drop(['sttl', 'ct_state_ttl'], axis=1)\n",
    "X_test = X_test.drop(['sttl', 'ct_state_ttl'], axis=1)\n",
    "\n",
    "#There's a marginal duplication of 27 records. So assume there is no duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     15811\n",
      "           1       0.99      0.98      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Try decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 12 Dload (0.610672)\n",
      "2. feature 7 dttl (0.222591)\n",
      "3. feature 15 swin (0.052201)\n",
      "4. feature 5 sbytes (0.036693)\n",
      "5. feature 3 state (0.022931)\n",
      "6. feature 9 dloss (0.019652)\n",
      "7. feature 11 Sload (0.004743)\n",
      "8. feature 6 dbytes (0.003896)\n",
      "9. feature 17 stcpb (0.002123)\n",
      "10. feature 28 synack (0.001867)\n",
      "11. feature 34 ct_srv_dst (0.001769)\n",
      "12. feature 18 dtcpb (0.001706)\n",
      "13. feature 29 ackdat (0.001604)\n",
      "14. feature 33 ct_srv_src (0.001582)\n",
      "15. feature 19 smeansz (0.001572)\n",
      "16. feature 23 Sjit (0.001498)\n",
      "17. feature 27 tcprtt (0.001451)\n",
      "18. feature 4 dur (0.001237)\n",
      "19. feature 39 ct_dst_src_ltm (0.001236)\n",
      "20. feature 25 Sintpkt (0.001158)\n",
      "21. feature 36 ct_src_ ltm (0.001126)\n",
      "22. feature 1 dsport (0.001111)\n",
      "23. feature 26 Dintpkt (0.000818)\n",
      "24. feature 37 ct_src_dport_ltm (0.000717)\n",
      "25. feature 35 ct_dst_ltm (0.000684)\n",
      "26. feature 2 proto (0.000530)\n",
      "27. feature 24 Djit (0.000519)\n",
      "28. feature 20 dmeansz (0.000486)\n",
      "29. feature 0 sport (0.000428)\n",
      "30. feature 13 Spkts (0.000353)\n",
      "31. feature 38 ct_dst_sport_ltm (0.000311)\n",
      "32. feature 10 service (0.000260)\n",
      "33. feature 22 res_bdy_len (0.000137)\n",
      "34. feature 30 ct_flw_http_mthd (0.000126)\n",
      "35. feature 8 sloss (0.000109)\n",
      "36. feature 14 Dpkts (0.000054)\n",
      "37. feature 32 ct_ftp_cmd (0.000045)\n",
      "38. feature 31 is_ftp_login (0.000005)\n",
      "39. feature 16 dwin (0.000000)\n",
      "40. feature 21 trans_depth (0.000000)\n"
     ]
    }
   ],
   "source": [
    "importances = dt.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], X_train.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of classifiers to include\n",
    "import sklearn\n",
    "import xgboost\n",
    "import lightgbm\n",
    "\n",
    "#Skip SVM\n",
    "classifiers = [\n",
    " ('AdaBoostClassifier', sklearn.ensemble._weight_boosting.AdaBoostClassifier),\n",
    " ('BaggingClassifier', sklearn.ensemble._bagging.BaggingClassifier),\n",
    " ('BernoulliNB', sklearn.naive_bayes.BernoulliNB),\n",
    " ('DecisionTreeClassifier', sklearn.tree._classes.DecisionTreeClassifier),\n",
    " ('DummyClassifier', sklearn.dummy.DummyClassifier),\n",
    " ('GaussianNB', sklearn.naive_bayes.GaussianNB),\n",
    " ('KNeighborsClassifier',  sklearn.neighbors._classification.KNeighborsClassifier),\n",
    " ('LinearDiscriminantAnalysis',  sklearn.discriminant_analysis.LinearDiscriminantAnalysis),\n",
    " ('LogisticRegression', sklearn.linear_model._logistic.LogisticRegression),\n",
    " ('Perceptron', sklearn.linear_model._perceptron.Perceptron),\n",
    " ('QuadraticDiscriminantAnalysis',  sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis),\n",
    " ('RandomForestClassifier', sklearn.ensemble._forest.RandomForestClassifier),\n",
    " ('StackingClassifier', sklearn.ensemble._stacking.StackingClassifier),\n",
    " ('XGBClassifier', xgboost.sklearn.XGBClassifier),\n",
    " ('LGBMClassifier', lightgbm.sklearn.LGBMClassifier)]\n",
    "clf = LazyClassifier(verbose=1,ignore_warnings=True, custom_metric=None,classifiers=classifiers,predictions=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tuple' object has no attribute '__name__'\n",
      "Invalid Classifier(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [01:44<24:21, 104.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostClassifier', 'Accuracy': 0.9909240402251597, 'Balanced Accuracy': 0.9909240402251597, 'ROC AUC': 0.9909240402251597, 'F1 Score': 0.9909236661801477, 'Time taken': 104.4176733493805}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [02:45<17:07, 79.01s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BaggingClassifier', 'Accuracy': 0.9917146290557207, 'Balanced Accuracy': 0.9917146290557206, 'ROC AUC': 0.9917146290557207, 'F1 Score': 0.9917144007265325, 'Time taken': 61.21940326690674}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [02:47<08:44, 43.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BernoulliNB', 'Accuracy': 0.9463032066282967, 'Balanced Accuracy': 0.9463032066282968, 'ROC AUC': 0.9463032066282967, 'F1 Score': 0.9462995202315023, 'Time taken': 1.682997465133667}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [02:57<05:34, 30.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DecisionTreeClassifier', 'Accuracy': 0.9856745303902347, 'Balanced Accuracy': 0.9856745303902346, 'ROC AUC': 0.9856745303902347, 'F1 Score': 0.9856744660797542, 'Time taken': 10.120678663253784}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [02:58<03:19, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DummyClassifier', 'Accuracy': 0.5, 'Balanced Accuracy': 0.5, 'ROC AUC': 0.5, 'F1 Score': 0.3333333333333333, 'Time taken': 1.376312017440796}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [03:00<02:03, 13.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GaussianNB', 'Accuracy': 0.9122762633609512, 'Balanced Accuracy': 0.9122762633609512, 'ROC AUC': 0.9122762633609512, 'F1 Score': 0.9121688198222384, 'Time taken': 1.6039955615997314}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [09:49<19:04, 143.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'KNeighborsClassifier', 'Accuracy': 0.9861172601353488, 'Balanced Accuracy': 0.9861172601353487, 'ROC AUC': 0.9861172601353488, 'F1 Score': 0.9861155102565818, 'Time taken': 409.2410125732422}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [09:52<11:28, 98.43s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LinearDiscriminantAnalysis', 'Accuracy': 0.9796028081715261, 'Balanced Accuracy': 0.9796028081715262, 'ROC AUC': 0.9796028081715261, 'F1 Score': 0.979598731614267, 'Time taken': 2.894321918487549}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [10:00<07:01, 70.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LogisticRegression', 'Accuracy': 0.9815950920245399, 'Balanced Accuracy': 0.9815950920245399, 'ROC AUC': 0.9815950920245399, 'F1 Score': 0.981590378267109, 'Time taken': 8.080846548080444}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [10:03<04:07, 49.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Perceptron', 'Accuracy': 0.9718550376320283, 'Balanced Accuracy': 0.9718550376320283, 'ROC AUC': 0.9718550376320284, 'F1 Score': 0.9718391117548667, 'Time taken': 3.131439447402954}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [10:06<02:20, 35.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'QuadraticDiscriminantAnalysis', 'Accuracy': 0.9792233255328568, 'Balanced Accuracy': 0.9792233255328568, 'ROC AUC': 0.979223325532857, 'F1 Score': 0.9792190984690882, 'Time taken': 2.543717384338379}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [12:11<03:07, 62.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RandomForestClassifier', 'Accuracy': 0.9926949592056163, 'Balanced Accuracy': 0.9926949592056163, 'ROC AUC': 0.9926949592056162, 'F1 Score': 0.9926946023851659, 'Time taken': 125.44841027259827}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [12:24<00:36, 36.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'XGBClassifier', 'Accuracy': 0.9927898298652836, 'Balanced Accuracy': 0.9927898298652837, 'ROC AUC': 0.9927898298652836, 'F1 Score': 0.9927894871760407, 'Time taken': 13.116864442825317}\n",
      "[LightGBM] [Info] Number of positive: 63244, number of negative: 63244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.249554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6493\n",
      "[LightGBM] [Info] Number of data points in the train set: 126488, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [12:40<00:00, 50.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LGBMClassifier', 'Accuracy': 0.9928214534185061, 'Balanced Accuracy': 0.992821453418506, 'ROC AUC': 0.9928214534185061, 'F1 Score': 0.9928211027767646, 'Time taken': 15.11256742477417}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>15.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>13.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>125.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>61.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>104.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>409.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>8.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "LGBMClassifier                     0.99               0.99     0.99      0.99   \n",
       "XGBClassifier                      0.99               0.99     0.99      0.99   \n",
       "RandomForestClassifier             0.99               0.99     0.99      0.99   \n",
       "BaggingClassifier                  0.99               0.99     0.99      0.99   \n",
       "AdaBoostClassifier                 0.99               0.99     0.99      0.99   \n",
       "KNeighborsClassifier               0.99               0.99     0.99      0.99   \n",
       "DecisionTreeClassifier             0.99               0.99     0.99      0.99   \n",
       "LogisticRegression                 0.98               0.98     0.98      0.98   \n",
       "LinearDiscriminantAnalysis         0.98               0.98     0.98      0.98   \n",
       "QuadraticDiscriminantAnalysis      0.98               0.98     0.98      0.98   \n",
       "Perceptron                         0.97               0.97     0.97      0.97   \n",
       "BernoulliNB                        0.95               0.95     0.95      0.95   \n",
       "GaussianNB                         0.91               0.91     0.91      0.91   \n",
       "DummyClassifier                    0.50               0.50     0.50      0.33   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "LGBMClassifier                      15.11  \n",
       "XGBClassifier                       13.12  \n",
       "RandomForestClassifier             125.45  \n",
       "BaggingClassifier                   61.22  \n",
       "AdaBoostClassifier                 104.42  \n",
       "KNeighborsClassifier               409.24  \n",
       "DecisionTreeClassifier              10.12  \n",
       "LogisticRegression                   8.08  \n",
       "LinearDiscriminantAnalysis           2.89  \n",
       "QuadraticDiscriminantAnalysis        2.54  \n",
       "Perceptron                           3.13  \n",
       "BernoulliNB                          1.68  \n",
       "GaussianNB                           1.60  \n",
       "DummyClassifier                      1.38  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models1,predictions1 = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     15811\n",
      "           1       0.98      1.00      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.9909240402251597\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "BaggingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     15811\n",
      "           1       0.99      1.00      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.9917146290557207\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "BernoulliNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     15811\n",
      "           1       0.94      0.95      0.95     15811\n",
      "\n",
      "    accuracy                           0.95     31622\n",
      "   macro avg       0.95      0.95      0.95     31622\n",
      "weighted avg       0.95      0.95      0.95     31622\n",
      "\n",
      "AUC Scores for each class: 0.9463032066282967\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     15811\n",
      "           1       0.99      0.98      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.9856745303902347\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "DummyClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     15811\n",
      "           1       0.00      0.00      0.00     15811\n",
      "\n",
      "    accuracy                           0.50     31622\n",
      "   macro avg       0.25      0.50      0.33     31622\n",
      "weighted avg       0.25      0.50      0.33     31622\n",
      "\n",
      "AUC Scores for each class: 0.5\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     15811\n",
      "           1       0.94      0.88      0.91     15811\n",
      "\n",
      "    accuracy                           0.91     31622\n",
      "   macro avg       0.91      0.91      0.91     31622\n",
      "weighted avg       0.91      0.91      0.91     31622\n",
      "\n",
      "AUC Scores for each class: 0.9122762633609512\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     15811\n",
      "           1       0.98      1.00      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.9861172601353488\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "LinearDiscriminantAnalysis\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     15811\n",
      "           1       0.97      0.99      0.98     15811\n",
      "\n",
      "    accuracy                           0.98     31622\n",
      "   macro avg       0.98      0.98      0.98     31622\n",
      "weighted avg       0.98      0.98      0.98     31622\n",
      "\n",
      "AUC Scores for each class: 0.9796028081715261\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     15811\n",
      "           1       0.97      1.00      0.98     15811\n",
      "\n",
      "    accuracy                           0.98     31622\n",
      "   macro avg       0.98      0.98      0.98     31622\n",
      "weighted avg       0.98      0.98      0.98     31622\n",
      "\n",
      "AUC Scores for each class: 0.9815950920245399\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "Perceptron\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     15811\n",
      "           1       0.95      1.00      0.97     15811\n",
      "\n",
      "    accuracy                           0.97     31622\n",
      "   macro avg       0.97      0.97      0.97     31622\n",
      "weighted avg       0.97      0.97      0.97     31622\n",
      "\n",
      "AUC Scores for each class: 0.9718550376320284\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "QuadraticDiscriminantAnalysis\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98     15811\n",
      "           1       0.97      0.99      0.98     15811\n",
      "\n",
      "    accuracy                           0.98     31622\n",
      "   macro avg       0.98      0.98      0.98     31622\n",
      "weighted avg       0.98      0.98      0.98     31622\n",
      "\n",
      "AUC Scores for each class: 0.979223325532857\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     15811\n",
      "           1       0.99      1.00      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.9926949592056162\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "XGBClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     15811\n",
      "           1       0.99      1.00      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.9927898298652836\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "LGBMClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     15811\n",
      "           1       0.99      1.00      0.99     15811\n",
      "\n",
      "    accuracy                           0.99     31622\n",
      "   macro avg       0.99      0.99      0.99     31622\n",
      "weighted avg       0.99      0.99      0.99     31622\n",
      "\n",
      "AUC Scores for each class: 0.9928214534185061\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "for model in predictions1.columns:\n",
    "    print(model)\n",
    "    print(classification_report(y_test, predictions1[model]))\n",
    "    auc_scores = roc_auc_score(y_test, predictions1[model], multi_class='ovr')  # Or multi_class='ovo' for one-vs-one\n",
    "    print(\"AUC Scores for each class:\", auc_scores)\n",
    "    print('-----------------------------------------------------------------------------------')\n",
    "    print('-----------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Performance of Models in Attack Category Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00467594 0.28453542 0.01533218 0.15907297 0.38336585 0.58759297\n",
      " 0.55313286 0.6514427  0.61479295 0.19213226 0.21914381 0.04620834\n",
      " 0.38123949 0.4259998  0.23815449 0.38012804 0.0054774  0.00667274\n",
      " 0.00126116 0.00272367 0.39241371 0.44096202 0.01675245 0.06628789\n",
      " 0.28844532 0.24373788 0.31653359 0.44219682 0.4447345  0.44188447\n",
      " 0.44460516 0.63879798 0.01560297 0.00144817 0.00072851 0.08059814\n",
      " 0.11891383 0.17153435 0.13297856 0.03306991 0.03414698 0.04889669]\n"
     ]
    }
   ],
   "source": [
    "#Find information gain and gini index for each feature in the dataset in classifying the label\n",
    "#Information gain\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "#IG for each attribute\n",
    "ig = mutual_info_classif(X_train, y_train, random_state=42)\n",
    "print(ig)\n",
    "#Print column name with ig\n",
    "ig = pd.Series(ig)\n",
    "ig.index = X_train.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ct_ftp_cmd          0.000729\n",
       "stcpb               0.001261\n",
       "is_ftp_login        0.001448\n",
       "dtcpb               0.002724\n",
       "sport               0.004676\n",
       "swin                0.005477\n",
       "dwin                0.006673\n",
       "proto               0.015332\n",
       "ct_flw_http_mthd    0.015603\n",
       "trans_depth         0.016752\n",
       "ct_src_dport_ltm    0.033070\n",
       "ct_dst_sport_ltm    0.034147\n",
       "service             0.046208\n",
       "ct_dst_src_ltm      0.048897\n",
       "res_bdy_len         0.066288\n",
       "ct_srv_src          0.080598\n",
       "ct_srv_dst          0.118914\n",
       "ct_src_ ltm         0.132979\n",
       "state               0.159073\n",
       "ct_dst_ltm          0.171534\n",
       "sloss               0.192132\n",
       "dloss               0.219144\n",
       "Spkts               0.238154\n",
       "Djit                0.243738\n",
       "dsport              0.284535\n",
       "Sjit                0.288445\n",
       "Sintpkt             0.316534\n",
       "Dpkts               0.380128\n",
       "Sload               0.381239\n",
       "dur                 0.383366\n",
       "smeansz             0.392414\n",
       "Dload               0.426000\n",
       "dmeansz             0.440962\n",
       "synack              0.441884\n",
       "Dintpkt             0.442197\n",
       "ackdat              0.444605\n",
       "tcprtt              0.444734\n",
       "dbytes              0.553133\n",
       "sbytes              0.587593\n",
       "dttl                0.614793\n",
       "ct_state_ttl        0.638798\n",
       "sttl                0.651443\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ig = pd.Series(ig)\n",
    "ig.index = X_train.columns\n",
    "ig.sort_values(ascending=True, inplace=True)\n",
    "ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trans_depth         0.000000\n",
       "dwin                0.000000\n",
       "is_ftp_login        0.000000\n",
       "dttl                0.000000\n",
       "swin                0.000000\n",
       "ct_ftp_cmd          0.000039\n",
       "service             0.000061\n",
       "dloss               0.000094\n",
       "Dpkts               0.000094\n",
       "res_bdy_len         0.000148\n",
       "Spkts               0.000154\n",
       "ct_flw_http_mthd    0.000162\n",
       "proto               0.000210\n",
       "ct_dst_sport_ltm    0.000253\n",
       "sloss               0.000297\n",
       "sport               0.000326\n",
       "dmeansz             0.000328\n",
       "ct_src_dport_ltm    0.000358\n",
       "state               0.000483\n",
       "ct_dst_ltm          0.000634\n",
       "Sjit                0.000863\n",
       "Dintpkt             0.000964\n",
       "ct_dst_src_ltm      0.001053\n",
       "Dload               0.001110\n",
       "Djit                0.001149\n",
       "smeansz             0.001164\n",
       "ct_srv_dst          0.001333\n",
       "ct_src_ ltm         0.001350\n",
       "Sintpkt             0.001377\n",
       "tcprtt              0.001378\n",
       "dur                 0.001434\n",
       "dtcpb               0.001519\n",
       "ct_srv_src          0.001524\n",
       "synack              0.001559\n",
       "sbytes              0.001708\n",
       "ackdat              0.001815\n",
       "Sload               0.002033\n",
       "stcpb               0.002229\n",
       "dbytes              0.002606\n",
       "ct_state_ttl        0.003433\n",
       "dsport              0.004466\n",
       "sttl                0.960294\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gini index\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "gini = dt.feature_importances_\n",
    "gini = pd.Series(gini)\n",
    "gini.index = X_train.columns\n",
    "gini.sort_values(ascending=True, inplace=True)\n",
    "gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 7 sttl (0.239618)\n",
      "2. feature 31 ct_state_ttl (0.145984)\n",
      "3. feature 13 Dload (0.123297)\n",
      "4. feature 8 dttl (0.092329)\n",
      "5. feature 30 ackdat (0.070177)\n",
      "6. feature 28 tcprtt (0.056903)\n",
      "7. feature 21 dmeansz (0.050559)\n",
      "8. feature 29 synack (0.044978)\n",
      "9. feature 6 dbytes (0.030799)\n",
      "10. feature 27 Dintpkt (0.029286)\n",
      "11. feature 24 Sjit (0.013810)\n",
      "12. feature 3 state (0.012666)\n",
      "13. feature 4 dur (0.011738)\n",
      "14. feature 26 Sintpkt (0.009851)\n",
      "15. feature 5 sbytes (0.009589)\n",
      "16. feature 15 Dpkts (0.008150)\n",
      "17. feature 12 Sload (0.008098)\n",
      "18. feature 37 ct_dst_ltm (0.006068)\n",
      "19. feature 10 dloss (0.005066)\n",
      "20. feature 1 dsport (0.004351)\n",
      "21. feature 25 Djit (0.004003)\n",
      "22. feature 20 smeansz (0.003856)\n",
      "23. feature 14 Spkts (0.002592)\n",
      "24. feature 41 ct_dst_src_ltm (0.002144)\n",
      "25. feature 36 ct_srv_dst (0.002121)\n",
      "26. feature 35 ct_srv_src (0.002058)\n",
      "27. feature 18 stcpb (0.001586)\n",
      "28. feature 19 dtcpb (0.001446)\n",
      "29. feature 39 ct_src_dport_ltm (0.001353)\n",
      "30. feature 38 ct_src_ ltm (0.001103)\n",
      "31. feature 9 sloss (0.001053)\n",
      "32. feature 11 service (0.000847)\n",
      "33. feature 40 ct_dst_sport_ltm (0.000766)\n",
      "34. feature 16 swin (0.000593)\n",
      "35. feature 2 proto (0.000385)\n",
      "36. feature 0 sport (0.000380)\n",
      "37. feature 23 res_bdy_len (0.000192)\n",
      "38. feature 32 ct_flw_http_mthd (0.000093)\n",
      "39. feature 22 trans_depth (0.000046)\n",
      "40. feature 17 dwin (0.000025)\n",
      "41. feature 34 ct_ftp_cmd (0.000022)\n",
      "42. feature 33 is_ftp_login (0.000017)\n"
     ]
    }
   ],
   "source": [
    "#Find out less important features using other metrics\n",
    "#Feature importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], X_train.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sttl 0.6519307153233845\n",
      "ct_state_ttl 0.6390593910486492\n",
      "dttl 0.6149109035440272\n",
      "sbytes 0.587247442240477\n",
      "dbytes 0.5524949642117569\n",
      "tcprtt 0.44455188180960215\n",
      "ackdat 0.44436722897014924\n",
      "Dintpkt 0.44306488146966827\n",
      "dmeansz 0.4414907882363108\n",
      "synack 0.441002791565152\n",
      "Dload 0.42590077456632924\n",
      "smeansz 0.39244389804582913\n",
      "dur 0.38360421341189976\n",
      "Sload 0.3812381337542132\n",
      "Dpkts 0.37926591556465183\n",
      "Sintpkt 0.31678366701069494\n",
      "Sjit 0.2880705450728873\n",
      "dsport 0.2835658105005858\n",
      "Djit 0.24339257648715495\n",
      "Spkts 0.2377133739359738\n",
      "dloss 0.2188002123816457\n",
      "sloss 0.1896227178751122\n",
      "ct_dst_ltm 0.16974317384632043\n",
      "state 0.1601539334834492\n",
      "ct_src_ ltm 0.1308162912466777\n",
      "ct_srv_dst 0.11796191941382195\n",
      "ct_srv_src 0.08258624334071873\n",
      "res_bdy_len 0.06581436253435591\n",
      "ct_dst_src_ltm 0.048519102444590345\n",
      "service 0.04703875325667761\n",
      "ct_dst_sport_ltm 0.032456743604212246\n",
      "ct_src_dport_ltm 0.031693136589936666\n",
      "ct_flw_http_mthd 0.016299095520632134\n",
      "proto 0.014640910886305925\n",
      "trans_depth 0.013385361845124288\n",
      "swin 0.008817636596974543\n",
      "dwin 0.006847796349836788\n",
      "sport 0.004939810698009861\n",
      "dtcpb 0.0019906465534069717\n",
      "stcpb 0.0013912136783191809\n",
      "is_ftp_login 0.0\n",
      "ct_ftp_cmd 0.0\n"
     ]
    }
   ],
   "source": [
    "#Mutual Importance\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Calculate mutual information between features and target variable\n",
    "mi_scores = mutual_info_classif(X_train, y_train)\n",
    "\n",
    "# Sort features based on mutual information scores\n",
    "sorted_features = sorted(zip(X_train.columns, mi_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print feature names and their mutual information scores\n",
    "for feature, score in sorted_features:\n",
    "    print(feature, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. LSTM FOR AVG STTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the dataset (1% sample taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data (sample data)\n",
    "# Replace this part with your actual data loading and preprocessing\n",
    "\n",
    "#Sample 1% of the dataset\n",
    "dfsample = df.sample(frac=0.01, random_state=42)\n",
    "\n",
    "nodes = set()\n",
    "for i in range(len(dfsample)):\n",
    "    src = str(dfsample['srcip'].iloc[i])+':'+str(dfsample['sport'].iloc[i])\n",
    "    dst = str(dfsample['dstip'].iloc[i])+':'+str(dfsample['dsport'].iloc[i])\n",
    "    nodes.add(src)\n",
    "    nodes.add(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5325"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25359"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "708891/708891 [==============================] - 5248s 7ms/step - loss: 2.7351e-04 - accuracy: 1.0000 - val_loss: 2.3519e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "708891/708891 [==============================] - 5573s 8ms/step - loss: 1.8012e-05 - accuracy: 1.0000 - val_loss: 2.0178e-05 - val_accuracy: 1.0000\n",
      " 14804/886114 [..............................] - ETA: 1:04:36 - loss: 1.2331e-06 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 68>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(adjacency_tensor, label_flat, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43madjacency_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_flat\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:2296\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2292\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   2293\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2294\u001b[0m             ):\n\u001b[0;32m   2295\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 2296\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2297\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2298\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2299\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2300\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2301\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2303\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2304\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:4108\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[1;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[0;32m   4107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[1;32m-> 4108\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   4110\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Modify the call method of the LSTMClassifier\n",
    "class LSTMClassifier(tf.keras.Model):\n",
    "    def __init__(self, input_shape, hidden_units, output_units):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = LSTM(hidden_units, return_sequences=False)  # Set return_sequences=False since we only need the output at the last timestep\n",
    "        self.dense = Dense(output_units, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.expand_dims(inputs, axis=-1)  # Add a new dimension to represent the input features\n",
    "        x = self.lstm(x)\n",
    "        output = self.dense(x)\n",
    "        return output\n",
    "\n",
    "# Prepare an adjacency matrix of the nodes\n",
    "adjacency_matrix = np.zeros((len(nodes), len(nodes)), dtype=float)\n",
    "count_matrix = np.zeros((len(nodes), len(nodes)), dtype=int)\n",
    "label_matrix = np.zeros((len(nodes), len(nodes)))\n",
    "\n",
    "# Add the columns srcip:sport and dstip:dsport to the adjacency matrix\n",
    "for i in range(len(dfsample)):\n",
    "    src = str(dfsample['srcip'].iloc[i])+':'+str(dfsample['sport'].iloc[i])\n",
    "    dst = str(dfsample['dstip'].iloc[i])+':'+str(dfsample['dsport'].iloc[i])\n",
    "    src_index = list(nodes).index(src)\n",
    "    dst_index = list(nodes).index(dst)\n",
    "    if dfsample['Label'].iloc[i] == 1:\n",
    "        if label_matrix[src_index,dst_index] == 0:\n",
    "            adjacency_matrix[src_index, dst_index] = dfsample['sttl'].iloc[i]\n",
    "            label_matrix[src_index, dst_index] = 1  \n",
    "            count_matrix[src_index,dst_index]+= 1\n",
    "        else:\n",
    "            adjacency_matrix[src_index, dst_index] = (adjacency_matrix[src_index, dst_index]*count_matrix[src_index,dst_index]+dfsample['sttl'].iloc[i])/(count_matrix[src_index,dst_index]+1)\n",
    "            count_matrix[src_index,dst_index]+= 1\n",
    "    else:\n",
    "        if count_matrix[src_index,dst_index] == 0:\n",
    "            adjacency_matrix[src_index, dst_index] = dfsample['sttl'].iloc[i]\n",
    "            count_matrix[src_index,dst_index]+= 1\n",
    "        else:\n",
    "            adjacency_matrix[src_index, dst_index] = (adjacency_matrix[src_index, dst_index]*count_matrix[src_index,dst_index]+dfsample['sttl'].iloc[i])/(count_matrix[src_index,dst_index]+1)\n",
    "            count_matrix[src_index,dst_index]+= 1\n",
    "\n",
    "# Flatten tuple values in the adjacency matrix\n",
    "adjacency_matrix_flat = adjacency_matrix.reshape(-1, 1)\n",
    "label_flat = label_matrix.reshape(-1, 1)\n",
    "\n",
    "# Hyperparameters\n",
    "input_shape = adjacency_matrix_flat.shape[1:]  # Assuming each tuple has 2 attributes\n",
    "hidden_units = 16\n",
    "output_units = 1  # Binary classification\n",
    "\n",
    "# Convert adjacency_matrix_flat to a TensorFlow tensor\n",
    "adjacency_tensor = tf.convert_to_tensor(adjacency_matrix_flat, dtype=tf.float32)\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "model = LSTMClassifier(input_shape, hidden_units, output_units)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Training\n",
    "history = model.fit(adjacency_tensor, label_flat, epochs=2, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluation\n",
    "#loss, accuracy = model.evaluate(adjacency_tensor, label_flat) \n",
    "#print(f'Loss: {loss}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparting Testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a sample from the dataset to evalute the lstm model\n",
    "dftestsample = df.sample(frac=0.001, random_state=32)\n",
    "\n",
    "nodestest = set()\n",
    "for i in range(len(dftestsample)):\n",
    "    src = str(dftestsample['srcip'].iloc[i])+':'+str(dftestsample['sport'].iloc[i])\n",
    "    dst = str(dftestsample['dstip'].iloc[i])+':'+str(dftestsample['dsport'].iloc[i])\n",
    "    nodestest.add(src)\n",
    "    nodestest.add(dst)\n",
    "\n",
    "# Prepare an adjacency matrix of the nodes\n",
    "adjacency_matrix_test = np.zeros((len(nodestest), len(nodestest)), dtype=float)\n",
    "label_matrix_test = np.zeros((len(nodestest), len(nodestest)))\n",
    "\n",
    "# Add the columns srcip:sport and dstip:dsport to the adjacency matrix\n",
    "for i in range(len(dftestsample)):\n",
    "    src = str(dftestsample['srcip'].iloc[i])+':'+str(dftestsample['sport'].iloc[i])\n",
    "    dst = str(dftestsample['dstip'].iloc[i])+':'+str(dftestsample['dsport'].iloc[i])\n",
    "    src_index = list(nodestest).index(src)\n",
    "    dst_index = list(nodestest).index(dst)\n",
    "\n",
    "    if dftestsample['Label'].iloc[i] == 1:\n",
    "        if label_matrix_test[src_index,dst_index] == 0:\n",
    "            adjacency_matrix_test[src_index, dst_index] = dftestsample['sttl'].iloc[i]\n",
    "            label_matrix_test[src_index, dst_index] = 1  \n",
    "\n",
    "    else:\n",
    "        adjacency_matrix_test[src_index, dst_index] = dftestsample['sttl'].iloc[i]\n",
    "\n",
    "\n",
    "# Flatten tuple values in the adjacency matrix\n",
    "adjacency_matrix_test_flat = adjacency_matrix_test.reshape(-1, 1)\n",
    "label_test_flat = label_matrix_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "732"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodestest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2536"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dftestsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14792/14792 [==============================] - 72s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(adjacency_matrix_test_flat)\n",
    "predictions = (predictions > 0.5).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    473252\n",
      "         1.0       0.76      0.99      0.86        92\n",
      "\n",
      "    accuracy                           1.00    473344\n",
      "   macro avg       0.88      0.99      0.93    473344\n",
      "weighted avg       1.00      1.00      1.00    473344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(label_test_flat, predictions)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer Phase2ParallelRunning.ipynb for other LSTM and GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore (Was supposed to be for GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define GCN layer\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.bias = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        support = torch.mm(x, self.weight)\n",
    "        output = torch.mm(adj, support) + self.bias\n",
    "        return output\n",
    "\n",
    "# Define GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(input_dim, hidden_dim)\n",
    "        self.gc2 = GraphConvolution(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = self.relu(self.gc1(x, adj))\n",
    "        out = self.gc2(h, adj)\n",
    "        return out\n",
    "\n",
    "# Function to calculate F1 score\n",
    "def calculate_f1_score(labels, predictions):\n",
    "    f1_score_0 = f1_score(labels, predictions, pos_label=0)\n",
    "    f1_score_1 = f1_score(labels, predictions, pos_label=1)\n",
    "    return f1_score_0, f1_score_1\n",
    "\n",
    "# Prepare data (sample data)\n",
    "# Replace this part with your actual data loading and preprocessing\n",
    "\n",
    "# Assuming adjacency matrix is already prepared\n",
    "adjacency_matrix = torch.tensor([[0, 1, 1],\n",
    "                                 [1, 0, 1],\n",
    "                                 [1, 1, 0]], dtype=torch.float32)\n",
    "\n",
    "# Assuming feature matrix is already prepared\n",
    "feature_matrix = torch.tensor([[0.1, 0.2],\n",
    "                               [0.3, 0.4],\n",
    "                               [0.5, 0.6]], dtype=torch.float32)\n",
    "\n",
    "# Assuming labels are already prepared\n",
    "labels = torch.tensor([0, 1, 0], dtype=torch.long)\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = feature_matrix.shape[1]\n",
    "hidden_dim = 16\n",
    "output_dim = 2\n",
    "lr = 0.01\n",
    "epochs = 100\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "model = GCN(input_dim, hidden_dim, output_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(feature_matrix, adjacency_matrix)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(feature_matrix, adjacency_matrix).argmax(dim=1)\n",
    "    f1_score_0, f1_score_1 = calculate_f1_score(labels.numpy(), predictions.numpy())\n",
    "    print(f'F1 Score for Label=0: {f1_score_0}')\n",
    "    print(f'F1 Score for Label=1: {f1_score_1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
