{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jagad\\AppData\\Local\\Temp\\ipykernel_12628\\1198099750.py:6: DtypeWarning: Columns (1,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"C:\\Users\\jagad\\Documents\\GitHub\\Graph-Anomaly-Detection\\datasets\\phase2labelencodeddataset.csv\",encoding='cp1252')\n",
      "c:\\Users\\jagad\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\jagad\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\jagad\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\jagad\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\jagad\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\Users\\jagad\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\jagad\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\jagad\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\jagad\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Attribute  Information_Gain\n",
      "42        attack_cat          0.471141\n",
      "5               sttl          0.396619\n",
      "6               dttl          0.381476\n",
      "0              proto          0.263225\n",
      "40  ct_dst_sport_ltm          0.259462\n",
      "1              state          0.241174\n",
      "14              swin          0.191722\n",
      "15              dwin          0.191264\n",
      "31      ct_state_ttl          0.160650\n",
      "3             sbytes          0.155067\n",
      "4             dbytes          0.134651\n",
      "39  ct_src_dport_ltm          0.123298\n",
      "19           dmeansz          0.122328\n",
      "10             Sload          0.106404\n",
      "18           smeansz          0.106325\n",
      "11             Dload          0.101572\n",
      "27           Dintpkt          0.101367\n",
      "13             Dpkts          0.093044\n",
      "28            tcprtt          0.091993\n",
      "30            ackdat          0.090931\n",
      "29            synack          0.089718\n",
      "2                dur          0.089272\n",
      "37        ct_dst_ltm          0.080907\n",
      "38       ct_src_ ltm          0.071120\n",
      "26           Sintpkt          0.058616\n",
      "12             Spkts          0.054787\n",
      "7              sloss          0.053226\n",
      "36        ct_srv_dst          0.052350\n",
      "41    ct_dst_src_ltm          0.050632\n",
      "22              Sjit          0.049758\n",
      "35        ct_srv_src          0.042654\n",
      "8              dloss          0.042112\n",
      "23              Djit          0.040248\n",
      "25             Ltime          0.033058\n",
      "24             Stime          0.032465\n",
      "9            service          0.029758\n",
      "21       res_bdy_len          0.016374\n",
      "20       trans_depth          0.011755\n",
      "32  ct_flw_http_mthd          0.011313\n",
      "16             stcpb          0.006141\n",
      "17             dtcpb          0.003937\n",
      "33      is_ftp_login          0.001095\n",
      "34        ct_ftp_cmd          0.000488\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Load UNSW-NB15 dataset\n",
    "# Assuming you have the dataset file named 'unsw_nb15.csv' in your current directory\n",
    "df = pd.read_csv(r\"C:\\Users\\jagad\\Documents\\GitHub\\Graph-Anomaly-Detection\\datasets\\phase2labelencodeddataset.csv\",encoding='cp1252')\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "# Assuming 'label' is the target variable column name\n",
    "target_variable = 'Label'\n",
    "\n",
    "# Remove non-numeric columns and target variable for calculating information gain\n",
    "numeric_df = df.select_dtypes(include='number').drop(columns=[target_variable])\n",
    "\n",
    "# Calculate information gain for each attribute\n",
    "information_gain = mutual_info_classif(numeric_df, df[target_variable])\n",
    "\n",
    "# Create a DataFrame to store attribute names and their corresponding information gain\n",
    "info_gain_df = pd.DataFrame({'Attribute': numeric_df.columns, 'Information_Gain': information_gain})\n",
    "\n",
    "# Sort the DataFrame by information gain values in descending order\n",
    "info_gain_df = info_gain_df.sort_values(by='Information_Gain', ascending=False)\n",
    "\n",
    "print(info_gain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
