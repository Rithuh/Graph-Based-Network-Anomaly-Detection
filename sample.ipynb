{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "num_nodes = 10\n",
    "num_edges = 20\n",
    "\n",
    "# Generate random adjacency matrix\n",
    "adjacency_matrix = np.random.randint(0, 2, size=(num_nodes, num_nodes))\n",
    "\n",
    "# Ensure symmetric adjacency\n",
    "adjacency_matrix = np.maximum(adjacency_matrix, adjacency_matrix.T)\n",
    "\n",
    "# Create random edge features\n",
    "edge_features = np.random.rand(num_edges, 1)\n",
    "\n",
    "# Label each edge as 'good' or 'bad' (binary classification)\n",
    "edge_labels = np.random.choice(['good', 'bad'], size=num_edges)\n",
    "\n",
    "# Map labels to integers (0 for 'bad', 1 for 'good')\n",
    "edge_labels = np.array([0 if label == 'bad' else 1 for label in edge_labels])\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "adjacency_matrix = torch.tensor(adjacency_matrix, dtype=torch.float32)\n",
    "edge_features = torch.tensor(edge_features, dtype=torch.float32)\n",
    "edge_labels = torch.tensor(edge_labels, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency Matrix Shape: torch.Size([10, 10])\n",
      "Edge Features Shape: torch.Size([20, 1])\n",
      "Edge Labels Shape: torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "num_nodes = 10\n",
    "num_edges = 20\n",
    "\n",
    "# Generate random adjacency matrix\n",
    "adjacency_matrix = torch.tensor(np.random.randint(0, 2, size=(num_nodes, num_nodes)), dtype=torch.float32)\n",
    "\n",
    "# Ensure symmetric adjacency\n",
    "adjacency_matrix = torch.maximum(adjacency_matrix, adjacency_matrix.T)\n",
    "\n",
    "# Get indices of non-zero elements in the adjacency matrix\n",
    "edge_indices = torch.nonzero(adjacency_matrix, as_tuple=False)\n",
    "\n",
    "# Create random edge features and labels based on the number of edges\n",
    "edge_features = torch.randn(num_edges, 1)\n",
    "edge_labels = torch.randint(0, 2, (num_edges,), dtype=torch.float32)\n",
    "\n",
    "print(\"Adjacency Matrix Shape:\", adjacency_matrix.shape)\n",
    "print(\"Edge Features Shape:\", edge_features.shape)\n",
    "print(\"Edge Labels Shape:\", edge_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sathi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sathi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sathi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "(32, 10, 64)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(1000, 64))\n",
    "# The model will take as input an integer matrix of size (batch,\n",
    "# input_length), and the largest integer (i.e. word index) in the input\n",
    "# should be no larger than 999 (vocabulary size).\n",
    "# Now model.output_shape is (None, 10, 64), where `None` is the batch\n",
    "# dimension.\n",
    "input_array = np.random.randint(1000, size=(32, 10))\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "print(output_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGATLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(EGATLayer, self).__init__()\n",
    "        self.fc = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        self.attn_fc = nn.Linear(2*out_dim, 1, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, adjacency_matrix):\n",
    "        h = self.fc(x)\n",
    "        batch_size, num_nodes, _ = h.size()\n",
    "        \n",
    "        # Pairwise node attention\n",
    "        attn_input = torch.cat([h.unsqueeze(2).expand(-1, -1, num_nodes, -1),\n",
    "                                h.unsqueeze(1).expand(-1, num_nodes, -1, -1)], dim=3)\n",
    "        attn_scores = self.attn_fc(attn_input).squeeze(3)\n",
    "        attn_scores = torch.where(adjacency_matrix.unsqueeze(0).expand(batch_size, -1, -1) > 0, attn_scores, torch.tensor(-9e15))\n",
    "        attn_scores = torch.softmax(attn_scores, dim=2)\n",
    "        \n",
    "        # Weighted sum of neighbors' features\n",
    "        h_prime = torch.matmul(attn_scores, h)\n",
    "        \n",
    "        return self.relu(h_prime)\n",
    "\n",
    "class EGAT(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super(EGAT, self).__init__()\n",
    "        self.egat_layer = EGATLayer(in_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x, adjacency_matrix):\n",
    "        h = self.egat_layer(x, adjacency_matrix)\n",
    "        out = self.fc(h.mean(dim=1))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency Matrix Shape: torch.Size([10, 10])\n",
      "Edge Features Shape: torch.Size([20, 1])\n",
      "Edge Labels Shape: torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "print(\"Adjacency Matrix Shape:\", adjacency_matrix.shape)\n",
    "print(\"Edge Features Shape:\", edge_features.shape)\n",
    "print(\"Edge Labels Shape:\", edge_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10, 20, 20]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Split data into training and testing sets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m adj_train, adj_test, features_train, features_test, labels_train, labels_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m      3\u001b[0m     adjacency_matrix, edge_features, edge_labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2564\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 443\u001b[0m check_consistent_length(\u001b[38;5;241m*\u001b[39mresult)\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10, 20, 20]"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "adj_train, adj_test, features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    adjacency_matrix, edge_features, edge_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = EGAT(in_dim=1, hidden_dim=32, out_dim=1)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features_train.unsqueeze(0), adj_train.unsqueeze(0))\n",
    "    loss = criterion(output.squeeze(), labels_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Evaluate on test set\n",
    "with torch.no_grad():\n",
    "    test_output = model(features_test.unsqueeze(0), adj_test.unsqueeze(0))\n",
    "    predicted_labels = torch.round(torch.sigmoid(test_output))\n",
    "    accuracy = (predicted_labels.squeeze() == labels_test).float().mean()\n",
    "    print(f'Accuracy on test set: {accuracy.item()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
